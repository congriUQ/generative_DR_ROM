{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/constantin/anaconda3/envs/genDRROM/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/constantin/anaconda3/envs/genDRROM/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/constantin/anaconda3/envs/genDRROM/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/constantin/anaconda3/envs/genDRROM/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/constantin/anaconda3/envs/genDRROM/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/constantin/anaconda3/envs/genDRROM/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from poisson_fem import PoissonFEM\n",
    "import ROM\n",
    "import GenerativeSurrogate as gs\n",
    "import Data as dta\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import scipy.sparse.linalg as lg\n",
    "import time\n",
    "import petsc4py\n",
    "import sys\n",
    "petsc4py.init(sys.argv)\n",
    "from petsc4py import PETSc\n",
    "import torch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Some fixed parameters\n",
    "lin_dim_rom = 4                      # Linear number of rom elements\n",
    "a = np.array([1, 2, 3])              # Boundary condition function coefficients\n",
    "dim_z = 30                            # Latent space dimension\n",
    "dtype = torch.float                  # Tensor data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Define mesh and boundary conditions\n",
    "mesh = PoissonFEM.RectangularMesh(np.ones(lin_dim_rom)/lin_dim_rom)\n",
    "# mesh.plot()\n",
    "\n",
    "def origin(x):\n",
    "    return np.abs(x[0]) < np.finfo(float).eps and np.abs(x[1]) < np.finfo(float).eps\n",
    "\n",
    "def essBoundaryFun(x):\n",
    "    return 0.0\n",
    "mesh.setEssentialBoundary(origin, essBoundaryFun)\n",
    "\n",
    "def domainBoundary(x):\n",
    "    # unit square\n",
    "    return np.abs(x[0]) < np.finfo(float).eps or np.abs(x[1]) < np.finfo(float).eps or \\\n",
    "            np.abs(x[0]) > 1.0 - np.finfo(float).eps or np.abs(x[1]) > 1.0 - np.finfo(float).eps\n",
    "mesh.setNaturalBoundary(domainBoundary)\n",
    "\n",
    "def flux(x):\n",
    "    q = np.array([a[0] + a[2]*x[1], a[1] + a[2]*x[0]])\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spepify right hand side and stiffness matrix\n",
    "#Define boundary flux field\n",
    "rhs = PoissonFEM.RightHandSide(mesh)\n",
    "rhs.setNaturalRHS(mesh, flux)\n",
    "funSpace = PoissonFEM.FunctionSpace(mesh)\n",
    "K = PoissonFEM.StiffnessMatrix(mesh, funSpace)\n",
    "rhs.setRhsStencil(mesh, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up solver\n",
    "ksp = PETSc.KSP().create()\n",
    "ksp.setType('preonly')\n",
    "precond = ksp.getPC()\n",
    "precond.setType('cholesky')\n",
    "ksp.setFromOptions() #???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define rom\n",
    "rom = ROM.ROM(mesh, K, rhs, ksp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = dta.StokesData(range(2048))\n",
    "trainingData.readData(['IMG'])\n",
    "# trainingData.plotMicrostruct(1)\n",
    "trainingData.reshapeInputImg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gs.GenerativeSurrogate(rom, trainingData, dim_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0\n",
      "loss_pf =  tensor(11631629., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.4331, grad_fn=<DotBackward>)\n",
      "step =  1\n",
      "loss_pf =  tensor(10922345., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(13.6645, grad_fn=<DotBackward>)\n",
      "step =  2\n",
      "loss_pf =  tensor(10847678., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.3698, grad_fn=<DotBackward>)\n",
      "step =  3\n",
      "loss_pf =  tensor(10689417., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4833, grad_fn=<DotBackward>)\n",
      "step =  4\n",
      "loss_pf =  tensor(10540688., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3425, grad_fn=<DotBackward>)\n",
      "step =  5\n",
      "loss_pf =  tensor(10480070., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1027, grad_fn=<DotBackward>)\n",
      "step =  6\n",
      "loss_pf =  tensor(10836524., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(25.1408, grad_fn=<DotBackward>)\n",
      "step =  7\n",
      "loss_pf =  tensor(10344600., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(24.6011, grad_fn=<DotBackward>)\n",
      "step =  8\n",
      "loss_pf =  tensor(10290627., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.2189, grad_fn=<DotBackward>)\n",
      "step =  9\n",
      "loss_pf =  tensor(10255834., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.6700, grad_fn=<DotBackward>)\n",
      "step =  10\n",
      "loss_pf =  tensor(10291568., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.8257, grad_fn=<DotBackward>)\n",
      "step =  11\n",
      "loss_pf =  tensor(10192504., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.3710, grad_fn=<DotBackward>)\n",
      "step =  12\n",
      "loss_pf =  tensor(10203238., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.5342, grad_fn=<DotBackward>)\n",
      "step =  13\n",
      "loss_pf =  tensor(10289484., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.0686, grad_fn=<DotBackward>)\n",
      "step =  14\n",
      "loss_pf =  tensor(10277816., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(15.5344, grad_fn=<DotBackward>)\n",
      "step =  15\n",
      "loss_pf =  tensor(10135076., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(14.1364, grad_fn=<DotBackward>)\n",
      "step =  16\n",
      "loss_pf =  tensor(10046306., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(8.3222, grad_fn=<DotBackward>)\n",
      "step =  17\n",
      "loss_pf =  tensor(10060180., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.3477, grad_fn=<DotBackward>)\n",
      "step =  18\n",
      "loss_pf =  tensor(9945208., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.0372, grad_fn=<DotBackward>)\n",
      "step =  19\n",
      "loss_pf =  tensor(9968886., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.1832, grad_fn=<DotBackward>)\n",
      "step =  20\n",
      "loss_pf =  tensor(9938447., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1701, grad_fn=<DotBackward>)\n",
      "step =  21\n",
      "loss_pf =  tensor(9829990., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0049, grad_fn=<DotBackward>)\n",
      "step =  22\n",
      "loss_pf =  tensor(9716953., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6762, grad_fn=<DotBackward>)\n",
      "step =  23\n",
      "loss_pf =  tensor(9595964., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1065, grad_fn=<DotBackward>)\n",
      "step =  24\n",
      "loss_pf =  tensor(9575071., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5061, grad_fn=<DotBackward>)\n",
      "step =  25\n",
      "loss_pf =  tensor(9445584., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6248, grad_fn=<DotBackward>)\n",
      "step =  26\n",
      "loss_pf =  tensor(9355349., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.9082, grad_fn=<DotBackward>)\n",
      "step =  27\n",
      "loss_pf =  tensor(9218699., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.8142, grad_fn=<DotBackward>)\n",
      "step =  28\n",
      "loss_pf =  tensor(9162373., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.7162, grad_fn=<DotBackward>)\n",
      "step =  29\n",
      "loss_pf =  tensor(9093546., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.5699, grad_fn=<DotBackward>)\n",
      "step =  30\n",
      "loss_pf =  tensor(8996788., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3521, grad_fn=<DotBackward>)\n",
      "step =  31\n",
      "loss_pf =  tensor(8923362., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7203, grad_fn=<DotBackward>)\n",
      "step =  32\n",
      "loss_pf =  tensor(8868296., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7660, grad_fn=<DotBackward>)\n",
      "step =  33\n",
      "loss_pf =  tensor(8869526., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.2017, grad_fn=<DotBackward>)\n",
      "step =  34\n",
      "loss_pf =  tensor(8859102., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.0402, grad_fn=<DotBackward>)\n",
      "step =  35\n",
      "loss_pf =  tensor(8680006., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.7706, grad_fn=<DotBackward>)\n",
      "step =  36\n",
      "loss_pf =  tensor(8691614., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.6596, grad_fn=<DotBackward>)\n",
      "step =  37\n",
      "loss_pf =  tensor(8532325., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.5588, grad_fn=<DotBackward>)\n",
      "step =  38\n",
      "loss_pf =  tensor(8493472., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.5339, grad_fn=<DotBackward>)\n",
      "step =  39\n",
      "loss_pf =  tensor(8520044., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.5970, grad_fn=<DotBackward>)\n",
      "step =  40\n",
      "loss_pf =  tensor(8330529.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.5827, grad_fn=<DotBackward>)\n",
      "step =  41\n",
      "loss_pf =  tensor(8279373., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.6855, grad_fn=<DotBackward>)\n",
      "step =  42\n",
      "loss_pf =  tensor(8408875., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.6416, grad_fn=<DotBackward>)\n",
      "step =  43\n",
      "loss_pf =  tensor(8191528.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.7178, grad_fn=<DotBackward>)\n",
      "step =  44\n",
      "loss_pf =  tensor(8165344., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.8861, grad_fn=<DotBackward>)\n",
      "step =  45\n",
      "loss_pf =  tensor(8112906., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.9042, grad_fn=<DotBackward>)\n",
      "step =  46\n",
      "loss_pf =  tensor(7993718., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.8343, grad_fn=<DotBackward>)\n",
      "step =  47\n",
      "loss_pf =  tensor(8001616.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.8025, grad_fn=<DotBackward>)\n",
      "step =  48\n",
      "loss_pf =  tensor(8059320., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.6581, grad_fn=<DotBackward>)\n",
      "step =  49\n",
      "loss_pf =  tensor(7772622., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.8273, grad_fn=<DotBackward>)\n",
      "step =  50\n",
      "loss_pf =  tensor(7870624., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.6614, grad_fn=<DotBackward>)\n",
      "step =  51\n",
      "loss_pf =  tensor(7856263., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.8070, grad_fn=<DotBackward>)\n",
      "step =  52\n",
      "loss_pf =  tensor(7756223., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.0336, grad_fn=<DotBackward>)\n",
      "step =  53\n",
      "loss_pf =  tensor(7713228.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6355, grad_fn=<DotBackward>)\n",
      "step =  54\n",
      "loss_pf =  tensor(7638036., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4720, grad_fn=<DotBackward>)\n",
      "step =  55\n",
      "loss_pf =  tensor(7470583., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.8509, grad_fn=<DotBackward>)\n",
      "step =  56\n",
      "loss_pf =  tensor(7437500., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.9042, grad_fn=<DotBackward>)\n",
      "step =  57\n",
      "loss_pf =  tensor(7403026., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2794, grad_fn=<DotBackward>)\n",
      "step =  58\n",
      "loss_pf =  tensor(7458966., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6704, grad_fn=<DotBackward>)\n",
      "step =  59\n",
      "loss_pf =  tensor(7329799., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.2208, grad_fn=<DotBackward>)\n",
      "step =  60\n",
      "loss_pf =  tensor(7458413., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.0862, grad_fn=<DotBackward>)\n",
      "step =  61\n",
      "loss_pf =  tensor(7186601., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.9577, grad_fn=<DotBackward>)\n",
      "step =  62\n",
      "loss_pf =  tensor(7078817., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.9202, grad_fn=<DotBackward>)\n",
      "step =  63\n",
      "loss_pf =  tensor(7101011., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.9602, grad_fn=<DotBackward>)\n",
      "step =  64\n",
      "loss_pf =  tensor(7165611., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.9880, grad_fn=<DotBackward>)\n",
      "step =  65\n",
      "loss_pf =  tensor(7025110., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.9495, grad_fn=<DotBackward>)\n",
      "step =  66\n",
      "loss_pf =  tensor(6997442., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.9295, grad_fn=<DotBackward>)\n",
      "step =  67\n",
      "loss_pf =  tensor(7117512.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.0836, grad_fn=<DotBackward>)\n",
      "step =  68\n",
      "loss_pf =  tensor(7200998., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.0113, grad_fn=<DotBackward>)\n",
      "step =  69\n",
      "loss_pf =  tensor(6783458.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.1591, grad_fn=<DotBackward>)\n",
      "step =  70\n",
      "loss_pf =  tensor(6875763., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5082, grad_fn=<DotBackward>)\n",
      "step =  71\n",
      "loss_pf =  tensor(6643023.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7957, grad_fn=<DotBackward>)\n",
      "step =  72\n",
      "loss_pf =  tensor(6955444., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5710, grad_fn=<DotBackward>)\n",
      "step =  73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_pf =  tensor(7010813., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6756, grad_fn=<DotBackward>)\n",
      "step =  74\n",
      "loss_pf =  tensor(7152637.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.5311, grad_fn=<DotBackward>)\n",
      "step =  75\n",
      "loss_pf =  tensor(7069683., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.0169, grad_fn=<DotBackward>)\n",
      "step =  76\n",
      "loss_pf =  tensor(6887920.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.1050, grad_fn=<DotBackward>)\n",
      "step =  77\n",
      "loss_pf =  tensor(6728373., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4174, grad_fn=<DotBackward>)\n",
      "step =  78\n",
      "loss_pf =  tensor(6661887., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0621, grad_fn=<DotBackward>)\n",
      "step =  79\n",
      "loss_pf =  tensor(6562073., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6378, grad_fn=<DotBackward>)\n",
      "step =  80\n",
      "loss_pf =  tensor(6810348., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.3057, grad_fn=<DotBackward>)\n",
      "step =  81\n",
      "loss_pf =  tensor(6644259., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.1621, grad_fn=<DotBackward>)\n",
      "step =  82\n",
      "loss_pf =  tensor(6397762., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.2169, grad_fn=<DotBackward>)\n",
      "step =  83\n",
      "loss_pf =  tensor(6186408., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.2627, grad_fn=<DotBackward>)\n",
      "step =  84\n",
      "loss_pf =  tensor(5853587., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(0.9590, grad_fn=<DotBackward>)\n",
      "step =  85\n",
      "loss_pf =  tensor(6463612., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.2016, grad_fn=<DotBackward>)\n",
      "step =  86\n",
      "loss_pf =  tensor(6349619., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.2003, grad_fn=<DotBackward>)\n",
      "step =  87\n",
      "loss_pf =  tensor(6361499., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.2640, grad_fn=<DotBackward>)\n",
      "step =  88\n",
      "loss_pf =  tensor(6391170., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.1816, grad_fn=<DotBackward>)\n",
      "step =  89\n",
      "loss_pf =  tensor(6189238., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.1518, grad_fn=<DotBackward>)\n",
      "step =  90\n",
      "loss_pf =  tensor(6197403., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.2391, grad_fn=<DotBackward>)\n",
      "step =  91\n",
      "loss_pf =  tensor(6073269., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.2066, grad_fn=<DotBackward>)\n",
      "step =  92\n",
      "loss_pf =  tensor(6084779.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.2146, grad_fn=<DotBackward>)\n",
      "step =  93\n",
      "loss_pf =  tensor(5919208., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.3007, grad_fn=<DotBackward>)\n",
      "step =  94\n",
      "loss_pf =  tensor(6266287.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.2985, grad_fn=<DotBackward>)\n",
      "step =  95\n",
      "loss_pf =  tensor(6084920., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.4989, grad_fn=<DotBackward>)\n",
      "step =  96\n",
      "loss_pf =  tensor(5848338., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5142, grad_fn=<DotBackward>)\n",
      "step =  97\n",
      "loss_pf =  tensor(5894504., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5831, grad_fn=<DotBackward>)\n",
      "step =  98\n",
      "loss_pf =  tensor(5942379., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.4762, grad_fn=<DotBackward>)\n",
      "step =  99\n",
      "loss_pf =  tensor(5988478., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6427, grad_fn=<DotBackward>)\n",
      "step =  100\n",
      "loss_pf =  tensor(5904144., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5693, grad_fn=<DotBackward>)\n",
      "step =  101\n",
      "loss_pf =  tensor(6156646., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5980, grad_fn=<DotBackward>)\n",
      "step =  102\n",
      "loss_pf =  tensor(5582824., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7843, grad_fn=<DotBackward>)\n",
      "step =  103\n",
      "loss_pf =  tensor(5798816., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6344, grad_fn=<DotBackward>)\n",
      "step =  104\n",
      "loss_pf =  tensor(5854859., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8780, grad_fn=<DotBackward>)\n",
      "step =  105\n",
      "loss_pf =  tensor(6053536., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5523, grad_fn=<DotBackward>)\n",
      "step =  106\n",
      "loss_pf =  tensor(5649767., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5401, grad_fn=<DotBackward>)\n",
      "step =  107\n",
      "loss_pf =  tensor(5660218., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.3792, grad_fn=<DotBackward>)\n",
      "step =  108\n",
      "loss_pf =  tensor(5864223., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(10.8919, grad_fn=<DotBackward>)\n",
      "step =  109\n",
      "loss_pf =  tensor(5747584., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(16.9947, grad_fn=<DotBackward>)\n",
      "step =  110\n",
      "loss_pf =  tensor(5895084., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(17.3797, grad_fn=<DotBackward>)\n",
      "step =  111\n",
      "loss_pf =  tensor(5755687.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(11.4319, grad_fn=<DotBackward>)\n",
      "step =  112\n",
      "loss_pf =  tensor(5612973., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.9515, grad_fn=<DotBackward>)\n",
      "step =  113\n",
      "loss_pf =  tensor(5597921., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2585, grad_fn=<DotBackward>)\n",
      "step =  114\n",
      "loss_pf =  tensor(5232791., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3530, grad_fn=<DotBackward>)\n",
      "step =  115\n",
      "loss_pf =  tensor(5226819., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5000, grad_fn=<DotBackward>)\n",
      "step =  116\n",
      "loss_pf =  tensor(5532009., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0745, grad_fn=<DotBackward>)\n",
      "step =  117\n",
      "loss_pf =  tensor(5476490., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1690, grad_fn=<DotBackward>)\n",
      "step =  118\n",
      "loss_pf =  tensor(5500786., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1694, grad_fn=<DotBackward>)\n",
      "step =  119\n",
      "loss_pf =  tensor(5523885., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0409, grad_fn=<DotBackward>)\n",
      "step =  120\n",
      "loss_pf =  tensor(5304844.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2051, grad_fn=<DotBackward>)\n",
      "step =  121\n",
      "loss_pf =  tensor(5345463., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2044, grad_fn=<DotBackward>)\n",
      "step =  122\n",
      "loss_pf =  tensor(5325573., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1462, grad_fn=<DotBackward>)\n",
      "step =  123\n",
      "loss_pf =  tensor(5176950., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0537, grad_fn=<DotBackward>)\n",
      "step =  124\n",
      "loss_pf =  tensor(5316668., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1718, grad_fn=<DotBackward>)\n",
      "step =  125\n",
      "loss_pf =  tensor(5249977., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6748, grad_fn=<DotBackward>)\n",
      "step =  126\n",
      "loss_pf =  tensor(5124393.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7440, grad_fn=<DotBackward>)\n",
      "step =  127\n",
      "loss_pf =  tensor(4986373.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3119, grad_fn=<DotBackward>)\n",
      "step =  128\n",
      "loss_pf =  tensor(5107002., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2871, grad_fn=<DotBackward>)\n",
      "step =  129\n",
      "loss_pf =  tensor(5077649.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4778, grad_fn=<DotBackward>)\n",
      "step =  130\n",
      "loss_pf =  tensor(5098741., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7469, grad_fn=<DotBackward>)\n",
      "step =  131\n",
      "loss_pf =  tensor(5091661., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9712, grad_fn=<DotBackward>)\n",
      "step =  132\n",
      "loss_pf =  tensor(5240384., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5740, grad_fn=<DotBackward>)\n",
      "step =  133\n",
      "loss_pf =  tensor(5336915., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.1490, grad_fn=<DotBackward>)\n",
      "step =  134\n",
      "loss_pf =  tensor(5076749., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.4813, grad_fn=<DotBackward>)\n",
      "step =  135\n",
      "loss_pf =  tensor(5291347., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.3099, grad_fn=<DotBackward>)\n",
      "step =  136\n",
      "loss_pf =  tensor(5441368.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.5269, grad_fn=<DotBackward>)\n",
      "step =  137\n",
      "loss_pf =  tensor(5047423., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(8.2594, grad_fn=<DotBackward>)\n",
      "step =  138\n",
      "loss_pf =  tensor(5199520., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.7614, grad_fn=<DotBackward>)\n",
      "step =  139\n",
      "loss_pf =  tensor(5349703., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(10.4024, grad_fn=<DotBackward>)\n",
      "step =  140\n",
      "loss_pf =  tensor(5134216., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.3355, grad_fn=<DotBackward>)\n",
      "step =  141\n",
      "loss_pf =  tensor(4831195., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(7.2108, grad_fn=<DotBackward>)\n",
      "step =  142\n",
      "loss_pf =  tensor(4976053., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.7355, grad_fn=<DotBackward>)\n",
      "step =  143\n",
      "loss_pf =  tensor(4833094.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.5590, grad_fn=<DotBackward>)\n",
      "step =  144\n",
      "loss_pf =  tensor(4878729., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4656, grad_fn=<DotBackward>)\n",
      "step =  145\n",
      "loss_pf =  tensor(5039903.5000, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_pc =  tensor(2.9852, grad_fn=<DotBackward>)\n",
      "step =  146\n",
      "loss_pf =  tensor(4836058.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.8009, grad_fn=<DotBackward>)\n",
      "step =  147\n",
      "loss_pf =  tensor(4809936., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9259, grad_fn=<DotBackward>)\n",
      "step =  148\n",
      "loss_pf =  tensor(5037110., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5416, grad_fn=<DotBackward>)\n",
      "step =  149\n",
      "loss_pf =  tensor(4532187., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7678, grad_fn=<DotBackward>)\n",
      "step =  150\n",
      "loss_pf =  tensor(4763558., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3930, grad_fn=<DotBackward>)\n",
      "step =  151\n",
      "loss_pf =  tensor(4600295.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0808, grad_fn=<DotBackward>)\n",
      "step =  152\n",
      "loss_pf =  tensor(4535979., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3258, grad_fn=<DotBackward>)\n",
      "step =  153\n",
      "loss_pf =  tensor(4562723., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9930, grad_fn=<DotBackward>)\n",
      "step =  154\n",
      "loss_pf =  tensor(4468865., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.1633, grad_fn=<DotBackward>)\n",
      "step =  155\n",
      "loss_pf =  tensor(4319708., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9641, grad_fn=<DotBackward>)\n",
      "step =  156\n",
      "loss_pf =  tensor(4543071., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2722, grad_fn=<DotBackward>)\n",
      "step =  157\n",
      "loss_pf =  tensor(4710102., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5388, grad_fn=<DotBackward>)\n",
      "step =  158\n",
      "loss_pf =  tensor(4653971.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.7218, grad_fn=<DotBackward>)\n",
      "step =  159\n",
      "loss_pf =  tensor(4377393.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.4688, grad_fn=<DotBackward>)\n",
      "step =  160\n",
      "loss_pf =  tensor(4831121.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.8477, grad_fn=<DotBackward>)\n",
      "step =  161\n",
      "loss_pf =  tensor(4652265., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.3079, grad_fn=<DotBackward>)\n",
      "step =  162\n",
      "loss_pf =  tensor(5115850., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(11.4221, grad_fn=<DotBackward>)\n",
      "step =  163\n",
      "loss_pf =  tensor(4935163., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(13.4472, grad_fn=<DotBackward>)\n",
      "step =  164\n",
      "loss_pf =  tensor(5084588., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(14.1425, grad_fn=<DotBackward>)\n",
      "step =  165\n",
      "loss_pf =  tensor(4821965.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(12.3864, grad_fn=<DotBackward>)\n",
      "step =  166\n",
      "loss_pf =  tensor(4953210., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(7.7438, grad_fn=<DotBackward>)\n",
      "step =  167\n",
      "loss_pf =  tensor(4587438., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.6205, grad_fn=<DotBackward>)\n",
      "step =  168\n",
      "loss_pf =  tensor(4609442., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5045, grad_fn=<DotBackward>)\n",
      "step =  169\n",
      "loss_pf =  tensor(4403916., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.9151, grad_fn=<DotBackward>)\n",
      "step =  170\n",
      "loss_pf =  tensor(4461185., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.7291, grad_fn=<DotBackward>)\n",
      "step =  171\n",
      "loss_pf =  tensor(4509298., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4855, grad_fn=<DotBackward>)\n",
      "step =  172\n",
      "loss_pf =  tensor(4562427., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0226, grad_fn=<DotBackward>)\n",
      "step =  173\n",
      "loss_pf =  tensor(4428216., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.8353, grad_fn=<DotBackward>)\n",
      "step =  174\n",
      "loss_pf =  tensor(4294574., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9640, grad_fn=<DotBackward>)\n",
      "step =  175\n",
      "loss_pf =  tensor(4325775.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0855, grad_fn=<DotBackward>)\n",
      "step =  176\n",
      "loss_pf =  tensor(4508592., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0677, grad_fn=<DotBackward>)\n",
      "step =  177\n",
      "loss_pf =  tensor(3896454., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2033, grad_fn=<DotBackward>)\n",
      "step =  178\n",
      "loss_pf =  tensor(4523703.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9870, grad_fn=<DotBackward>)\n",
      "step =  179\n",
      "loss_pf =  tensor(4018063., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7561, grad_fn=<DotBackward>)\n",
      "step =  180\n",
      "loss_pf =  tensor(4145851.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.1498, grad_fn=<DotBackward>)\n",
      "step =  181\n",
      "loss_pf =  tensor(4216252.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.3356, grad_fn=<DotBackward>)\n",
      "step =  182\n",
      "loss_pf =  tensor(4285086., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.1472, grad_fn=<DotBackward>)\n",
      "step =  183\n",
      "loss_pf =  tensor(4125927.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7505, grad_fn=<DotBackward>)\n",
      "step =  184\n",
      "loss_pf =  tensor(4117216., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0868, grad_fn=<DotBackward>)\n",
      "step =  185\n",
      "loss_pf =  tensor(4250563., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2565, grad_fn=<DotBackward>)\n",
      "step =  186\n",
      "loss_pf =  tensor(4219883., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6616, grad_fn=<DotBackward>)\n",
      "step =  187\n",
      "loss_pf =  tensor(4557823., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.9496, grad_fn=<DotBackward>)\n",
      "step =  188\n",
      "loss_pf =  tensor(4582136., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.0681, grad_fn=<DotBackward>)\n",
      "step =  189\n",
      "loss_pf =  tensor(4478359.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.8922, grad_fn=<DotBackward>)\n",
      "step =  190\n",
      "loss_pf =  tensor(4612442., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.3006, grad_fn=<DotBackward>)\n",
      "step =  191\n",
      "loss_pf =  tensor(4273028., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.9013, grad_fn=<DotBackward>)\n",
      "step =  192\n",
      "loss_pf =  tensor(4541325., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(8.0353, grad_fn=<DotBackward>)\n",
      "step =  193\n",
      "loss_pf =  tensor(4516844.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(8.8434, grad_fn=<DotBackward>)\n",
      "step =  194\n",
      "loss_pf =  tensor(4581408., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(7.7893, grad_fn=<DotBackward>)\n",
      "step =  195\n",
      "loss_pf =  tensor(4483058., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.9563, grad_fn=<DotBackward>)\n",
      "step =  196\n",
      "loss_pf =  tensor(4252681., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.7626, grad_fn=<DotBackward>)\n",
      "step =  197\n",
      "loss_pf =  tensor(4282768., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.3641, grad_fn=<DotBackward>)\n",
      "step =  198\n",
      "loss_pf =  tensor(4192271., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.6479, grad_fn=<DotBackward>)\n",
      "step =  199\n",
      "loss_pf =  tensor(4041155., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.9853, grad_fn=<DotBackward>)\n",
      "step =  200\n",
      "loss_pf =  tensor(4463658., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.3558, grad_fn=<DotBackward>)\n",
      "step =  201\n",
      "loss_pf =  tensor(4208310., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.3683, grad_fn=<DotBackward>)\n",
      "step =  202\n",
      "loss_pf =  tensor(4476073.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4404, grad_fn=<DotBackward>)\n",
      "step =  203\n",
      "loss_pf =  tensor(4014198.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.1294, grad_fn=<DotBackward>)\n",
      "step =  204\n",
      "loss_pf =  tensor(4012339., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.3381, grad_fn=<DotBackward>)\n",
      "step =  205\n",
      "loss_pf =  tensor(4118703., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.7205, grad_fn=<DotBackward>)\n",
      "step =  206\n",
      "loss_pf =  tensor(3983984.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.8347, grad_fn=<DotBackward>)\n",
      "step =  207\n",
      "loss_pf =  tensor(3708610., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6061, grad_fn=<DotBackward>)\n",
      "step =  208\n",
      "loss_pf =  tensor(4069929.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.1096, grad_fn=<DotBackward>)\n",
      "step =  209\n",
      "loss_pf =  tensor(3654366.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.8153, grad_fn=<DotBackward>)\n",
      "step =  210\n",
      "loss_pf =  tensor(4054720.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7612, grad_fn=<DotBackward>)\n",
      "step =  211\n",
      "loss_pf =  tensor(3919703.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0236, grad_fn=<DotBackward>)\n",
      "step =  212\n",
      "loss_pf =  tensor(3848104., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5587, grad_fn=<DotBackward>)\n",
      "step =  213\n",
      "loss_pf =  tensor(3528691.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3953, grad_fn=<DotBackward>)\n",
      "step =  214\n",
      "loss_pf =  tensor(3743218., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5248, grad_fn=<DotBackward>)\n",
      "step =  215\n",
      "loss_pf =  tensor(3721751., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2549, grad_fn=<DotBackward>)\n",
      "step =  216\n",
      "loss_pf =  tensor(4102677.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5899, grad_fn=<DotBackward>)\n",
      "step =  217\n",
      "loss_pf =  tensor(3941518.7500, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_pc =  tensor(4.7488, grad_fn=<DotBackward>)\n",
      "step =  218\n",
      "loss_pf =  tensor(3971583.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.1794, grad_fn=<DotBackward>)\n",
      "step =  219\n",
      "loss_pf =  tensor(4373474., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.9284, grad_fn=<DotBackward>)\n",
      "step =  220\n",
      "loss_pf =  tensor(4380168., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(7.2782, grad_fn=<DotBackward>)\n",
      "step =  221\n",
      "loss_pf =  tensor(4482258., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.5565, grad_fn=<DotBackward>)\n",
      "step =  222\n",
      "loss_pf =  tensor(4937345.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(10.4378, grad_fn=<DotBackward>)\n",
      "step =  223\n",
      "loss_pf =  tensor(4285781., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.9886, grad_fn=<DotBackward>)\n",
      "step =  224\n",
      "loss_pf =  tensor(4602187., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(8.5600, grad_fn=<DotBackward>)\n",
      "step =  225\n",
      "loss_pf =  tensor(4747888.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(7.2768, grad_fn=<DotBackward>)\n",
      "step =  226\n",
      "loss_pf =  tensor(4704847., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.2506, grad_fn=<DotBackward>)\n",
      "step =  227\n",
      "loss_pf =  tensor(4291712.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.2815, grad_fn=<DotBackward>)\n",
      "step =  228\n",
      "loss_pf =  tensor(4229345.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.0837, grad_fn=<DotBackward>)\n",
      "step =  229\n",
      "loss_pf =  tensor(4079193.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.3124, grad_fn=<DotBackward>)\n",
      "step =  230\n",
      "loss_pf =  tensor(3993085., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.2990, grad_fn=<DotBackward>)\n",
      "step =  231\n",
      "loss_pf =  tensor(3800870.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2739, grad_fn=<DotBackward>)\n",
      "step =  232\n",
      "loss_pf =  tensor(3884054., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0277, grad_fn=<DotBackward>)\n",
      "step =  233\n",
      "loss_pf =  tensor(4144028.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.1468, grad_fn=<DotBackward>)\n",
      "step =  234\n",
      "loss_pf =  tensor(4013186.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4846, grad_fn=<DotBackward>)\n",
      "step =  235\n",
      "loss_pf =  tensor(4128225.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2199, grad_fn=<DotBackward>)\n",
      "step =  236\n",
      "loss_pf =  tensor(3960125.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7753, grad_fn=<DotBackward>)\n",
      "step =  237\n",
      "loss_pf =  tensor(3609270.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7272, grad_fn=<DotBackward>)\n",
      "step =  238\n",
      "loss_pf =  tensor(3686482.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.8041, grad_fn=<DotBackward>)\n",
      "step =  239\n",
      "loss_pf =  tensor(3777123., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5167, grad_fn=<DotBackward>)\n",
      "step =  240\n",
      "loss_pf =  tensor(3424796.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0359, grad_fn=<DotBackward>)\n",
      "step =  241\n",
      "loss_pf =  tensor(3973071.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3626, grad_fn=<DotBackward>)\n",
      "step =  242\n",
      "loss_pf =  tensor(3575705., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6275, grad_fn=<DotBackward>)\n",
      "step =  243\n",
      "loss_pf =  tensor(3441143.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7056, grad_fn=<DotBackward>)\n",
      "step =  244\n",
      "loss_pf =  tensor(3500596.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5139, grad_fn=<DotBackward>)\n",
      "step =  245\n",
      "loss_pf =  tensor(3944230.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2743, grad_fn=<DotBackward>)\n",
      "step =  246\n",
      "loss_pf =  tensor(3476566., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5232, grad_fn=<DotBackward>)\n",
      "step =  247\n",
      "loss_pf =  tensor(3230814.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4070, grad_fn=<DotBackward>)\n",
      "step =  248\n",
      "loss_pf =  tensor(3625800.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9616, grad_fn=<DotBackward>)\n",
      "step =  249\n",
      "loss_pf =  tensor(2928626.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4144, grad_fn=<DotBackward>)\n",
      "step =  250\n",
      "loss_pf =  tensor(3568246., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3473, grad_fn=<DotBackward>)\n",
      "step =  251\n",
      "loss_pf =  tensor(3249455., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6314, grad_fn=<DotBackward>)\n",
      "step =  252\n",
      "loss_pf =  tensor(3783495.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0896, grad_fn=<DotBackward>)\n",
      "step =  253\n",
      "loss_pf =  tensor(3852202., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5438, grad_fn=<DotBackward>)\n",
      "step =  254\n",
      "loss_pf =  tensor(3579748.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.8127, grad_fn=<DotBackward>)\n",
      "step =  255\n",
      "loss_pf =  tensor(3490165.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.7062, grad_fn=<DotBackward>)\n",
      "step =  256\n",
      "loss_pf =  tensor(3844081., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.1132, grad_fn=<DotBackward>)\n",
      "step =  257\n",
      "loss_pf =  tensor(3845666.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.8737, grad_fn=<DotBackward>)\n",
      "step =  258\n",
      "loss_pf =  tensor(4244472., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6052, grad_fn=<DotBackward>)\n",
      "step =  259\n",
      "loss_pf =  tensor(4201778., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.7178, grad_fn=<DotBackward>)\n",
      "step =  260\n",
      "loss_pf =  tensor(4214064., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0638, grad_fn=<DotBackward>)\n",
      "step =  261\n",
      "loss_pf =  tensor(4424659., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.2164, grad_fn=<DotBackward>)\n",
      "step =  262\n",
      "loss_pf =  tensor(4432311.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9722, grad_fn=<DotBackward>)\n",
      "step =  263\n",
      "loss_pf =  tensor(4022712.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7835, grad_fn=<DotBackward>)\n",
      "step =  264\n",
      "loss_pf =  tensor(4227880., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.4273, grad_fn=<DotBackward>)\n",
      "step =  265\n",
      "loss_pf =  tensor(4057113., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.4974, grad_fn=<DotBackward>)\n",
      "step =  266\n",
      "loss_pf =  tensor(4125459., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.2893, grad_fn=<DotBackward>)\n",
      "step =  267\n",
      "loss_pf =  tensor(3806401.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.3286, grad_fn=<DotBackward>)\n",
      "step =  268\n",
      "loss_pf =  tensor(3675787., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.9459, grad_fn=<DotBackward>)\n",
      "step =  269\n",
      "loss_pf =  tensor(3602647., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.7178, grad_fn=<DotBackward>)\n",
      "step =  270\n",
      "loss_pf =  tensor(3253646.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6900, grad_fn=<DotBackward>)\n",
      "step =  271\n",
      "loss_pf =  tensor(3191084., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7928, grad_fn=<DotBackward>)\n",
      "step =  272\n",
      "loss_pf =  tensor(3895946.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4875, grad_fn=<DotBackward>)\n",
      "step =  273\n",
      "loss_pf =  tensor(3301597., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.8987, grad_fn=<DotBackward>)\n",
      "step =  274\n",
      "loss_pf =  tensor(3413807.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5468, grad_fn=<DotBackward>)\n",
      "step =  275\n",
      "loss_pf =  tensor(3349954., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3417, grad_fn=<DotBackward>)\n",
      "step =  276\n",
      "loss_pf =  tensor(3370211., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8973, grad_fn=<DotBackward>)\n",
      "step =  277\n",
      "loss_pf =  tensor(3524932.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8077, grad_fn=<DotBackward>)\n",
      "step =  278\n",
      "loss_pf =  tensor(3214373., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0848, grad_fn=<DotBackward>)\n",
      "step =  279\n",
      "loss_pf =  tensor(3194062.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1851, grad_fn=<DotBackward>)\n",
      "step =  280\n",
      "loss_pf =  tensor(3443919., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3125, grad_fn=<DotBackward>)\n",
      "step =  281\n",
      "loss_pf =  tensor(3219537., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6724, grad_fn=<DotBackward>)\n",
      "step =  282\n",
      "loss_pf =  tensor(3560687.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4756, grad_fn=<DotBackward>)\n",
      "step =  283\n",
      "loss_pf =  tensor(3371520., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4534, grad_fn=<DotBackward>)\n",
      "step =  284\n",
      "loss_pf =  tensor(3451295., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6651, grad_fn=<DotBackward>)\n",
      "step =  285\n",
      "loss_pf =  tensor(3515754.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9772, grad_fn=<DotBackward>)\n",
      "step =  286\n",
      "loss_pf =  tensor(3278463., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4920, grad_fn=<DotBackward>)\n",
      "step =  287\n",
      "loss_pf =  tensor(3468120.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.6626, grad_fn=<DotBackward>)\n",
      "step =  288\n",
      "loss_pf =  tensor(3973391.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.8110, grad_fn=<DotBackward>)\n",
      "step =  289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_pf =  tensor(3642521.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(8.5923, grad_fn=<DotBackward>)\n",
      "step =  290\n",
      "loss_pf =  tensor(4610995., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(16.0095, grad_fn=<DotBackward>)\n",
      "step =  291\n",
      "loss_pf =  tensor(4121476.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(15.2908, grad_fn=<DotBackward>)\n",
      "step =  292\n",
      "loss_pf =  tensor(5159740., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(19.9908, grad_fn=<DotBackward>)\n",
      "step =  293\n",
      "loss_pf =  tensor(3892110.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(12.1170, grad_fn=<DotBackward>)\n",
      "step =  294\n",
      "loss_pf =  tensor(4875648., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(8.8046, grad_fn=<DotBackward>)\n",
      "step =  295\n",
      "loss_pf =  tensor(3983895., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.5501, grad_fn=<DotBackward>)\n",
      "step =  296\n",
      "loss_pf =  tensor(4225967., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.6367, grad_fn=<DotBackward>)\n",
      "step =  297\n",
      "loss_pf =  tensor(4232307.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.8827, grad_fn=<DotBackward>)\n",
      "step =  298\n",
      "loss_pf =  tensor(4215848.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.2424, grad_fn=<DotBackward>)\n",
      "step =  299\n",
      "loss_pf =  tensor(3758291.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.9539, grad_fn=<DotBackward>)\n",
      "step =  300\n",
      "loss_pf =  tensor(3820163., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0583, grad_fn=<DotBackward>)\n",
      "step =  301\n",
      "loss_pf =  tensor(3414629.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.3144, grad_fn=<DotBackward>)\n",
      "step =  302\n",
      "loss_pf =  tensor(3635435., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1697, grad_fn=<DotBackward>)\n",
      "step =  303\n",
      "loss_pf =  tensor(3350795., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7680, grad_fn=<DotBackward>)\n",
      "step =  304\n",
      "loss_pf =  tensor(3440870., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6981, grad_fn=<DotBackward>)\n",
      "step =  305\n",
      "loss_pf =  tensor(3502795., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8670, grad_fn=<DotBackward>)\n",
      "step =  306\n",
      "loss_pf =  tensor(3486324., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5509, grad_fn=<DotBackward>)\n",
      "step =  307\n",
      "loss_pf =  tensor(3562454.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7282, grad_fn=<DotBackward>)\n",
      "step =  308\n",
      "loss_pf =  tensor(3053092.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6726, grad_fn=<DotBackward>)\n",
      "step =  309\n",
      "loss_pf =  tensor(3120614.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7804, grad_fn=<DotBackward>)\n",
      "step =  310\n",
      "loss_pf =  tensor(3173699.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9233, grad_fn=<DotBackward>)\n",
      "step =  311\n",
      "loss_pf =  tensor(3113553., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1188, grad_fn=<DotBackward>)\n",
      "step =  312\n",
      "loss_pf =  tensor(2903311.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9523, grad_fn=<DotBackward>)\n",
      "step =  313\n",
      "loss_pf =  tensor(2938491.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8984, grad_fn=<DotBackward>)\n",
      "step =  314\n",
      "loss_pf =  tensor(3252004.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8160, grad_fn=<DotBackward>)\n",
      "step =  315\n",
      "loss_pf =  tensor(3470168.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6462, grad_fn=<DotBackward>)\n",
      "step =  316\n",
      "loss_pf =  tensor(2703011., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6498, grad_fn=<DotBackward>)\n",
      "step =  317\n",
      "loss_pf =  tensor(2983281., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5468, grad_fn=<DotBackward>)\n",
      "step =  318\n",
      "loss_pf =  tensor(3142815.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1243, grad_fn=<DotBackward>)\n",
      "step =  319\n",
      "loss_pf =  tensor(3068806.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9950, grad_fn=<DotBackward>)\n",
      "step =  320\n",
      "loss_pf =  tensor(3115704.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5553, grad_fn=<DotBackward>)\n",
      "step =  321\n",
      "loss_pf =  tensor(2981508.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6508, grad_fn=<DotBackward>)\n",
      "step =  322\n",
      "loss_pf =  tensor(2627613.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1878, grad_fn=<DotBackward>)\n",
      "step =  323\n",
      "loss_pf =  tensor(2622002., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0466, grad_fn=<DotBackward>)\n",
      "step =  324\n",
      "loss_pf =  tensor(2845270.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8958, grad_fn=<DotBackward>)\n",
      "step =  325\n",
      "loss_pf =  tensor(2984992., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2493, grad_fn=<DotBackward>)\n",
      "step =  326\n",
      "loss_pf =  tensor(2709579.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3757, grad_fn=<DotBackward>)\n",
      "step =  327\n",
      "loss_pf =  tensor(2846781.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1133, grad_fn=<DotBackward>)\n",
      "step =  328\n",
      "loss_pf =  tensor(2861789.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0896, grad_fn=<DotBackward>)\n",
      "step =  329\n",
      "loss_pf =  tensor(2685012.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4168, grad_fn=<DotBackward>)\n",
      "step =  330\n",
      "loss_pf =  tensor(2861048.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2623, grad_fn=<DotBackward>)\n",
      "step =  331\n",
      "loss_pf =  tensor(2725193.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2793, grad_fn=<DotBackward>)\n",
      "step =  332\n",
      "loss_pf =  tensor(2861993.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4993, grad_fn=<DotBackward>)\n",
      "step =  333\n",
      "loss_pf =  tensor(3067107.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0494, grad_fn=<DotBackward>)\n",
      "step =  334\n",
      "loss_pf =  tensor(2834259.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.1367, grad_fn=<DotBackward>)\n",
      "step =  335\n",
      "loss_pf =  tensor(3161571., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.4354, grad_fn=<DotBackward>)\n",
      "step =  336\n",
      "loss_pf =  tensor(3295122.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.9926, grad_fn=<DotBackward>)\n",
      "step =  337\n",
      "loss_pf =  tensor(3246642.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.0870, grad_fn=<DotBackward>)\n",
      "step =  338\n",
      "loss_pf =  tensor(3226536., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.9592, grad_fn=<DotBackward>)\n",
      "step =  339\n",
      "loss_pf =  tensor(3154684., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5925, grad_fn=<DotBackward>)\n",
      "step =  340\n",
      "loss_pf =  tensor(3343621., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.0195, grad_fn=<DotBackward>)\n",
      "step =  341\n",
      "loss_pf =  tensor(3392579.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.5997, grad_fn=<DotBackward>)\n",
      "step =  342\n",
      "loss_pf =  tensor(3679755., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.8314, grad_fn=<DotBackward>)\n",
      "step =  343\n",
      "loss_pf =  tensor(3148119.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.0417, grad_fn=<DotBackward>)\n",
      "step =  344\n",
      "loss_pf =  tensor(3794461., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.0665, grad_fn=<DotBackward>)\n",
      "step =  345\n",
      "loss_pf =  tensor(3675980.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.8072, grad_fn=<DotBackward>)\n",
      "step =  346\n",
      "loss_pf =  tensor(3635165.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.4209, grad_fn=<DotBackward>)\n",
      "step =  347\n",
      "loss_pf =  tensor(4072947.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.9750, grad_fn=<DotBackward>)\n",
      "step =  348\n",
      "loss_pf =  tensor(3659343., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.5341, grad_fn=<DotBackward>)\n",
      "step =  349\n",
      "loss_pf =  tensor(3691732.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.1813, grad_fn=<DotBackward>)\n",
      "step =  350\n",
      "loss_pf =  tensor(3748349., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.7123, grad_fn=<DotBackward>)\n",
      "step =  351\n",
      "loss_pf =  tensor(3616947.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4450, grad_fn=<DotBackward>)\n",
      "step =  352\n",
      "loss_pf =  tensor(3369113., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.7921, grad_fn=<DotBackward>)\n",
      "step =  353\n",
      "loss_pf =  tensor(3477856.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.0836, grad_fn=<DotBackward>)\n",
      "step =  354\n",
      "loss_pf =  tensor(3556339.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.4432, grad_fn=<DotBackward>)\n",
      "step =  355\n",
      "loss_pf =  tensor(3366453., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.2097, grad_fn=<DotBackward>)\n",
      "step =  356\n",
      "loss_pf =  tensor(3303927., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.1303, grad_fn=<DotBackward>)\n",
      "step =  357\n",
      "loss_pf =  tensor(2974374.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7635, grad_fn=<DotBackward>)\n",
      "step =  358\n",
      "loss_pf =  tensor(2926560.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7231, grad_fn=<DotBackward>)\n",
      "step =  359\n",
      "loss_pf =  tensor(3131639.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6777, grad_fn=<DotBackward>)\n",
      "step =  360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_pf =  tensor(3131249.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5633, grad_fn=<DotBackward>)\n",
      "step =  361\n",
      "loss_pf =  tensor(3087603.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5082, grad_fn=<DotBackward>)\n",
      "step =  362\n",
      "loss_pf =  tensor(2819599., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6039, grad_fn=<DotBackward>)\n",
      "step =  363\n",
      "loss_pf =  tensor(2844794.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8096, grad_fn=<DotBackward>)\n",
      "step =  364\n",
      "loss_pf =  tensor(2680142.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1861, grad_fn=<DotBackward>)\n",
      "step =  365\n",
      "loss_pf =  tensor(3077367., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3927, grad_fn=<DotBackward>)\n",
      "step =  366\n",
      "loss_pf =  tensor(2917112.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2064, grad_fn=<DotBackward>)\n",
      "step =  367\n",
      "loss_pf =  tensor(2541134.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0386, grad_fn=<DotBackward>)\n",
      "step =  368\n",
      "loss_pf =  tensor(2749714.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9695, grad_fn=<DotBackward>)\n",
      "step =  369\n",
      "loss_pf =  tensor(2967581.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9909, grad_fn=<DotBackward>)\n",
      "step =  370\n",
      "loss_pf =  tensor(2516982.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3497, grad_fn=<DotBackward>)\n",
      "step =  371\n",
      "loss_pf =  tensor(2551126.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5478, grad_fn=<DotBackward>)\n",
      "step =  372\n",
      "loss_pf =  tensor(2402883.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2710, grad_fn=<DotBackward>)\n",
      "step =  373\n",
      "loss_pf =  tensor(2696037.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9865, grad_fn=<DotBackward>)\n",
      "step =  374\n",
      "loss_pf =  tensor(2582867.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5089, grad_fn=<DotBackward>)\n",
      "step =  375\n",
      "loss_pf =  tensor(2472805., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.4796, grad_fn=<DotBackward>)\n",
      "step =  376\n",
      "loss_pf =  tensor(2656045.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6248, grad_fn=<DotBackward>)\n",
      "step =  377\n",
      "loss_pf =  tensor(2640644., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7455, grad_fn=<DotBackward>)\n",
      "step =  378\n",
      "loss_pf =  tensor(2575795.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5511, grad_fn=<DotBackward>)\n",
      "step =  379\n",
      "loss_pf =  tensor(2817155., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5894, grad_fn=<DotBackward>)\n",
      "step =  380\n",
      "loss_pf =  tensor(2645459., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5478, grad_fn=<DotBackward>)\n",
      "step =  381\n",
      "loss_pf =  tensor(2828907., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6368, grad_fn=<DotBackward>)\n",
      "step =  382\n",
      "loss_pf =  tensor(2897091., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2152, grad_fn=<DotBackward>)\n",
      "step =  383\n",
      "loss_pf =  tensor(3271688.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.0506, grad_fn=<DotBackward>)\n",
      "step =  384\n",
      "loss_pf =  tensor(3544945.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.1890, grad_fn=<DotBackward>)\n",
      "step =  385\n",
      "loss_pf =  tensor(3586611.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.9181, grad_fn=<DotBackward>)\n",
      "step =  386\n",
      "loss_pf =  tensor(3517983.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.5725, grad_fn=<DotBackward>)\n",
      "step =  387\n",
      "loss_pf =  tensor(4218540.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(8.0060, grad_fn=<DotBackward>)\n",
      "step =  388\n",
      "loss_pf =  tensor(4085470., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(8.8331, grad_fn=<DotBackward>)\n",
      "step =  389\n",
      "loss_pf =  tensor(4632141., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(11.6665, grad_fn=<DotBackward>)\n",
      "step =  390\n",
      "loss_pf =  tensor(4156336.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(8.5738, grad_fn=<DotBackward>)\n",
      "step =  391\n",
      "loss_pf =  tensor(4884799., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.3743, grad_fn=<DotBackward>)\n",
      "step =  392\n",
      "loss_pf =  tensor(3936369., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.0490, grad_fn=<DotBackward>)\n",
      "step =  393\n",
      "loss_pf =  tensor(4629445., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.7031, grad_fn=<DotBackward>)\n",
      "step =  394\n",
      "loss_pf =  tensor(4175601., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.7112, grad_fn=<DotBackward>)\n",
      "step =  395\n",
      "loss_pf =  tensor(4142169., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.2778, grad_fn=<DotBackward>)\n",
      "step =  396\n",
      "loss_pf =  tensor(3830008., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.4155, grad_fn=<DotBackward>)\n",
      "step =  397\n",
      "loss_pf =  tensor(3818772., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.9285, grad_fn=<DotBackward>)\n",
      "step =  398\n",
      "loss_pf =  tensor(3473460.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.3562, grad_fn=<DotBackward>)\n",
      "step =  399\n",
      "loss_pf =  tensor(3480430., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.7192, grad_fn=<DotBackward>)\n",
      "step =  400\n",
      "loss_pf =  tensor(3143582., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6646, grad_fn=<DotBackward>)\n",
      "step =  401\n",
      "loss_pf =  tensor(2887602.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4911, grad_fn=<DotBackward>)\n",
      "step =  402\n",
      "loss_pf =  tensor(3089299.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2992, grad_fn=<DotBackward>)\n",
      "step =  403\n",
      "loss_pf =  tensor(3136235., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9924, grad_fn=<DotBackward>)\n",
      "step =  404\n",
      "loss_pf =  tensor(2822778., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8290, grad_fn=<DotBackward>)\n",
      "step =  405\n",
      "loss_pf =  tensor(2954538., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6351, grad_fn=<DotBackward>)\n",
      "step =  406\n",
      "loss_pf =  tensor(2633749., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6847, grad_fn=<DotBackward>)\n",
      "step =  407\n",
      "loss_pf =  tensor(3100495.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.4942, grad_fn=<DotBackward>)\n",
      "step =  408\n",
      "loss_pf =  tensor(2997938., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.4550, grad_fn=<DotBackward>)\n",
      "step =  409\n",
      "loss_pf =  tensor(2757950., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5683, grad_fn=<DotBackward>)\n",
      "step =  410\n",
      "loss_pf =  tensor(2344881.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.3240, grad_fn=<DotBackward>)\n",
      "step =  411\n",
      "loss_pf =  tensor(2504120., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8697, grad_fn=<DotBackward>)\n",
      "step =  412\n",
      "loss_pf =  tensor(2843535.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6152, grad_fn=<DotBackward>)\n",
      "step =  413\n",
      "loss_pf =  tensor(2480173.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.3936, grad_fn=<DotBackward>)\n",
      "step =  414\n",
      "loss_pf =  tensor(2529735., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5684, grad_fn=<DotBackward>)\n",
      "step =  415\n",
      "loss_pf =  tensor(2538383.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7702, grad_fn=<DotBackward>)\n",
      "step =  416\n",
      "loss_pf =  tensor(2318411., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6899, grad_fn=<DotBackward>)\n",
      "step =  417\n",
      "loss_pf =  tensor(2684455., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6542, grad_fn=<DotBackward>)\n",
      "step =  418\n",
      "loss_pf =  tensor(2386358., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6856, grad_fn=<DotBackward>)\n",
      "step =  419\n",
      "loss_pf =  tensor(2313533.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7177, grad_fn=<DotBackward>)\n",
      "step =  420\n",
      "loss_pf =  tensor(2332426.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9540, grad_fn=<DotBackward>)\n",
      "step =  421\n",
      "loss_pf =  tensor(2214469.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9598, grad_fn=<DotBackward>)\n",
      "step =  422\n",
      "loss_pf =  tensor(2164510., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8110, grad_fn=<DotBackward>)\n",
      "step =  423\n",
      "loss_pf =  tensor(2260217., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0126, grad_fn=<DotBackward>)\n",
      "step =  424\n",
      "loss_pf =  tensor(2151958., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9796, grad_fn=<DotBackward>)\n",
      "step =  425\n",
      "loss_pf =  tensor(2327427.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9867, grad_fn=<DotBackward>)\n",
      "step =  426\n",
      "loss_pf =  tensor(2192150.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7776, grad_fn=<DotBackward>)\n",
      "step =  427\n",
      "loss_pf =  tensor(1877311.3750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7575, grad_fn=<DotBackward>)\n",
      "step =  428\n",
      "loss_pf =  tensor(2293127.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9761, grad_fn=<DotBackward>)\n",
      "step =  429\n",
      "loss_pf =  tensor(2183479.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1527, grad_fn=<DotBackward>)\n",
      "step =  430\n",
      "loss_pf =  tensor(2054771.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1797, grad_fn=<DotBackward>)\n",
      "step =  431\n",
      "loss_pf =  tensor(2110269.5000, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_pc =  tensor(2.3332, grad_fn=<DotBackward>)\n",
      "step =  432\n",
      "loss_pf =  tensor(1890255.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5268, grad_fn=<DotBackward>)\n",
      "step =  433\n",
      "loss_pf =  tensor(2286012.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4069, grad_fn=<DotBackward>)\n",
      "step =  434\n",
      "loss_pf =  tensor(2574648.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9978, grad_fn=<DotBackward>)\n",
      "step =  435\n",
      "loss_pf =  tensor(2037335.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1402, grad_fn=<DotBackward>)\n",
      "step =  436\n",
      "loss_pf =  tensor(2254164.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3878, grad_fn=<DotBackward>)\n",
      "step =  437\n",
      "loss_pf =  tensor(2312113.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4526, grad_fn=<DotBackward>)\n",
      "step =  438\n",
      "loss_pf =  tensor(2468337.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2100, grad_fn=<DotBackward>)\n",
      "step =  439\n",
      "loss_pf =  tensor(2024420.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1869, grad_fn=<DotBackward>)\n",
      "step =  440\n",
      "loss_pf =  tensor(2364354., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6733, grad_fn=<DotBackward>)\n",
      "step =  441\n",
      "loss_pf =  tensor(2248521.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.8341, grad_fn=<DotBackward>)\n",
      "step =  442\n",
      "loss_pf =  tensor(2173325.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9603, grad_fn=<DotBackward>)\n",
      "step =  443\n",
      "loss_pf =  tensor(2560717.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0544, grad_fn=<DotBackward>)\n",
      "step =  444\n",
      "loss_pf =  tensor(2567920.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2393, grad_fn=<DotBackward>)\n",
      "step =  445\n",
      "loss_pf =  tensor(2730910.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5311, grad_fn=<DotBackward>)\n",
      "step =  446\n",
      "loss_pf =  tensor(2865827.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.9105, grad_fn=<DotBackward>)\n",
      "step =  447\n",
      "loss_pf =  tensor(3179461., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6969, grad_fn=<DotBackward>)\n",
      "step =  448\n",
      "loss_pf =  tensor(3478267.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.4954, grad_fn=<DotBackward>)\n",
      "step =  449\n",
      "loss_pf =  tensor(3376577.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.0765, grad_fn=<DotBackward>)\n",
      "step =  450\n",
      "loss_pf =  tensor(3356734.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.9390, grad_fn=<DotBackward>)\n",
      "step =  451\n",
      "loss_pf =  tensor(3845778., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.2083, grad_fn=<DotBackward>)\n",
      "step =  452\n",
      "loss_pf =  tensor(4086545., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.5293, grad_fn=<DotBackward>)\n",
      "step =  453\n",
      "loss_pf =  tensor(4275398.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(8.2286, grad_fn=<DotBackward>)\n",
      "step =  454\n",
      "loss_pf =  tensor(4291751., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(10.2370, grad_fn=<DotBackward>)\n",
      "step =  455\n",
      "loss_pf =  tensor(4744031., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(12.0756, grad_fn=<DotBackward>)\n",
      "step =  456\n",
      "loss_pf =  tensor(4494462., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(7.4951, grad_fn=<DotBackward>)\n",
      "step =  457\n",
      "loss_pf =  tensor(4735792., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.9046, grad_fn=<DotBackward>)\n",
      "step =  458\n",
      "loss_pf =  tensor(4142626., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.4065, grad_fn=<DotBackward>)\n",
      "step =  459\n",
      "loss_pf =  tensor(4657589., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(11.2661, grad_fn=<DotBackward>)\n",
      "step =  460\n",
      "loss_pf =  tensor(4028965., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.0486, grad_fn=<DotBackward>)\n",
      "step =  461\n",
      "loss_pf =  tensor(4161030., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(8.0627, grad_fn=<DotBackward>)\n",
      "step =  462\n",
      "loss_pf =  tensor(3927881., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.6929, grad_fn=<DotBackward>)\n",
      "step =  463\n",
      "loss_pf =  tensor(3682829.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.5887, grad_fn=<DotBackward>)\n",
      "step =  464\n",
      "loss_pf =  tensor(3888362., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.8331, grad_fn=<DotBackward>)\n",
      "step =  465\n",
      "loss_pf =  tensor(3520524.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.3679, grad_fn=<DotBackward>)\n",
      "step =  466\n",
      "loss_pf =  tensor(3271417.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6326, grad_fn=<DotBackward>)\n",
      "step =  467\n",
      "loss_pf =  tensor(3060328., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5483, grad_fn=<DotBackward>)\n",
      "step =  468\n",
      "loss_pf =  tensor(2991169.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3260, grad_fn=<DotBackward>)\n",
      "step =  469\n",
      "loss_pf =  tensor(2653326., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2464, grad_fn=<DotBackward>)\n",
      "step =  470\n",
      "loss_pf =  tensor(3151830., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8459, grad_fn=<DotBackward>)\n",
      "step =  471\n",
      "loss_pf =  tensor(3018824.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8554, grad_fn=<DotBackward>)\n",
      "step =  472\n",
      "loss_pf =  tensor(2646362.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6859, grad_fn=<DotBackward>)\n",
      "step =  473\n",
      "loss_pf =  tensor(2556335., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7581, grad_fn=<DotBackward>)\n",
      "step =  474\n",
      "loss_pf =  tensor(2540199.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5741, grad_fn=<DotBackward>)\n",
      "step =  475\n",
      "loss_pf =  tensor(2490221.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7569, grad_fn=<DotBackward>)\n",
      "step =  476\n",
      "loss_pf =  tensor(2572270.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8233, grad_fn=<DotBackward>)\n",
      "step =  477\n",
      "loss_pf =  tensor(2333621., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6455, grad_fn=<DotBackward>)\n",
      "step =  478\n",
      "loss_pf =  tensor(2663522.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.2639, grad_fn=<DotBackward>)\n",
      "step =  479\n",
      "loss_pf =  tensor(2414729.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5613, grad_fn=<DotBackward>)\n",
      "step =  480\n",
      "loss_pf =  tensor(2188006.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6326, grad_fn=<DotBackward>)\n",
      "step =  481\n",
      "loss_pf =  tensor(1870362.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6705, grad_fn=<DotBackward>)\n",
      "step =  482\n",
      "loss_pf =  tensor(2399246., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5229, grad_fn=<DotBackward>)\n",
      "step =  483\n",
      "loss_pf =  tensor(2500543.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6786, grad_fn=<DotBackward>)\n",
      "step =  484\n",
      "loss_pf =  tensor(2505027.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6322, grad_fn=<DotBackward>)\n",
      "step =  485\n",
      "loss_pf =  tensor(2122532.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5844, grad_fn=<DotBackward>)\n",
      "step =  486\n",
      "loss_pf =  tensor(2204667.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.4843, grad_fn=<DotBackward>)\n",
      "step =  487\n",
      "loss_pf =  tensor(2217851.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7712, grad_fn=<DotBackward>)\n",
      "step =  488\n",
      "loss_pf =  tensor(2281172., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6569, grad_fn=<DotBackward>)\n",
      "step =  489\n",
      "loss_pf =  tensor(2156740., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8099, grad_fn=<DotBackward>)\n",
      "step =  490\n",
      "loss_pf =  tensor(2329642., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7068, grad_fn=<DotBackward>)\n",
      "step =  491\n",
      "loss_pf =  tensor(2098765.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7199, grad_fn=<DotBackward>)\n",
      "step =  492\n",
      "loss_pf =  tensor(2526340., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7443, grad_fn=<DotBackward>)\n",
      "step =  493\n",
      "loss_pf =  tensor(2188221., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7659, grad_fn=<DotBackward>)\n",
      "step =  494\n",
      "loss_pf =  tensor(1972471.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9036, grad_fn=<DotBackward>)\n",
      "step =  495\n",
      "loss_pf =  tensor(1882563.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8710, grad_fn=<DotBackward>)\n",
      "step =  496\n",
      "loss_pf =  tensor(2164031.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.4236, grad_fn=<DotBackward>)\n",
      "step =  497\n",
      "loss_pf =  tensor(1985204.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5971, grad_fn=<DotBackward>)\n",
      "step =  498\n",
      "loss_pf =  tensor(1994738., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6633, grad_fn=<DotBackward>)\n",
      "step =  499\n",
      "loss_pf =  tensor(1882018.8750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7768, grad_fn=<DotBackward>)\n",
      "step =  500\n",
      "loss_pf =  tensor(1861526.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7712, grad_fn=<DotBackward>)\n",
      "step =  501\n",
      "loss_pf =  tensor(2025497.8750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7519, grad_fn=<DotBackward>)\n",
      "step =  502\n",
      "loss_pf =  tensor(1640834.8750, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_pc =  tensor(1.4836, grad_fn=<DotBackward>)\n",
      "step =  503\n",
      "loss_pf =  tensor(1844973.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.4748, grad_fn=<DotBackward>)\n",
      "step =  504\n",
      "loss_pf =  tensor(1824289.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7381, grad_fn=<DotBackward>)\n",
      "step =  505\n",
      "loss_pf =  tensor(1653779.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0442, grad_fn=<DotBackward>)\n",
      "step =  506\n",
      "loss_pf =  tensor(1953500.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9772, grad_fn=<DotBackward>)\n",
      "step =  507\n",
      "loss_pf =  tensor(1888586., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0405, grad_fn=<DotBackward>)\n",
      "step =  508\n",
      "loss_pf =  tensor(2128053.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3741, grad_fn=<DotBackward>)\n",
      "step =  509\n",
      "loss_pf =  tensor(1739236.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8703, grad_fn=<DotBackward>)\n",
      "step =  510\n",
      "loss_pf =  tensor(1811889.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7411, grad_fn=<DotBackward>)\n",
      "step =  511\n",
      "loss_pf =  tensor(1713453.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7437, grad_fn=<DotBackward>)\n",
      "step =  512\n",
      "loss_pf =  tensor(2041485.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8725, grad_fn=<DotBackward>)\n",
      "step =  513\n",
      "loss_pf =  tensor(1857023.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2815, grad_fn=<DotBackward>)\n",
      "step =  514\n",
      "loss_pf =  tensor(1776058.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5095, grad_fn=<DotBackward>)\n",
      "step =  515\n",
      "loss_pf =  tensor(1994003.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7629, grad_fn=<DotBackward>)\n",
      "step =  516\n",
      "loss_pf =  tensor(1863206.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6182, grad_fn=<DotBackward>)\n",
      "step =  517\n",
      "loss_pf =  tensor(2260872., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6391, grad_fn=<DotBackward>)\n",
      "step =  518\n",
      "loss_pf =  tensor(2054348.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.0913, grad_fn=<DotBackward>)\n",
      "step =  519\n",
      "loss_pf =  tensor(2204357., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9993, grad_fn=<DotBackward>)\n",
      "step =  520\n",
      "loss_pf =  tensor(2282451., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8862, grad_fn=<DotBackward>)\n",
      "step =  521\n",
      "loss_pf =  tensor(2045852., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2908, grad_fn=<DotBackward>)\n",
      "step =  522\n",
      "loss_pf =  tensor(2815235., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9827, grad_fn=<DotBackward>)\n",
      "step =  523\n",
      "loss_pf =  tensor(2783526.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.9774, grad_fn=<DotBackward>)\n",
      "step =  524\n",
      "loss_pf =  tensor(2893694.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6745, grad_fn=<DotBackward>)\n",
      "step =  525\n",
      "loss_pf =  tensor(3322004.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.3437, grad_fn=<DotBackward>)\n",
      "step =  526\n",
      "loss_pf =  tensor(3737712., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.3361, grad_fn=<DotBackward>)\n",
      "step =  527\n",
      "loss_pf =  tensor(3942553.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.4742, grad_fn=<DotBackward>)\n",
      "step =  528\n",
      "loss_pf =  tensor(4560683., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(7.5167, grad_fn=<DotBackward>)\n",
      "step =  529\n",
      "loss_pf =  tensor(4506082., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(7.5537, grad_fn=<DotBackward>)\n",
      "step =  530\n",
      "loss_pf =  tensor(5127618., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(12.3263, grad_fn=<DotBackward>)\n",
      "step =  531\n",
      "loss_pf =  tensor(5200292.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(13.9449, grad_fn=<DotBackward>)\n",
      "step =  532\n",
      "loss_pf =  tensor(5710880., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(16.7094, grad_fn=<DotBackward>)\n",
      "step =  533\n",
      "loss_pf =  tensor(5446361., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(14.8264, grad_fn=<DotBackward>)\n",
      "step =  534\n",
      "loss_pf =  tensor(5773833.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(17.5157, grad_fn=<DotBackward>)\n",
      "step =  535\n",
      "loss_pf =  tensor(5621761., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(15.5671, grad_fn=<DotBackward>)\n",
      "step =  536\n",
      "loss_pf =  tensor(5577714.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(15.0258, grad_fn=<DotBackward>)\n",
      "step =  537\n",
      "loss_pf =  tensor(4988668., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(11.1912, grad_fn=<DotBackward>)\n",
      "step =  538\n",
      "loss_pf =  tensor(5240162., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(11.4295, grad_fn=<DotBackward>)\n",
      "step =  539\n",
      "loss_pf =  tensor(4547356., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(10.9972, grad_fn=<DotBackward>)\n",
      "step =  540\n",
      "loss_pf =  tensor(4457924., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(8.3542, grad_fn=<DotBackward>)\n",
      "step =  541\n",
      "loss_pf =  tensor(4257250., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.3463, grad_fn=<DotBackward>)\n",
      "step =  542\n",
      "loss_pf =  tensor(4159325.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.3227, grad_fn=<DotBackward>)\n",
      "step =  543\n",
      "loss_pf =  tensor(3874310., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.0330, grad_fn=<DotBackward>)\n",
      "step =  544\n",
      "loss_pf =  tensor(3745620.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5217, grad_fn=<DotBackward>)\n",
      "step =  545\n",
      "loss_pf =  tensor(3311486., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9710, grad_fn=<DotBackward>)\n",
      "step =  546\n",
      "loss_pf =  tensor(3071685.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3432, grad_fn=<DotBackward>)\n",
      "step =  547\n",
      "loss_pf =  tensor(3155663., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6931, grad_fn=<DotBackward>)\n",
      "step =  548\n",
      "loss_pf =  tensor(2983385., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.3377, grad_fn=<DotBackward>)\n",
      "step =  549\n",
      "loss_pf =  tensor(3010367.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1522, grad_fn=<DotBackward>)\n",
      "step =  550\n",
      "loss_pf =  tensor(3043308.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9593, grad_fn=<DotBackward>)\n",
      "step =  551\n",
      "loss_pf =  tensor(2692431.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9453, grad_fn=<DotBackward>)\n",
      "step =  552\n",
      "loss_pf =  tensor(2759747., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5063, grad_fn=<DotBackward>)\n",
      "step =  553\n",
      "loss_pf =  tensor(2367891.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5477, grad_fn=<DotBackward>)\n",
      "step =  554\n",
      "loss_pf =  tensor(2478112., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5108, grad_fn=<DotBackward>)\n",
      "step =  555\n",
      "loss_pf =  tensor(2614233.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6038, grad_fn=<DotBackward>)\n",
      "step =  556\n",
      "loss_pf =  tensor(2519473.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7100, grad_fn=<DotBackward>)\n",
      "step =  557\n",
      "loss_pf =  tensor(2407506.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6883, grad_fn=<DotBackward>)\n",
      "step =  558\n",
      "loss_pf =  tensor(2281222., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5392, grad_fn=<DotBackward>)\n",
      "step =  559\n",
      "loss_pf =  tensor(2117315.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8249, grad_fn=<DotBackward>)\n",
      "step =  560\n",
      "loss_pf =  tensor(2159681.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5895, grad_fn=<DotBackward>)\n",
      "step =  561\n",
      "loss_pf =  tensor(2176665.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.4812, grad_fn=<DotBackward>)\n",
      "step =  562\n",
      "loss_pf =  tensor(1957535.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5494, grad_fn=<DotBackward>)\n",
      "step =  563\n",
      "loss_pf =  tensor(2316438., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6362, grad_fn=<DotBackward>)\n",
      "step =  564\n",
      "loss_pf =  tensor(2104716., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5202, grad_fn=<DotBackward>)\n",
      "step =  565\n",
      "loss_pf =  tensor(2350484.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7697, grad_fn=<DotBackward>)\n",
      "step =  566\n",
      "loss_pf =  tensor(1922693.3750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8243, grad_fn=<DotBackward>)\n",
      "step =  567\n",
      "loss_pf =  tensor(1821788., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.3869, grad_fn=<DotBackward>)\n",
      "step =  568\n",
      "loss_pf =  tensor(1982071.1250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5081, grad_fn=<DotBackward>)\n",
      "step =  569\n",
      "loss_pf =  tensor(1876778.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.3473, grad_fn=<DotBackward>)\n",
      "step =  570\n",
      "loss_pf =  tensor(1926655.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.1718, grad_fn=<DotBackward>)\n",
      "step =  571\n",
      "loss_pf =  tensor(1866352.8750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.4013, grad_fn=<DotBackward>)\n",
      "step =  572\n",
      "loss_pf =  tensor(1839537.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.4827, grad_fn=<DotBackward>)\n",
      "step =  573\n",
      "loss_pf =  tensor(1823560.5000, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_pc =  tensor(1.6819, grad_fn=<DotBackward>)\n",
      "step =  574\n",
      "loss_pf =  tensor(2150046.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8442, grad_fn=<DotBackward>)\n",
      "step =  575\n",
      "loss_pf =  tensor(2082984., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.4956, grad_fn=<DotBackward>)\n",
      "step =  576\n",
      "loss_pf =  tensor(1847446.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5763, grad_fn=<DotBackward>)\n",
      "step =  577\n",
      "loss_pf =  tensor(1974538.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7167, grad_fn=<DotBackward>)\n",
      "step =  578\n",
      "loss_pf =  tensor(2163883.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6675, grad_fn=<DotBackward>)\n",
      "step =  579\n",
      "loss_pf =  tensor(1624888.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.4233, grad_fn=<DotBackward>)\n",
      "step =  580\n",
      "loss_pf =  tensor(1884499.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5719, grad_fn=<DotBackward>)\n",
      "step =  581\n",
      "loss_pf =  tensor(1590752.8750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5296, grad_fn=<DotBackward>)\n",
      "step =  582\n",
      "loss_pf =  tensor(1588242.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7359, grad_fn=<DotBackward>)\n",
      "step =  583\n",
      "loss_pf =  tensor(1634429.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7535, grad_fn=<DotBackward>)\n",
      "step =  584\n",
      "loss_pf =  tensor(1867016.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8524, grad_fn=<DotBackward>)\n",
      "step =  585\n",
      "loss_pf =  tensor(1757383.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9872, grad_fn=<DotBackward>)\n",
      "step =  586\n",
      "loss_pf =  tensor(1577972.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5080, grad_fn=<DotBackward>)\n",
      "step =  587\n",
      "loss_pf =  tensor(1902404.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5023, grad_fn=<DotBackward>)\n",
      "step =  588\n",
      "loss_pf =  tensor(1805494.3750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9194, grad_fn=<DotBackward>)\n",
      "step =  589\n",
      "loss_pf =  tensor(1553472.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5835, grad_fn=<DotBackward>)\n",
      "step =  590\n",
      "loss_pf =  tensor(1540874.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7311, grad_fn=<DotBackward>)\n",
      "step =  591\n",
      "loss_pf =  tensor(1741493., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0135, grad_fn=<DotBackward>)\n",
      "step =  592\n",
      "loss_pf =  tensor(1652581.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1496, grad_fn=<DotBackward>)\n",
      "step =  593\n",
      "loss_pf =  tensor(1773508.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5826, grad_fn=<DotBackward>)\n",
      "step =  594\n",
      "loss_pf =  tensor(1547784.8750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5767, grad_fn=<DotBackward>)\n",
      "step =  595\n",
      "loss_pf =  tensor(1616533.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4324, grad_fn=<DotBackward>)\n",
      "step =  596\n",
      "loss_pf =  tensor(1256312.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4405, grad_fn=<DotBackward>)\n",
      "step =  597\n",
      "loss_pf =  tensor(1775623., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4813, grad_fn=<DotBackward>)\n",
      "step =  598\n",
      "loss_pf =  tensor(1672453.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5010, grad_fn=<DotBackward>)\n",
      "step =  599\n",
      "loss_pf =  tensor(1593927.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5408, grad_fn=<DotBackward>)\n",
      "step =  600\n",
      "loss_pf =  tensor(1390011.3750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4676, grad_fn=<DotBackward>)\n",
      "step =  601\n",
      "loss_pf =  tensor(1458377.8750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5087, grad_fn=<DotBackward>)\n",
      "step =  602\n",
      "loss_pf =  tensor(1571285., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6509, grad_fn=<DotBackward>)\n",
      "step =  603\n",
      "loss_pf =  tensor(1367454.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0139, grad_fn=<DotBackward>)\n",
      "step =  604\n",
      "loss_pf =  tensor(1298963.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0450, grad_fn=<DotBackward>)\n",
      "step =  605\n",
      "loss_pf =  tensor(1448573.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.3043, grad_fn=<DotBackward>)\n",
      "step =  606\n",
      "loss_pf =  tensor(1466672.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.1752, grad_fn=<DotBackward>)\n",
      "step =  607\n",
      "loss_pf =  tensor(1470508.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9472, grad_fn=<DotBackward>)\n",
      "step =  608\n",
      "loss_pf =  tensor(1525952.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2127, grad_fn=<DotBackward>)\n",
      "step =  609\n",
      "loss_pf =  tensor(1746986.3750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6561, grad_fn=<DotBackward>)\n",
      "step =  610\n",
      "loss_pf =  tensor(1597069., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6044, grad_fn=<DotBackward>)\n",
      "step =  611\n",
      "loss_pf =  tensor(1583945.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.7447, grad_fn=<DotBackward>)\n",
      "step =  612\n",
      "loss_pf =  tensor(1621922.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2223, grad_fn=<DotBackward>)\n",
      "step =  613\n",
      "loss_pf =  tensor(1608963.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0788, grad_fn=<DotBackward>)\n",
      "step =  614\n",
      "loss_pf =  tensor(1147545.1250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6727, grad_fn=<DotBackward>)\n",
      "step =  615\n",
      "loss_pf =  tensor(1554810.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.3470, grad_fn=<DotBackward>)\n",
      "step =  616\n",
      "loss_pf =  tensor(1525200.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0741, grad_fn=<DotBackward>)\n",
      "step =  617\n",
      "loss_pf =  tensor(1476497.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0407, grad_fn=<DotBackward>)\n",
      "step =  618\n",
      "loss_pf =  tensor(1578189.1250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9483, grad_fn=<DotBackward>)\n",
      "step =  619\n",
      "loss_pf =  tensor(1623593.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.1865, grad_fn=<DotBackward>)\n",
      "step =  620\n",
      "loss_pf =  tensor(1773063., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0111, grad_fn=<DotBackward>)\n",
      "step =  621\n",
      "loss_pf =  tensor(1589950.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2603, grad_fn=<DotBackward>)\n",
      "step =  622\n",
      "loss_pf =  tensor(1818575.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4075, grad_fn=<DotBackward>)\n",
      "step =  623\n",
      "loss_pf =  tensor(1669261., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.7833, grad_fn=<DotBackward>)\n",
      "step =  624\n",
      "loss_pf =  tensor(2190357.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.9021, grad_fn=<DotBackward>)\n",
      "step =  625\n",
      "loss_pf =  tensor(1880265.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.5950, grad_fn=<DotBackward>)\n",
      "step =  626\n",
      "loss_pf =  tensor(2223936.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.6284, grad_fn=<DotBackward>)\n",
      "step =  627\n",
      "loss_pf =  tensor(2144513.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5969, grad_fn=<DotBackward>)\n",
      "step =  628\n",
      "loss_pf =  tensor(2378083.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5686, grad_fn=<DotBackward>)\n",
      "step =  629\n",
      "loss_pf =  tensor(2604517., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.0260, grad_fn=<DotBackward>)\n",
      "step =  630\n",
      "loss_pf =  tensor(2735887.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0696, grad_fn=<DotBackward>)\n",
      "step =  631\n",
      "loss_pf =  tensor(2951676.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1209, grad_fn=<DotBackward>)\n",
      "step =  632\n",
      "loss_pf =  tensor(2932748., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1034, grad_fn=<DotBackward>)\n",
      "step =  633\n",
      "loss_pf =  tensor(3359318.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9761, grad_fn=<DotBackward>)\n",
      "step =  634\n",
      "loss_pf =  tensor(3357278., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.1147, grad_fn=<DotBackward>)\n",
      "step =  635\n",
      "loss_pf =  tensor(3689045., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.7452, grad_fn=<DotBackward>)\n",
      "step =  636\n",
      "loss_pf =  tensor(4003087.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.3548, grad_fn=<DotBackward>)\n",
      "step =  637\n",
      "loss_pf =  tensor(4082751.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9390, grad_fn=<DotBackward>)\n",
      "step =  638\n",
      "loss_pf =  tensor(4472590.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6195, grad_fn=<DotBackward>)\n",
      "step =  639\n",
      "loss_pf =  tensor(4729371., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.2708, grad_fn=<DotBackward>)\n",
      "step =  640\n",
      "loss_pf =  tensor(4958220., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(10.6519, grad_fn=<DotBackward>)\n",
      "step =  641\n",
      "loss_pf =  tensor(5118980., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.2977, grad_fn=<DotBackward>)\n",
      "step =  642\n",
      "loss_pf =  tensor(5412400., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(8.6274, grad_fn=<DotBackward>)\n",
      "step =  643\n",
      "loss_pf =  tensor(5602013., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.0538, grad_fn=<DotBackward>)\n",
      "step =  644\n",
      "loss_pf =  tensor(6006224., grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_pc =  tensor(10.7530, grad_fn=<DotBackward>)\n",
      "step =  645\n",
      "loss_pf =  tensor(6297200., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(5.8419, grad_fn=<DotBackward>)\n",
      "step =  646\n",
      "loss_pf =  tensor(7031905., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(7.9554, grad_fn=<DotBackward>)\n",
      "step =  647\n",
      "loss_pf =  tensor(7058641., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(11.9346, grad_fn=<DotBackward>)\n",
      "step =  648\n",
      "loss_pf =  tensor(7872949.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(20.0658, grad_fn=<DotBackward>)\n",
      "step =  649\n",
      "loss_pf =  tensor(7524569., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(25.2343, grad_fn=<DotBackward>)\n",
      "step =  650\n",
      "loss_pf =  tensor(9091829., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(46.1211, grad_fn=<DotBackward>)\n",
      "step =  651\n",
      "loss_pf =  tensor(7897878.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(42.4998, grad_fn=<DotBackward>)\n",
      "step =  652\n",
      "loss_pf =  tensor(9169933., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(56.2754, grad_fn=<DotBackward>)\n",
      "step =  653\n",
      "loss_pf =  tensor(7437557., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(29.2933, grad_fn=<DotBackward>)\n",
      "step =  654\n",
      "loss_pf =  tensor(7983979., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(27.7908, grad_fn=<DotBackward>)\n",
      "step =  655\n",
      "loss_pf =  tensor(6931753.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(14.4575, grad_fn=<DotBackward>)\n",
      "step =  656\n",
      "loss_pf =  tensor(6907038., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(16.7643, grad_fn=<DotBackward>)\n",
      "step =  657\n",
      "loss_pf =  tensor(6259435., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(13.5621, grad_fn=<DotBackward>)\n",
      "step =  658\n",
      "loss_pf =  tensor(5784073., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(11.8781, grad_fn=<DotBackward>)\n",
      "step =  659\n",
      "loss_pf =  tensor(5481724.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(9.5954, grad_fn=<DotBackward>)\n",
      "step =  660\n",
      "loss_pf =  tensor(5096966., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(6.5975, grad_fn=<DotBackward>)\n",
      "step =  661\n",
      "loss_pf =  tensor(4813868., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.8819, grad_fn=<DotBackward>)\n",
      "step =  662\n",
      "loss_pf =  tensor(4603972., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.0017, grad_fn=<DotBackward>)\n",
      "step =  663\n",
      "loss_pf =  tensor(4437428., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.2774, grad_fn=<DotBackward>)\n",
      "step =  664\n",
      "loss_pf =  tensor(4366238.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6011, grad_fn=<DotBackward>)\n",
      "step =  665\n",
      "loss_pf =  tensor(3971266., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5209, grad_fn=<DotBackward>)\n",
      "step =  666\n",
      "loss_pf =  tensor(3864527.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.8866, grad_fn=<DotBackward>)\n",
      "step =  667\n",
      "loss_pf =  tensor(3525918., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2968, grad_fn=<DotBackward>)\n",
      "step =  668\n",
      "loss_pf =  tensor(3554545., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4570, grad_fn=<DotBackward>)\n",
      "step =  669\n",
      "loss_pf =  tensor(3311362.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3612, grad_fn=<DotBackward>)\n",
      "step =  670\n",
      "loss_pf =  tensor(3481075., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4083, grad_fn=<DotBackward>)\n",
      "step =  671\n",
      "loss_pf =  tensor(3029348.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7804, grad_fn=<DotBackward>)\n",
      "step =  672\n",
      "loss_pf =  tensor(3059222.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2855, grad_fn=<DotBackward>)\n",
      "step =  673\n",
      "loss_pf =  tensor(3029933.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2113, grad_fn=<DotBackward>)\n",
      "step =  674\n",
      "loss_pf =  tensor(2809412., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3649, grad_fn=<DotBackward>)\n",
      "step =  675\n",
      "loss_pf =  tensor(2859283.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4489, grad_fn=<DotBackward>)\n",
      "step =  676\n",
      "loss_pf =  tensor(2532291., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2522, grad_fn=<DotBackward>)\n",
      "step =  677\n",
      "loss_pf =  tensor(2594592., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0476, grad_fn=<DotBackward>)\n",
      "step =  678\n",
      "loss_pf =  tensor(2299988.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0786, grad_fn=<DotBackward>)\n",
      "step =  679\n",
      "loss_pf =  tensor(2783385., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2090, grad_fn=<DotBackward>)\n",
      "step =  680\n",
      "loss_pf =  tensor(2514006.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1184, grad_fn=<DotBackward>)\n",
      "step =  681\n",
      "loss_pf =  tensor(2405351.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8778, grad_fn=<DotBackward>)\n",
      "step =  682\n",
      "loss_pf =  tensor(2122298., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9517, grad_fn=<DotBackward>)\n",
      "step =  683\n",
      "loss_pf =  tensor(2325499.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1448, grad_fn=<DotBackward>)\n",
      "step =  684\n",
      "loss_pf =  tensor(2190971., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1050, grad_fn=<DotBackward>)\n",
      "step =  685\n",
      "loss_pf =  tensor(2278980., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0227, grad_fn=<DotBackward>)\n",
      "step =  686\n",
      "loss_pf =  tensor(2198205.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8613, grad_fn=<DotBackward>)\n",
      "step =  687\n",
      "loss_pf =  tensor(2093715.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9788, grad_fn=<DotBackward>)\n",
      "step =  688\n",
      "loss_pf =  tensor(1948514., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1943, grad_fn=<DotBackward>)\n",
      "step =  689\n",
      "loss_pf =  tensor(2026661.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0856, grad_fn=<DotBackward>)\n",
      "step =  690\n",
      "loss_pf =  tensor(2005657., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8496, grad_fn=<DotBackward>)\n",
      "step =  691\n",
      "loss_pf =  tensor(2138732., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5968, grad_fn=<DotBackward>)\n",
      "step =  692\n",
      "loss_pf =  tensor(1928291., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5548, grad_fn=<DotBackward>)\n",
      "step =  693\n",
      "loss_pf =  tensor(2144294.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.6063, grad_fn=<DotBackward>)\n",
      "step =  694\n",
      "loss_pf =  tensor(1850367.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0171, grad_fn=<DotBackward>)\n",
      "step =  695\n",
      "loss_pf =  tensor(1786053.1250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9638, grad_fn=<DotBackward>)\n",
      "step =  696\n",
      "loss_pf =  tensor(1929832.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9830, grad_fn=<DotBackward>)\n",
      "step =  697\n",
      "loss_pf =  tensor(1875464., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9219, grad_fn=<DotBackward>)\n",
      "step =  698\n",
      "loss_pf =  tensor(1742620.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9072, grad_fn=<DotBackward>)\n",
      "step =  699\n",
      "loss_pf =  tensor(1691960.3750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0210, grad_fn=<DotBackward>)\n",
      "step =  700\n",
      "loss_pf =  tensor(1562239.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1226, grad_fn=<DotBackward>)\n",
      "step =  701\n",
      "loss_pf =  tensor(1759989.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8959, grad_fn=<DotBackward>)\n",
      "step =  702\n",
      "loss_pf =  tensor(1799070.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2142, grad_fn=<DotBackward>)\n",
      "step =  703\n",
      "loss_pf =  tensor(1641736., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2890, grad_fn=<DotBackward>)\n",
      "step =  704\n",
      "loss_pf =  tensor(1682587.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3149, grad_fn=<DotBackward>)\n",
      "step =  705\n",
      "loss_pf =  tensor(1568439., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2261, grad_fn=<DotBackward>)\n",
      "step =  706\n",
      "loss_pf =  tensor(1602843.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0376, grad_fn=<DotBackward>)\n",
      "step =  707\n",
      "loss_pf =  tensor(1647373.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9397, grad_fn=<DotBackward>)\n",
      "step =  708\n",
      "loss_pf =  tensor(1750926.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1264, grad_fn=<DotBackward>)\n",
      "step =  709\n",
      "loss_pf =  tensor(1776901., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3244, grad_fn=<DotBackward>)\n",
      "step =  710\n",
      "loss_pf =  tensor(1457062.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0030, grad_fn=<DotBackward>)\n",
      "step =  711\n",
      "loss_pf =  tensor(1293373., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.9679, grad_fn=<DotBackward>)\n",
      "step =  712\n",
      "loss_pf =  tensor(1561714., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0441, grad_fn=<DotBackward>)\n",
      "step =  713\n",
      "loss_pf =  tensor(1607621.3750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3606, grad_fn=<DotBackward>)\n",
      "step =  714\n",
      "loss_pf =  tensor(1631341.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5308, grad_fn=<DotBackward>)\n",
      "step =  715\n",
      "loss_pf =  tensor(1372863., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5270, grad_fn=<DotBackward>)\n",
      "step =  716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_pf =  tensor(1501470.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4068, grad_fn=<DotBackward>)\n",
      "step =  717\n",
      "loss_pf =  tensor(1584984.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3644, grad_fn=<DotBackward>)\n",
      "step =  718\n",
      "loss_pf =  tensor(1690943.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5668, grad_fn=<DotBackward>)\n",
      "step =  719\n",
      "loss_pf =  tensor(1763316.8750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3462, grad_fn=<DotBackward>)\n",
      "step =  720\n",
      "loss_pf =  tensor(1507454.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3160, grad_fn=<DotBackward>)\n",
      "step =  721\n",
      "loss_pf =  tensor(1309657.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3794, grad_fn=<DotBackward>)\n",
      "step =  722\n",
      "loss_pf =  tensor(1126659.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6067, grad_fn=<DotBackward>)\n",
      "step =  723\n",
      "loss_pf =  tensor(1279913.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.8600, grad_fn=<DotBackward>)\n",
      "step =  724\n",
      "loss_pf =  tensor(1296524.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6838, grad_fn=<DotBackward>)\n",
      "step =  725\n",
      "loss_pf =  tensor(1325930.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4933, grad_fn=<DotBackward>)\n",
      "step =  726\n",
      "loss_pf =  tensor(1400176.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4606, grad_fn=<DotBackward>)\n",
      "step =  727\n",
      "loss_pf =  tensor(1755157.3750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6015, grad_fn=<DotBackward>)\n",
      "step =  728\n",
      "loss_pf =  tensor(1363876.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7781, grad_fn=<DotBackward>)\n",
      "step =  729\n",
      "loss_pf =  tensor(1424899.3750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.8608, grad_fn=<DotBackward>)\n",
      "step =  730\n",
      "loss_pf =  tensor(1424926., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5666, grad_fn=<DotBackward>)\n",
      "step =  731\n",
      "loss_pf =  tensor(1480582., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4639, grad_fn=<DotBackward>)\n",
      "step =  732\n",
      "loss_pf =  tensor(1345760.1250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4118, grad_fn=<DotBackward>)\n",
      "step =  733\n",
      "loss_pf =  tensor(1352706.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5390, grad_fn=<DotBackward>)\n",
      "step =  734\n",
      "loss_pf =  tensor(1289930.1250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2792, grad_fn=<DotBackward>)\n",
      "step =  735\n",
      "loss_pf =  tensor(1262564.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4461, grad_fn=<DotBackward>)\n",
      "step =  736\n",
      "loss_pf =  tensor(1345280., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9714, grad_fn=<DotBackward>)\n",
      "step =  737\n",
      "loss_pf =  tensor(1296650., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.8796, grad_fn=<DotBackward>)\n",
      "step =  738\n",
      "loss_pf =  tensor(1265317.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5898, grad_fn=<DotBackward>)\n",
      "step =  739\n",
      "loss_pf =  tensor(1433223.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4190, grad_fn=<DotBackward>)\n",
      "step =  740\n",
      "loss_pf =  tensor(1320344.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5443, grad_fn=<DotBackward>)\n",
      "step =  741\n",
      "loss_pf =  tensor(1265378., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5142, grad_fn=<DotBackward>)\n",
      "step =  742\n",
      "loss_pf =  tensor(1278517.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6081, grad_fn=<DotBackward>)\n",
      "step =  743\n",
      "loss_pf =  tensor(1053096.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5134, grad_fn=<DotBackward>)\n",
      "step =  744\n",
      "loss_pf =  tensor(1338909.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4102, grad_fn=<DotBackward>)\n",
      "step =  745\n",
      "loss_pf =  tensor(1241209.3750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4941, grad_fn=<DotBackward>)\n",
      "step =  746\n",
      "loss_pf =  tensor(1221591.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.1856, grad_fn=<DotBackward>)\n",
      "step =  747\n",
      "loss_pf =  tensor(1283007.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.3727, grad_fn=<DotBackward>)\n",
      "step =  748\n",
      "loss_pf =  tensor(1266404.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.7145, grad_fn=<DotBackward>)\n",
      "step =  749\n",
      "loss_pf =  tensor(1404128.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6781, grad_fn=<DotBackward>)\n",
      "step =  750\n",
      "loss_pf =  tensor(990852.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2951, grad_fn=<DotBackward>)\n",
      "step =  751\n",
      "loss_pf =  tensor(1410647.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5176, grad_fn=<DotBackward>)\n",
      "step =  752\n",
      "loss_pf =  tensor(1132426.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2935, grad_fn=<DotBackward>)\n",
      "step =  753\n",
      "loss_pf =  tensor(1123321.3750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.5815, grad_fn=<DotBackward>)\n",
      "step =  754\n",
      "loss_pf =  tensor(1201788., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9781, grad_fn=<DotBackward>)\n",
      "step =  755\n",
      "loss_pf =  tensor(1182453.1250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2614, grad_fn=<DotBackward>)\n",
      "step =  756\n",
      "loss_pf =  tensor(1152584.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9639, grad_fn=<DotBackward>)\n",
      "step =  757\n",
      "loss_pf =  tensor(1307593.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3651, grad_fn=<DotBackward>)\n",
      "step =  758\n",
      "loss_pf =  tensor(1211669.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0155, grad_fn=<DotBackward>)\n",
      "step =  759\n",
      "loss_pf =  tensor(1023713.8750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.1072, grad_fn=<DotBackward>)\n",
      "step =  760\n",
      "loss_pf =  tensor(1176837.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.2689, grad_fn=<DotBackward>)\n",
      "step =  761\n",
      "loss_pf =  tensor(1085396.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.6001, grad_fn=<DotBackward>)\n",
      "step =  762\n",
      "loss_pf =  tensor(1139946.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2323, grad_fn=<DotBackward>)\n",
      "step =  763\n",
      "loss_pf =  tensor(1390901.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.9823, grad_fn=<DotBackward>)\n",
      "step =  764\n",
      "loss_pf =  tensor(1179980.8750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6287, grad_fn=<DotBackward>)\n",
      "step =  765\n",
      "loss_pf =  tensor(998532.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5856, grad_fn=<DotBackward>)\n",
      "step =  766\n",
      "loss_pf =  tensor(920390.1250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6318, grad_fn=<DotBackward>)\n",
      "step =  767\n",
      "loss_pf =  tensor(1270268.6250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6679, grad_fn=<DotBackward>)\n",
      "step =  768\n",
      "loss_pf =  tensor(909938., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5262, grad_fn=<DotBackward>)\n",
      "step =  769\n",
      "loss_pf =  tensor(1173390.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.7216, grad_fn=<DotBackward>)\n",
      "step =  770\n",
      "loss_pf =  tensor(1251278.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.8408, grad_fn=<DotBackward>)\n",
      "step =  771\n",
      "loss_pf =  tensor(1002851., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(1.5264, grad_fn=<DotBackward>)\n",
      "step =  772\n",
      "loss_pf =  tensor(1065921.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0343, grad_fn=<DotBackward>)\n",
      "step =  773\n",
      "loss_pf =  tensor(1048428.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3009, grad_fn=<DotBackward>)\n",
      "step =  774\n",
      "loss_pf =  tensor(1267609.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3576, grad_fn=<DotBackward>)\n",
      "step =  775\n",
      "loss_pf =  tensor(1043942.3125, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.3614, grad_fn=<DotBackward>)\n",
      "step =  776\n",
      "loss_pf =  tensor(1137369., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.1772, grad_fn=<DotBackward>)\n",
      "step =  777\n",
      "loss_pf =  tensor(1061706.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.8469, grad_fn=<DotBackward>)\n",
      "step =  778\n",
      "loss_pf =  tensor(1042134.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0469, grad_fn=<DotBackward>)\n",
      "step =  779\n",
      "loss_pf =  tensor(1165100.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9685, grad_fn=<DotBackward>)\n",
      "step =  780\n",
      "loss_pf =  tensor(1236893.1250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4300, grad_fn=<DotBackward>)\n",
      "step =  781\n",
      "loss_pf =  tensor(1005505.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6020, grad_fn=<DotBackward>)\n",
      "step =  782\n",
      "loss_pf =  tensor(1019967.3750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.3252, grad_fn=<DotBackward>)\n",
      "step =  783\n",
      "loss_pf =  tensor(1049316.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7681, grad_fn=<DotBackward>)\n",
      "step =  784\n",
      "loss_pf =  tensor(1022979., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7199, grad_fn=<DotBackward>)\n",
      "step =  785\n",
      "loss_pf =  tensor(1343231., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.8432, grad_fn=<DotBackward>)\n",
      "step =  786\n",
      "loss_pf =  tensor(1216952.1250, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_pc =  tensor(3.2651, grad_fn=<DotBackward>)\n",
      "step =  787\n",
      "loss_pf =  tensor(1209271.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.1792, grad_fn=<DotBackward>)\n",
      "step =  788\n",
      "loss_pf =  tensor(1283375.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.2330, grad_fn=<DotBackward>)\n",
      "step =  789\n",
      "loss_pf =  tensor(1157871.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.0893, grad_fn=<DotBackward>)\n",
      "step =  790\n",
      "loss_pf =  tensor(1349102.3750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.0366, grad_fn=<DotBackward>)\n",
      "step =  791\n",
      "loss_pf =  tensor(1108545., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.2486, grad_fn=<DotBackward>)\n",
      "step =  792\n",
      "loss_pf =  tensor(1221763.5000, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.7971, grad_fn=<DotBackward>)\n",
      "step =  793\n",
      "loss_pf =  tensor(997515.4375, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.6936, grad_fn=<DotBackward>)\n",
      "step =  794\n",
      "loss_pf =  tensor(1101700., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.4442, grad_fn=<DotBackward>)\n",
      "step =  795\n",
      "loss_pf =  tensor(1202119.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.5913, grad_fn=<DotBackward>)\n",
      "step =  796\n",
      "loss_pf =  tensor(1379955.8750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.0036, grad_fn=<DotBackward>)\n",
      "step =  797\n",
      "loss_pf =  tensor(1278762.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.8377, grad_fn=<DotBackward>)\n",
      "step =  798\n",
      "loss_pf =  tensor(1279912.1250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0717, grad_fn=<DotBackward>)\n",
      "step =  799\n",
      "loss_pf =  tensor(1355026.1250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.7759, grad_fn=<DotBackward>)\n",
      "step =  800\n",
      "loss_pf =  tensor(1380671.8750, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9003, grad_fn=<DotBackward>)\n",
      "step =  801\n",
      "loss_pf =  tensor(1321658.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.8952, grad_fn=<DotBackward>)\n",
      "step =  802\n",
      "loss_pf =  tensor(1376746.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9600, grad_fn=<DotBackward>)\n",
      "step =  803\n",
      "loss_pf =  tensor(1508772.1250, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9280, grad_fn=<DotBackward>)\n",
      "step =  804\n",
      "loss_pf =  tensor(1401772.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.9230, grad_fn=<DotBackward>)\n",
      "step =  805\n",
      "loss_pf =  tensor(1486509.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.4184, grad_fn=<DotBackward>)\n",
      "step =  806\n",
      "loss_pf =  tensor(1650999.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(4.2420, grad_fn=<DotBackward>)\n",
      "step =  807\n",
      "loss_pf =  tensor(1652713.7500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(3.0670, grad_fn=<DotBackward>)\n",
      "step =  808\n",
      "loss_pf =  tensor(1680976., grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.4235, grad_fn=<DotBackward>)\n",
      "step =  809\n",
      "loss_pf =  tensor(1643238.2500, grad_fn=<SubBackward0>)\n",
      "loss_pc =  tensor(2.0602, grad_fn=<DotBackward>)\n",
      "step =  810\n"
     ]
    }
   ],
   "source": [
    "steps = int(1000)\n",
    "for s in range(steps):\n",
    "    print('step = ', s)\n",
    "    batchSamples_pf = torch.multinomial(torch.ones(trainingData.nSamplesIn), model.batchSizeN_pf)\n",
    "    batchSamples_pc = torch.multinomial(torch.ones(trainingData.nSamplesOut), model.batchSizeN_pc)\n",
    "    model.optLatentDistStep()\n",
    "    model.pfStep(batchSamples_pf)\n",
    "    model.pcStep(batchSamples_pc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plotInputReconstruction()\n",
    "f = plt.gcf()\n",
    "f.suptitle('Untrained, N = 1184', fontsize=32, y=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (generative_DR_ROM)",
   "language": "python",
   "name": "pycharm-712517ba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
