{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/constantin/anaconda3/envs/genDRROM/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/constantin/anaconda3/envs/genDRROM/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/constantin/anaconda3/envs/genDRROM/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/constantin/anaconda3/envs/genDRROM/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/constantin/anaconda3/envs/genDRROM/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/constantin/anaconda3/envs/genDRROM/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from poisson_fem import PoissonFEM\n",
    "import ROM\n",
    "import GenerativeSurrogate as gs\n",
    "import Data as dta\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import scipy.sparse.linalg as lg\n",
    "import time\n",
    "import petsc4py\n",
    "import sys\n",
    "petsc4py.init(sys.argv)\n",
    "from petsc4py import PETSc\n",
    "import torch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Some fixed parameters\n",
    "lin_dim_rom = 4                      # Linear number of rom elements\n",
    "a = np.array([1, 2, 3])              # Boundary condition function coefficients\n",
    "dim_z = 30                            # Latent space dimension\n",
    "dtype = torch.float                  # Tensor data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Define mesh and boundary conditions\n",
    "mesh = PoissonFEM.RectangularMesh(np.ones(lin_dim_rom)/lin_dim_rom)\n",
    "# mesh.plot()\n",
    "\n",
    "def origin(x):\n",
    "    return np.abs(x[0]) < np.finfo(float).eps and np.abs(x[1]) < np.finfo(float).eps\n",
    "\n",
    "def essBoundaryFun(x):\n",
    "    return 0.0\n",
    "mesh.setEssentialBoundary(origin, essBoundaryFun)\n",
    "\n",
    "def domainBoundary(x):\n",
    "    # unit square\n",
    "    return np.abs(x[0]) < np.finfo(float).eps or np.abs(x[1]) < np.finfo(float).eps or \\\n",
    "            np.abs(x[0]) > 1.0 - np.finfo(float).eps or np.abs(x[1]) > 1.0 - np.finfo(float).eps\n",
    "mesh.setNaturalBoundary(domainBoundary)\n",
    "\n",
    "def flux(x):\n",
    "    q = np.array([a[0] + a[2]*x[1], a[1] + a[2]*x[0]])\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spepify right hand side and stiffness matrix\n",
    "#Define boundary flux field\n",
    "rhs = PoissonFEM.RightHandSide(mesh)\n",
    "rhs.setNaturalRHS(mesh, flux)\n",
    "funSpace = PoissonFEM.FunctionSpace(mesh)\n",
    "K = PoissonFEM.StiffnessMatrix(mesh, funSpace)\n",
    "rhs.setRhsStencil(mesh, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up solver\n",
    "ksp = PETSc.KSP().create()\n",
    "ksp.setType('preonly')\n",
    "precond = ksp.getPC()\n",
    "precond.setType('cholesky')\n",
    "ksp.setFromOptions() #???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define rom\n",
    "rom = ROM.ROM(mesh, K, rhs, ksp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = dta.StokesData(range(32))\n",
    "trainingData.readData(['IMG'])\n",
    "# trainingData.plotMicrostruct(1)\n",
    "trainingData.reshapeInputImg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f134d64ee50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gs.GenerativeSurrogate(rom, trainingData, dim_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0\n",
      "loss =  tensor(5875348.5000, grad_fn=<SubBackward0>)\n",
      "step =  1\n",
      "loss =  tensor(5874116., grad_fn=<SubBackward0>)\n",
      "step =  2\n",
      "loss =  tensor(5868407., grad_fn=<SubBackward0>)\n",
      "step =  3\n",
      "loss =  tensor(5867252., grad_fn=<SubBackward0>)\n",
      "step =  4\n",
      "loss =  tensor(5867238.5000, grad_fn=<SubBackward0>)\n",
      "step =  5\n",
      "loss =  tensor(5866145., grad_fn=<SubBackward0>)\n",
      "step =  6\n",
      "loss =  tensor(5861843., grad_fn=<SubBackward0>)\n",
      "step =  7\n",
      "loss =  tensor(5862414., grad_fn=<SubBackward0>)\n",
      "step =  8\n",
      "loss =  tensor(5860766., grad_fn=<SubBackward0>)\n",
      "step =  9\n",
      "loss =  tensor(5857771., grad_fn=<SubBackward0>)\n",
      "step =  10\n",
      "loss =  tensor(5855629., grad_fn=<SubBackward0>)\n",
      "step =  11\n",
      "loss =  tensor(5857502.5000, grad_fn=<SubBackward0>)\n",
      "step =  12\n",
      "loss =  tensor(5855002., grad_fn=<SubBackward0>)\n",
      "step =  13\n",
      "loss =  tensor(5852093., grad_fn=<SubBackward0>)\n",
      "step =  14\n",
      "loss =  tensor(5852227.5000, grad_fn=<SubBackward0>)\n",
      "step =  15\n",
      "loss =  tensor(5849658.5000, grad_fn=<SubBackward0>)\n",
      "step =  16\n",
      "loss =  tensor(5849641., grad_fn=<SubBackward0>)\n",
      "step =  17\n",
      "loss =  tensor(5846548.5000, grad_fn=<SubBackward0>)\n",
      "step =  18\n",
      "loss =  tensor(5846177.5000, grad_fn=<SubBackward0>)\n",
      "step =  19\n",
      "loss =  tensor(5845372.5000, grad_fn=<SubBackward0>)\n",
      "step =  20\n",
      "loss =  tensor(5844089.5000, grad_fn=<SubBackward0>)\n",
      "step =  21\n",
      "loss =  tensor(5841152., grad_fn=<SubBackward0>)\n",
      "step =  22\n",
      "loss =  tensor(5840865., grad_fn=<SubBackward0>)\n",
      "step =  23\n",
      "loss =  tensor(5839866., grad_fn=<SubBackward0>)\n",
      "step =  24\n",
      "loss =  tensor(5837414.5000, grad_fn=<SubBackward0>)\n",
      "step =  25\n",
      "loss =  tensor(5836512., grad_fn=<SubBackward0>)\n",
      "step =  26\n",
      "loss =  tensor(5834536.5000, grad_fn=<SubBackward0>)\n",
      "step =  27\n",
      "loss =  tensor(5833100., grad_fn=<SubBackward0>)\n",
      "step =  28\n",
      "loss =  tensor(5831291., grad_fn=<SubBackward0>)\n",
      "step =  29\n",
      "loss =  tensor(5829511., grad_fn=<SubBackward0>)\n",
      "step =  30\n",
      "loss =  tensor(5828221.5000, grad_fn=<SubBackward0>)\n",
      "step =  31\n",
      "loss =  tensor(5827321., grad_fn=<SubBackward0>)\n",
      "step =  32\n",
      "loss =  tensor(5825601., grad_fn=<SubBackward0>)\n",
      "step =  33\n",
      "loss =  tensor(5823875., grad_fn=<SubBackward0>)\n",
      "step =  34\n",
      "loss =  tensor(5821759.5000, grad_fn=<SubBackward0>)\n",
      "step =  35\n",
      "loss =  tensor(5820093., grad_fn=<SubBackward0>)\n",
      "step =  36\n",
      "loss =  tensor(5817922., grad_fn=<SubBackward0>)\n",
      "step =  37\n",
      "loss =  tensor(5816684., grad_fn=<SubBackward0>)\n",
      "step =  38\n",
      "loss =  tensor(5813971., grad_fn=<SubBackward0>)\n",
      "step =  39\n",
      "loss =  tensor(5813046., grad_fn=<SubBackward0>)\n",
      "step =  40\n",
      "loss =  tensor(5810691., grad_fn=<SubBackward0>)\n",
      "step =  41\n",
      "loss =  tensor(5808733.5000, grad_fn=<SubBackward0>)\n",
      "step =  42\n",
      "loss =  tensor(5807974., grad_fn=<SubBackward0>)\n",
      "step =  43\n",
      "loss =  tensor(5806312., grad_fn=<SubBackward0>)\n",
      "step =  44\n",
      "loss =  tensor(5803202.5000, grad_fn=<SubBackward0>)\n",
      "step =  45\n",
      "loss =  tensor(5800263., grad_fn=<SubBackward0>)\n",
      "step =  46\n",
      "loss =  tensor(5799751., grad_fn=<SubBackward0>)\n",
      "step =  47\n",
      "loss =  tensor(5797031., grad_fn=<SubBackward0>)\n",
      "step =  48\n",
      "loss =  tensor(5795431., grad_fn=<SubBackward0>)\n",
      "step =  49\n",
      "loss =  tensor(5791895., grad_fn=<SubBackward0>)\n",
      "step =  50\n",
      "loss =  tensor(5793257., grad_fn=<SubBackward0>)\n",
      "step =  51\n",
      "loss =  tensor(5786166., grad_fn=<SubBackward0>)\n",
      "step =  52\n",
      "loss =  tensor(5786427.5000, grad_fn=<SubBackward0>)\n",
      "step =  53\n",
      "loss =  tensor(5784638.5000, grad_fn=<SubBackward0>)\n",
      "step =  54\n",
      "loss =  tensor(5781943.5000, grad_fn=<SubBackward0>)\n",
      "step =  55\n",
      "loss =  tensor(5779507., grad_fn=<SubBackward0>)\n",
      "step =  56\n",
      "loss =  tensor(5775123., grad_fn=<SubBackward0>)\n",
      "step =  57\n",
      "loss =  tensor(5774136., grad_fn=<SubBackward0>)\n",
      "step =  58\n",
      "loss =  tensor(5770175., grad_fn=<SubBackward0>)\n",
      "step =  59\n",
      "loss =  tensor(5770944., grad_fn=<SubBackward0>)\n",
      "step =  60\n",
      "loss =  tensor(5769753., grad_fn=<SubBackward0>)\n",
      "step =  61\n",
      "loss =  tensor(5761566., grad_fn=<SubBackward0>)\n",
      "step =  62\n",
      "loss =  tensor(5765737.5000, grad_fn=<SubBackward0>)\n",
      "step =  63\n",
      "loss =  tensor(5758359., grad_fn=<SubBackward0>)\n",
      "step =  64\n",
      "loss =  tensor(5758153., grad_fn=<SubBackward0>)\n",
      "step =  65\n",
      "loss =  tensor(5750261., grad_fn=<SubBackward0>)\n",
      "step =  66\n",
      "loss =  tensor(5748884., grad_fn=<SubBackward0>)\n",
      "step =  67\n",
      "loss =  tensor(5749647., grad_fn=<SubBackward0>)\n",
      "step =  68\n",
      "loss =  tensor(5744282., grad_fn=<SubBackward0>)\n",
      "step =  69\n",
      "loss =  tensor(5741410.5000, grad_fn=<SubBackward0>)\n",
      "step =  70\n",
      "loss =  tensor(5743484., grad_fn=<SubBackward0>)\n",
      "step =  71\n",
      "loss =  tensor(5741356., grad_fn=<SubBackward0>)\n",
      "step =  72\n",
      "loss =  tensor(5734012.5000, grad_fn=<SubBackward0>)\n",
      "step =  73\n",
      "loss =  tensor(5740509., grad_fn=<SubBackward0>)\n",
      "step =  74\n",
      "loss =  tensor(5727930., grad_fn=<SubBackward0>)\n",
      "step =  75\n",
      "loss =  tensor(5725197.5000, grad_fn=<SubBackward0>)\n",
      "step =  76\n",
      "loss =  tensor(5723762., grad_fn=<SubBackward0>)\n",
      "step =  77\n",
      "loss =  tensor(5718389., grad_fn=<SubBackward0>)\n",
      "step =  78\n",
      "loss =  tensor(5722307., grad_fn=<SubBackward0>)\n",
      "step =  79\n",
      "loss =  tensor(5716148., grad_fn=<SubBackward0>)\n",
      "step =  80\n",
      "loss =  tensor(5715944., grad_fn=<SubBackward0>)\n",
      "step =  81\n",
      "loss =  tensor(5709227., grad_fn=<SubBackward0>)\n",
      "step =  82\n",
      "loss =  tensor(5713399., grad_fn=<SubBackward0>)\n",
      "step =  83\n",
      "loss =  tensor(5710828., grad_fn=<SubBackward0>)\n",
      "step =  84\n",
      "loss =  tensor(5708011.5000, grad_fn=<SubBackward0>)\n",
      "step =  85\n",
      "loss =  tensor(5710090., grad_fn=<SubBackward0>)\n",
      "step =  86\n",
      "loss =  tensor(5702377.5000, grad_fn=<SubBackward0>)\n",
      "step =  87\n",
      "loss =  tensor(5700826.5000, grad_fn=<SubBackward0>)\n",
      "step =  88\n",
      "loss =  tensor(5701804., grad_fn=<SubBackward0>)\n",
      "step =  89\n",
      "loss =  tensor(5704750.5000, grad_fn=<SubBackward0>)\n",
      "step =  90\n",
      "loss =  tensor(5693264.5000, grad_fn=<SubBackward0>)\n",
      "step =  91\n",
      "loss =  tensor(5689948., grad_fn=<SubBackward0>)\n",
      "step =  92\n",
      "loss =  tensor(5691177., grad_fn=<SubBackward0>)\n",
      "step =  93\n",
      "loss =  tensor(5685164.5000, grad_fn=<SubBackward0>)\n",
      "step =  94\n",
      "loss =  tensor(5686914., grad_fn=<SubBackward0>)\n",
      "step =  95\n",
      "loss =  tensor(5694078.5000, grad_fn=<SubBackward0>)\n",
      "step =  96\n",
      "loss =  tensor(5682670.5000, grad_fn=<SubBackward0>)\n",
      "step =  97\n",
      "loss =  tensor(5678464., grad_fn=<SubBackward0>)\n",
      "step =  98\n",
      "loss =  tensor(5675189., grad_fn=<SubBackward0>)\n",
      "step =  99\n",
      "loss =  tensor(5678860., grad_fn=<SubBackward0>)\n",
      "step =  100\n",
      "loss =  tensor(5671637., grad_fn=<SubBackward0>)\n",
      "step =  101\n",
      "loss =  tensor(5678424., grad_fn=<SubBackward0>)\n",
      "step =  102\n",
      "loss =  tensor(5678780., grad_fn=<SubBackward0>)\n",
      "step =  103\n",
      "loss =  tensor(5675516., grad_fn=<SubBackward0>)\n",
      "step =  104\n",
      "loss =  tensor(5669769., grad_fn=<SubBackward0>)\n",
      "step =  105\n",
      "loss =  tensor(5670677., grad_fn=<SubBackward0>)\n",
      "step =  106\n",
      "loss =  tensor(5658736., grad_fn=<SubBackward0>)\n",
      "step =  107\n",
      "loss =  tensor(5674050., grad_fn=<SubBackward0>)\n",
      "step =  108\n",
      "loss =  tensor(5664312., grad_fn=<SubBackward0>)\n",
      "step =  109\n",
      "loss =  tensor(5668429., grad_fn=<SubBackward0>)\n",
      "step =  110\n",
      "loss =  tensor(5662084., grad_fn=<SubBackward0>)\n",
      "step =  111\n",
      "loss =  tensor(5654531., grad_fn=<SubBackward0>)\n",
      "step =  112\n",
      "loss =  tensor(5650780.5000, grad_fn=<SubBackward0>)\n",
      "step =  113\n",
      "loss =  tensor(5651406., grad_fn=<SubBackward0>)\n",
      "step =  114\n",
      "loss =  tensor(5660321., grad_fn=<SubBackward0>)\n",
      "step =  115\n",
      "loss =  tensor(5653722.5000, grad_fn=<SubBackward0>)\n",
      "step =  116\n",
      "loss =  tensor(5645150., grad_fn=<SubBackward0>)\n",
      "step =  117\n",
      "loss =  tensor(5643405., grad_fn=<SubBackward0>)\n",
      "step =  118\n",
      "loss =  tensor(5641806., grad_fn=<SubBackward0>)\n",
      "step =  119\n",
      "loss =  tensor(5640652., grad_fn=<SubBackward0>)\n",
      "step =  120\n",
      "loss =  tensor(5644912.5000, grad_fn=<SubBackward0>)\n",
      "step =  121\n",
      "loss =  tensor(5642132., grad_fn=<SubBackward0>)\n",
      "step =  122\n",
      "loss =  tensor(5645497., grad_fn=<SubBackward0>)\n",
      "step =  123\n",
      "loss =  tensor(5641782., grad_fn=<SubBackward0>)\n",
      "step =  124\n",
      "loss =  tensor(5635555., grad_fn=<SubBackward0>)\n",
      "step =  125\n",
      "loss =  tensor(5628863., grad_fn=<SubBackward0>)\n",
      "step =  126\n",
      "loss =  tensor(5631117.5000, grad_fn=<SubBackward0>)\n",
      "step =  127\n",
      "loss =  tensor(5637072., grad_fn=<SubBackward0>)\n",
      "step =  128\n",
      "loss =  tensor(5630987., grad_fn=<SubBackward0>)\n",
      "step =  129\n",
      "loss =  tensor(5627486., grad_fn=<SubBackward0>)\n",
      "step =  130\n",
      "loss =  tensor(5628720.5000, grad_fn=<SubBackward0>)\n",
      "step =  131\n",
      "loss =  tensor(5629669., grad_fn=<SubBackward0>)\n",
      "step =  132\n",
      "loss =  tensor(5621696., grad_fn=<SubBackward0>)\n",
      "step =  133\n",
      "loss =  tensor(5630144.5000, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  134\n",
      "loss =  tensor(5617319., grad_fn=<SubBackward0>)\n",
      "step =  135\n",
      "loss =  tensor(5620020., grad_fn=<SubBackward0>)\n",
      "step =  136\n",
      "loss =  tensor(5623093., grad_fn=<SubBackward0>)\n",
      "step =  137\n",
      "loss =  tensor(5613890., grad_fn=<SubBackward0>)\n",
      "step =  138\n",
      "loss =  tensor(5624133.5000, grad_fn=<SubBackward0>)\n",
      "step =  139\n",
      "loss =  tensor(5619156., grad_fn=<SubBackward0>)\n",
      "step =  140\n",
      "loss =  tensor(5610193.5000, grad_fn=<SubBackward0>)\n",
      "step =  141\n",
      "loss =  tensor(5606429., grad_fn=<SubBackward0>)\n",
      "step =  142\n",
      "loss =  tensor(5608740., grad_fn=<SubBackward0>)\n",
      "step =  143\n",
      "loss =  tensor(5616539., grad_fn=<SubBackward0>)\n",
      "step =  144\n",
      "loss =  tensor(5605237., grad_fn=<SubBackward0>)\n",
      "step =  145\n",
      "loss =  tensor(5610547., grad_fn=<SubBackward0>)\n",
      "step =  146\n",
      "loss =  tensor(5599496.5000, grad_fn=<SubBackward0>)\n",
      "step =  147\n",
      "loss =  tensor(5596762., grad_fn=<SubBackward0>)\n",
      "step =  148\n",
      "loss =  tensor(5596705., grad_fn=<SubBackward0>)\n",
      "step =  149\n",
      "loss =  tensor(5594619.5000, grad_fn=<SubBackward0>)\n",
      "step =  150\n",
      "loss =  tensor(5592449.5000, grad_fn=<SubBackward0>)\n",
      "step =  151\n",
      "loss =  tensor(5601265., grad_fn=<SubBackward0>)\n",
      "step =  152\n",
      "loss =  tensor(5581323., grad_fn=<SubBackward0>)\n",
      "step =  153\n",
      "loss =  tensor(5590885., grad_fn=<SubBackward0>)\n",
      "step =  154\n",
      "loss =  tensor(5581036.5000, grad_fn=<SubBackward0>)\n",
      "step =  155\n",
      "loss =  tensor(5593309., grad_fn=<SubBackward0>)\n",
      "step =  156\n",
      "loss =  tensor(5581075.5000, grad_fn=<SubBackward0>)\n",
      "step =  157\n",
      "loss =  tensor(5584315., grad_fn=<SubBackward0>)\n",
      "step =  158\n",
      "loss =  tensor(5578913.5000, grad_fn=<SubBackward0>)\n",
      "step =  159\n",
      "loss =  tensor(5591024.5000, grad_fn=<SubBackward0>)\n",
      "step =  160\n",
      "loss =  tensor(5580454.5000, grad_fn=<SubBackward0>)\n",
      "step =  161\n",
      "loss =  tensor(5590858., grad_fn=<SubBackward0>)\n",
      "step =  162\n",
      "loss =  tensor(5556958.5000, grad_fn=<SubBackward0>)\n",
      "step =  163\n",
      "loss =  tensor(5556345., grad_fn=<SubBackward0>)\n",
      "step =  164\n",
      "loss =  tensor(5571007., grad_fn=<SubBackward0>)\n",
      "step =  165\n",
      "loss =  tensor(5580097., grad_fn=<SubBackward0>)\n",
      "step =  166\n",
      "loss =  tensor(5569547., grad_fn=<SubBackward0>)\n",
      "step =  167\n",
      "loss =  tensor(5567869.5000, grad_fn=<SubBackward0>)\n",
      "step =  168\n",
      "loss =  tensor(5570908., grad_fn=<SubBackward0>)\n",
      "step =  169\n",
      "loss =  tensor(5558876.5000, grad_fn=<SubBackward0>)\n",
      "step =  170\n",
      "loss =  tensor(5554100., grad_fn=<SubBackward0>)\n",
      "step =  171\n",
      "loss =  tensor(5544032., grad_fn=<SubBackward0>)\n",
      "step =  172\n",
      "loss =  tensor(5577082., grad_fn=<SubBackward0>)\n",
      "step =  173\n",
      "loss =  tensor(5572145., grad_fn=<SubBackward0>)\n",
      "step =  174\n",
      "loss =  tensor(5541313., grad_fn=<SubBackward0>)\n",
      "step =  175\n",
      "loss =  tensor(5573823.5000, grad_fn=<SubBackward0>)\n",
      "step =  176\n",
      "loss =  tensor(5532194., grad_fn=<SubBackward0>)\n",
      "step =  177\n",
      "loss =  tensor(5536827.5000, grad_fn=<SubBackward0>)\n",
      "step =  178\n",
      "loss =  tensor(5536898., grad_fn=<SubBackward0>)\n",
      "step =  179\n",
      "loss =  tensor(5525913., grad_fn=<SubBackward0>)\n",
      "step =  180\n",
      "loss =  tensor(5529934., grad_fn=<SubBackward0>)\n",
      "step =  181\n",
      "loss =  tensor(5539046., grad_fn=<SubBackward0>)\n",
      "step =  182\n",
      "loss =  tensor(5550350., grad_fn=<SubBackward0>)\n",
      "step =  183\n",
      "loss =  tensor(5537606.5000, grad_fn=<SubBackward0>)\n",
      "step =  184\n",
      "loss =  tensor(5532730., grad_fn=<SubBackward0>)\n",
      "step =  185\n",
      "loss =  tensor(5529542., grad_fn=<SubBackward0>)\n",
      "step =  186\n",
      "loss =  tensor(5532331., grad_fn=<SubBackward0>)\n",
      "step =  187\n",
      "loss =  tensor(5543481., grad_fn=<SubBackward0>)\n",
      "step =  188\n",
      "loss =  tensor(5544913., grad_fn=<SubBackward0>)\n",
      "step =  189\n",
      "loss =  tensor(5528283., grad_fn=<SubBackward0>)\n",
      "step =  190\n",
      "loss =  tensor(5535105.5000, grad_fn=<SubBackward0>)\n",
      "step =  191\n",
      "loss =  tensor(5534112., grad_fn=<SubBackward0>)\n",
      "step =  192\n",
      "loss =  tensor(5528593., grad_fn=<SubBackward0>)\n",
      "step =  193\n",
      "loss =  tensor(5510987., grad_fn=<SubBackward0>)\n",
      "step =  194\n",
      "loss =  tensor(5551922., grad_fn=<SubBackward0>)\n",
      "step =  195\n",
      "loss =  tensor(5524200., grad_fn=<SubBackward0>)\n",
      "step =  196\n",
      "loss =  tensor(5514561., grad_fn=<SubBackward0>)\n",
      "step =  197\n",
      "loss =  tensor(5523695.5000, grad_fn=<SubBackward0>)\n",
      "step =  198\n",
      "loss =  tensor(5525278., grad_fn=<SubBackward0>)\n",
      "step =  199\n",
      "loss =  tensor(5510271.5000, grad_fn=<SubBackward0>)\n",
      "step =  200\n",
      "loss =  tensor(5519925.5000, grad_fn=<SubBackward0>)\n",
      "step =  201\n",
      "loss =  tensor(5510821., grad_fn=<SubBackward0>)\n",
      "step =  202\n",
      "loss =  tensor(5507827.5000, grad_fn=<SubBackward0>)\n",
      "step =  203\n",
      "loss =  tensor(5505872., grad_fn=<SubBackward0>)\n",
      "step =  204\n",
      "loss =  tensor(5504549., grad_fn=<SubBackward0>)\n",
      "step =  205\n",
      "loss =  tensor(5514450., grad_fn=<SubBackward0>)\n",
      "step =  206\n",
      "loss =  tensor(5501991., grad_fn=<SubBackward0>)\n",
      "step =  207\n",
      "loss =  tensor(5535798.5000, grad_fn=<SubBackward0>)\n",
      "step =  208\n",
      "loss =  tensor(5510366., grad_fn=<SubBackward0>)\n",
      "step =  209\n",
      "loss =  tensor(5525265.5000, grad_fn=<SubBackward0>)\n",
      "step =  210\n",
      "loss =  tensor(5488443., grad_fn=<SubBackward0>)\n",
      "step =  211\n",
      "loss =  tensor(5493786., grad_fn=<SubBackward0>)\n",
      "step =  212\n",
      "loss =  tensor(5507239.5000, grad_fn=<SubBackward0>)\n",
      "step =  213\n",
      "loss =  tensor(5514594., grad_fn=<SubBackward0>)\n",
      "step =  214\n",
      "loss =  tensor(5494741.5000, grad_fn=<SubBackward0>)\n",
      "step =  215\n",
      "loss =  tensor(5524757., grad_fn=<SubBackward0>)\n",
      "step =  216\n",
      "loss =  tensor(5527733., grad_fn=<SubBackward0>)\n",
      "step =  217\n",
      "loss =  tensor(5524510.5000, grad_fn=<SubBackward0>)\n",
      "step =  218\n",
      "loss =  tensor(5503353., grad_fn=<SubBackward0>)\n",
      "step =  219\n",
      "loss =  tensor(5517175., grad_fn=<SubBackward0>)\n",
      "step =  220\n",
      "loss =  tensor(5491632.5000, grad_fn=<SubBackward0>)\n",
      "step =  221\n",
      "loss =  tensor(5523289.5000, grad_fn=<SubBackward0>)\n",
      "step =  222\n",
      "loss =  tensor(5491645., grad_fn=<SubBackward0>)\n",
      "step =  223\n",
      "loss =  tensor(5494059., grad_fn=<SubBackward0>)\n",
      "step =  224\n",
      "loss =  tensor(5508417., grad_fn=<SubBackward0>)\n",
      "step =  225\n",
      "loss =  tensor(5505123.5000, grad_fn=<SubBackward0>)\n",
      "step =  226\n",
      "loss =  tensor(5498274., grad_fn=<SubBackward0>)\n",
      "step =  227\n",
      "loss =  tensor(5508207., grad_fn=<SubBackward0>)\n",
      "step =  228\n",
      "loss =  tensor(5510762., grad_fn=<SubBackward0>)\n",
      "step =  229\n",
      "loss =  tensor(5501164., grad_fn=<SubBackward0>)\n",
      "step =  230\n",
      "loss =  tensor(5500084.5000, grad_fn=<SubBackward0>)\n",
      "step =  231\n",
      "loss =  tensor(5499542., grad_fn=<SubBackward0>)\n",
      "step =  232\n",
      "loss =  tensor(5508583., grad_fn=<SubBackward0>)\n",
      "step =  233\n",
      "loss =  tensor(5500036.5000, grad_fn=<SubBackward0>)\n",
      "step =  234\n",
      "loss =  tensor(5503029., grad_fn=<SubBackward0>)\n",
      "step =  235\n",
      "loss =  tensor(5484630., grad_fn=<SubBackward0>)\n",
      "step =  236\n",
      "loss =  tensor(5493431., grad_fn=<SubBackward0>)\n",
      "step =  237\n",
      "loss =  tensor(5512490.5000, grad_fn=<SubBackward0>)\n",
      "step =  238\n",
      "loss =  tensor(5510063.5000, grad_fn=<SubBackward0>)\n",
      "step =  239\n",
      "loss =  tensor(5505670.5000, grad_fn=<SubBackward0>)\n",
      "step =  240\n",
      "loss =  tensor(5494270., grad_fn=<SubBackward0>)\n",
      "step =  241\n",
      "loss =  tensor(5518290., grad_fn=<SubBackward0>)\n",
      "step =  242\n",
      "loss =  tensor(5510867., grad_fn=<SubBackward0>)\n",
      "step =  243\n",
      "loss =  tensor(5487827., grad_fn=<SubBackward0>)\n",
      "step =  244\n",
      "loss =  tensor(5516228., grad_fn=<SubBackward0>)\n",
      "step =  245\n",
      "loss =  tensor(5484343.5000, grad_fn=<SubBackward0>)\n",
      "step =  246\n",
      "loss =  tensor(5495053., grad_fn=<SubBackward0>)\n",
      "step =  247\n",
      "loss =  tensor(5526210., grad_fn=<SubBackward0>)\n",
      "step =  248\n",
      "loss =  tensor(5502847.5000, grad_fn=<SubBackward0>)\n",
      "step =  249\n",
      "loss =  tensor(5491843., grad_fn=<SubBackward0>)\n",
      "step =  250\n",
      "loss =  tensor(5495215., grad_fn=<SubBackward0>)\n",
      "step =  251\n",
      "loss =  tensor(5496017.5000, grad_fn=<SubBackward0>)\n",
      "step =  252\n",
      "loss =  tensor(5513191., grad_fn=<SubBackward0>)\n",
      "step =  253\n",
      "loss =  tensor(5491655., grad_fn=<SubBackward0>)\n",
      "step =  254\n",
      "loss =  tensor(5507978., grad_fn=<SubBackward0>)\n",
      "step =  255\n",
      "loss =  tensor(5524628.5000, grad_fn=<SubBackward0>)\n",
      "step =  256\n",
      "loss =  tensor(5511023., grad_fn=<SubBackward0>)\n",
      "step =  257\n",
      "loss =  tensor(5487701., grad_fn=<SubBackward0>)\n",
      "step =  258\n",
      "loss =  tensor(5503091., grad_fn=<SubBackward0>)\n",
      "step =  259\n",
      "loss =  tensor(5495861., grad_fn=<SubBackward0>)\n",
      "step =  260\n",
      "loss =  tensor(5484774., grad_fn=<SubBackward0>)\n",
      "step =  261\n",
      "loss =  tensor(5510386.5000, grad_fn=<SubBackward0>)\n",
      "step =  262\n",
      "loss =  tensor(5507052., grad_fn=<SubBackward0>)\n",
      "step =  263\n",
      "loss =  tensor(5532479., grad_fn=<SubBackward0>)\n",
      "step =  264\n",
      "loss =  tensor(5496766., grad_fn=<SubBackward0>)\n",
      "step =  265\n",
      "loss =  tensor(5470315., grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  266\n",
      "loss =  tensor(5508691., grad_fn=<SubBackward0>)\n",
      "step =  267\n",
      "loss =  tensor(5485025., grad_fn=<SubBackward0>)\n",
      "step =  268\n",
      "loss =  tensor(5470435., grad_fn=<SubBackward0>)\n",
      "step =  269\n",
      "loss =  tensor(5483238., grad_fn=<SubBackward0>)\n",
      "step =  270\n",
      "loss =  tensor(5491588., grad_fn=<SubBackward0>)\n",
      "step =  271\n",
      "loss =  tensor(5491281., grad_fn=<SubBackward0>)\n",
      "step =  272\n",
      "loss =  tensor(5497464.5000, grad_fn=<SubBackward0>)\n",
      "step =  273\n",
      "loss =  tensor(5485090., grad_fn=<SubBackward0>)\n",
      "step =  274\n",
      "loss =  tensor(5499498.5000, grad_fn=<SubBackward0>)\n",
      "step =  275\n",
      "loss =  tensor(5483603., grad_fn=<SubBackward0>)\n",
      "step =  276\n",
      "loss =  tensor(5484888., grad_fn=<SubBackward0>)\n",
      "step =  277\n",
      "loss =  tensor(5499669., grad_fn=<SubBackward0>)\n",
      "step =  278\n",
      "loss =  tensor(5488709., grad_fn=<SubBackward0>)\n",
      "step =  279\n",
      "loss =  tensor(5473951.5000, grad_fn=<SubBackward0>)\n",
      "step =  280\n",
      "loss =  tensor(5509757., grad_fn=<SubBackward0>)\n",
      "step =  281\n",
      "loss =  tensor(5493258., grad_fn=<SubBackward0>)\n",
      "step =  282\n",
      "loss =  tensor(5506337.5000, grad_fn=<SubBackward0>)\n",
      "step =  283\n",
      "loss =  tensor(5504026.5000, grad_fn=<SubBackward0>)\n",
      "step =  284\n",
      "loss =  tensor(5513499., grad_fn=<SubBackward0>)\n",
      "step =  285\n",
      "loss =  tensor(5495362., grad_fn=<SubBackward0>)\n",
      "step =  286\n",
      "loss =  tensor(5498014., grad_fn=<SubBackward0>)\n",
      "step =  287\n",
      "loss =  tensor(5504407., grad_fn=<SubBackward0>)\n",
      "step =  288\n",
      "loss =  tensor(5507856., grad_fn=<SubBackward0>)\n",
      "step =  289\n",
      "loss =  tensor(5511320., grad_fn=<SubBackward0>)\n",
      "step =  290\n",
      "loss =  tensor(5502042., grad_fn=<SubBackward0>)\n",
      "step =  291\n",
      "loss =  tensor(5505438., grad_fn=<SubBackward0>)\n",
      "step =  292\n",
      "loss =  tensor(5504936., grad_fn=<SubBackward0>)\n",
      "step =  293\n",
      "loss =  tensor(5504338.5000, grad_fn=<SubBackward0>)\n",
      "step =  294\n",
      "loss =  tensor(5503094., grad_fn=<SubBackward0>)\n",
      "step =  295\n",
      "loss =  tensor(5499012., grad_fn=<SubBackward0>)\n",
      "step =  296\n",
      "loss =  tensor(5491081., grad_fn=<SubBackward0>)\n",
      "step =  297\n",
      "loss =  tensor(5496685., grad_fn=<SubBackward0>)\n",
      "step =  298\n",
      "loss =  tensor(5503771.5000, grad_fn=<SubBackward0>)\n",
      "step =  299\n",
      "loss =  tensor(5481367., grad_fn=<SubBackward0>)\n",
      "step =  300\n",
      "loss =  tensor(5475002.5000, grad_fn=<SubBackward0>)\n",
      "step =  301\n",
      "loss =  tensor(5509695., grad_fn=<SubBackward0>)\n",
      "step =  302\n",
      "loss =  tensor(5511471., grad_fn=<SubBackward0>)\n",
      "step =  303\n",
      "loss =  tensor(5518239., grad_fn=<SubBackward0>)\n",
      "step =  304\n",
      "loss =  tensor(5500698., grad_fn=<SubBackward0>)\n",
      "step =  305\n",
      "loss =  tensor(5515854., grad_fn=<SubBackward0>)\n",
      "step =  306\n",
      "loss =  tensor(5503182., grad_fn=<SubBackward0>)\n",
      "step =  307\n",
      "loss =  tensor(5494988., grad_fn=<SubBackward0>)\n",
      "step =  308\n",
      "loss =  tensor(5502693., grad_fn=<SubBackward0>)\n",
      "step =  309\n",
      "loss =  tensor(5507860., grad_fn=<SubBackward0>)\n",
      "step =  310\n",
      "loss =  tensor(5504905., grad_fn=<SubBackward0>)\n",
      "step =  311\n",
      "loss =  tensor(5511365.5000, grad_fn=<SubBackward0>)\n",
      "step =  312\n",
      "loss =  tensor(5517453., grad_fn=<SubBackward0>)\n",
      "step =  313\n",
      "loss =  tensor(5504012., grad_fn=<SubBackward0>)\n",
      "step =  314\n",
      "loss =  tensor(5504511., grad_fn=<SubBackward0>)\n",
      "step =  315\n",
      "loss =  tensor(5488626., grad_fn=<SubBackward0>)\n",
      "step =  316\n",
      "loss =  tensor(5511820., grad_fn=<SubBackward0>)\n",
      "step =  317\n",
      "loss =  tensor(5493879., grad_fn=<SubBackward0>)\n",
      "step =  318\n",
      "loss =  tensor(5497878.5000, grad_fn=<SubBackward0>)\n",
      "step =  319\n",
      "loss =  tensor(5495316., grad_fn=<SubBackward0>)\n",
      "step =  320\n",
      "loss =  tensor(5520557., grad_fn=<SubBackward0>)\n",
      "step =  321\n",
      "loss =  tensor(5517141., grad_fn=<SubBackward0>)\n",
      "step =  322\n",
      "loss =  tensor(5481986., grad_fn=<SubBackward0>)\n",
      "step =  323\n",
      "loss =  tensor(5485108., grad_fn=<SubBackward0>)\n",
      "step =  324\n",
      "loss =  tensor(5479953., grad_fn=<SubBackward0>)\n",
      "step =  325\n",
      "loss =  tensor(5493772., grad_fn=<SubBackward0>)\n",
      "step =  326\n",
      "loss =  tensor(5504438., grad_fn=<SubBackward0>)\n",
      "step =  327\n",
      "loss =  tensor(5467383., grad_fn=<SubBackward0>)\n",
      "step =  328\n",
      "loss =  tensor(5485226., grad_fn=<SubBackward0>)\n",
      "step =  329\n",
      "loss =  tensor(5501651., grad_fn=<SubBackward0>)\n",
      "step =  330\n",
      "loss =  tensor(5504493., grad_fn=<SubBackward0>)\n",
      "step =  331\n",
      "loss =  tensor(5475191., grad_fn=<SubBackward0>)\n",
      "step =  332\n",
      "loss =  tensor(5496461., grad_fn=<SubBackward0>)\n",
      "step =  333\n",
      "loss =  tensor(5514086., grad_fn=<SubBackward0>)\n",
      "step =  334\n",
      "loss =  tensor(5487120., grad_fn=<SubBackward0>)\n",
      "step =  335\n",
      "loss =  tensor(5494143., grad_fn=<SubBackward0>)\n",
      "step =  336\n",
      "loss =  tensor(5483851., grad_fn=<SubBackward0>)\n",
      "step =  337\n",
      "loss =  tensor(5500104., grad_fn=<SubBackward0>)\n",
      "step =  338\n",
      "loss =  tensor(5478836.5000, grad_fn=<SubBackward0>)\n",
      "step =  339\n",
      "loss =  tensor(5477571., grad_fn=<SubBackward0>)\n",
      "step =  340\n",
      "loss =  tensor(5494108., grad_fn=<SubBackward0>)\n",
      "step =  341\n",
      "loss =  tensor(5514106., grad_fn=<SubBackward0>)\n",
      "step =  342\n",
      "loss =  tensor(5498372., grad_fn=<SubBackward0>)\n",
      "step =  343\n",
      "loss =  tensor(5494460., grad_fn=<SubBackward0>)\n",
      "step =  344\n",
      "loss =  tensor(5480188.5000, grad_fn=<SubBackward0>)\n",
      "step =  345\n",
      "loss =  tensor(5515622., grad_fn=<SubBackward0>)\n",
      "step =  346\n",
      "loss =  tensor(5519970., grad_fn=<SubBackward0>)\n",
      "step =  347\n",
      "loss =  tensor(5478575., grad_fn=<SubBackward0>)\n",
      "step =  348\n",
      "loss =  tensor(5485067., grad_fn=<SubBackward0>)\n",
      "step =  349\n",
      "loss =  tensor(5489632.5000, grad_fn=<SubBackward0>)\n",
      "step =  350\n",
      "loss =  tensor(5488992.5000, grad_fn=<SubBackward0>)\n",
      "step =  351\n",
      "loss =  tensor(5512930., grad_fn=<SubBackward0>)\n",
      "step =  352\n",
      "loss =  tensor(5517200., grad_fn=<SubBackward0>)\n",
      "step =  353\n",
      "loss =  tensor(5497438., grad_fn=<SubBackward0>)\n",
      "step =  354\n",
      "loss =  tensor(5487631., grad_fn=<SubBackward0>)\n",
      "step =  355\n",
      "loss =  tensor(5497101.5000, grad_fn=<SubBackward0>)\n",
      "step =  356\n",
      "loss =  tensor(5489432., grad_fn=<SubBackward0>)\n",
      "step =  357\n",
      "loss =  tensor(5502808., grad_fn=<SubBackward0>)\n",
      "step =  358\n",
      "loss =  tensor(5512712., grad_fn=<SubBackward0>)\n",
      "step =  359\n",
      "loss =  tensor(5513114.5000, grad_fn=<SubBackward0>)\n",
      "step =  360\n",
      "loss =  tensor(5490217., grad_fn=<SubBackward0>)\n",
      "step =  361\n",
      "loss =  tensor(5484342., grad_fn=<SubBackward0>)\n",
      "step =  362\n",
      "loss =  tensor(5492125., grad_fn=<SubBackward0>)\n",
      "step =  363\n",
      "loss =  tensor(5487435., grad_fn=<SubBackward0>)\n",
      "step =  364\n",
      "loss =  tensor(5494752., grad_fn=<SubBackward0>)\n",
      "step =  365\n",
      "loss =  tensor(5495952.5000, grad_fn=<SubBackward0>)\n",
      "step =  366\n",
      "loss =  tensor(5504682.5000, grad_fn=<SubBackward0>)\n",
      "step =  367\n",
      "loss =  tensor(5497626.5000, grad_fn=<SubBackward0>)\n",
      "step =  368\n",
      "loss =  tensor(5490281.5000, grad_fn=<SubBackward0>)\n",
      "step =  369\n",
      "loss =  tensor(5484703., grad_fn=<SubBackward0>)\n",
      "step =  370\n",
      "loss =  tensor(5514328.5000, grad_fn=<SubBackward0>)\n",
      "step =  371\n",
      "loss =  tensor(5498736., grad_fn=<SubBackward0>)\n",
      "step =  372\n",
      "loss =  tensor(5494459.5000, grad_fn=<SubBackward0>)\n",
      "step =  373\n",
      "loss =  tensor(5498754., grad_fn=<SubBackward0>)\n",
      "step =  374\n",
      "loss =  tensor(5490954., grad_fn=<SubBackward0>)\n",
      "step =  375\n",
      "loss =  tensor(5492870., grad_fn=<SubBackward0>)\n",
      "step =  376\n",
      "loss =  tensor(5496496.5000, grad_fn=<SubBackward0>)\n",
      "step =  377\n",
      "loss =  tensor(5496299.5000, grad_fn=<SubBackward0>)\n",
      "step =  378\n",
      "loss =  tensor(5497512., grad_fn=<SubBackward0>)\n",
      "step =  379\n",
      "loss =  tensor(5496936., grad_fn=<SubBackward0>)\n",
      "step =  380\n",
      "loss =  tensor(5497719.5000, grad_fn=<SubBackward0>)\n",
      "step =  381\n",
      "loss =  tensor(5491944., grad_fn=<SubBackward0>)\n",
      "step =  382\n",
      "loss =  tensor(5471425., grad_fn=<SubBackward0>)\n",
      "step =  383\n",
      "loss =  tensor(5477105., grad_fn=<SubBackward0>)\n",
      "step =  384\n",
      "loss =  tensor(5491393., grad_fn=<SubBackward0>)\n",
      "step =  385\n",
      "loss =  tensor(5503059.5000, grad_fn=<SubBackward0>)\n",
      "step =  386\n",
      "loss =  tensor(5500518., grad_fn=<SubBackward0>)\n",
      "step =  387\n",
      "loss =  tensor(5484499., grad_fn=<SubBackward0>)\n",
      "step =  388\n",
      "loss =  tensor(5504512., grad_fn=<SubBackward0>)\n",
      "step =  389\n",
      "loss =  tensor(5492718.5000, grad_fn=<SubBackward0>)\n",
      "step =  390\n",
      "loss =  tensor(5517334., grad_fn=<SubBackward0>)\n",
      "step =  391\n",
      "loss =  tensor(5471995., grad_fn=<SubBackward0>)\n",
      "step =  392\n",
      "loss =  tensor(5487606., grad_fn=<SubBackward0>)\n",
      "step =  393\n",
      "loss =  tensor(5500486.5000, grad_fn=<SubBackward0>)\n",
      "step =  394\n",
      "loss =  tensor(5507374., grad_fn=<SubBackward0>)\n",
      "step =  395\n",
      "loss =  tensor(5498304., grad_fn=<SubBackward0>)\n",
      "step =  396\n",
      "loss =  tensor(5500646., grad_fn=<SubBackward0>)\n",
      "step =  397\n",
      "loss =  tensor(5501802., grad_fn=<SubBackward0>)\n",
      "step =  398\n",
      "loss =  tensor(5475657., grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  399\n",
      "loss =  tensor(5494078.5000, grad_fn=<SubBackward0>)\n",
      "step =  400\n",
      "loss =  tensor(5479059.5000, grad_fn=<SubBackward0>)\n",
      "step =  401\n",
      "loss =  tensor(5493719., grad_fn=<SubBackward0>)\n",
      "step =  402\n",
      "loss =  tensor(5502052., grad_fn=<SubBackward0>)\n",
      "step =  403\n",
      "loss =  tensor(5494269., grad_fn=<SubBackward0>)\n",
      "step =  404\n",
      "loss =  tensor(5493135.5000, grad_fn=<SubBackward0>)\n",
      "step =  405\n",
      "loss =  tensor(5495119., grad_fn=<SubBackward0>)\n",
      "step =  406\n",
      "loss =  tensor(5493347., grad_fn=<SubBackward0>)\n",
      "step =  407\n",
      "loss =  tensor(5479389.5000, grad_fn=<SubBackward0>)\n",
      "step =  408\n",
      "loss =  tensor(5523333., grad_fn=<SubBackward0>)\n",
      "step =  409\n",
      "loss =  tensor(5492214., grad_fn=<SubBackward0>)\n",
      "step =  410\n",
      "loss =  tensor(5488806., grad_fn=<SubBackward0>)\n",
      "step =  411\n",
      "loss =  tensor(5508482.5000, grad_fn=<SubBackward0>)\n",
      "step =  412\n",
      "loss =  tensor(5513101., grad_fn=<SubBackward0>)\n",
      "step =  413\n",
      "loss =  tensor(5489691., grad_fn=<SubBackward0>)\n",
      "step =  414\n",
      "loss =  tensor(5499874.5000, grad_fn=<SubBackward0>)\n",
      "step =  415\n",
      "loss =  tensor(5503387.5000, grad_fn=<SubBackward0>)\n",
      "step =  416\n",
      "loss =  tensor(5486394., grad_fn=<SubBackward0>)\n",
      "step =  417\n",
      "loss =  tensor(5502528., grad_fn=<SubBackward0>)\n",
      "step =  418\n",
      "loss =  tensor(5482689., grad_fn=<SubBackward0>)\n",
      "step =  419\n",
      "loss =  tensor(5489969., grad_fn=<SubBackward0>)\n",
      "step =  420\n",
      "loss =  tensor(5467401.5000, grad_fn=<SubBackward0>)\n",
      "step =  421\n",
      "loss =  tensor(5495568., grad_fn=<SubBackward0>)\n",
      "step =  422\n",
      "loss =  tensor(5490674., grad_fn=<SubBackward0>)\n",
      "step =  423\n",
      "loss =  tensor(5473295., grad_fn=<SubBackward0>)\n",
      "step =  424\n",
      "loss =  tensor(5497770., grad_fn=<SubBackward0>)\n",
      "step =  425\n",
      "loss =  tensor(5504788., grad_fn=<SubBackward0>)\n",
      "step =  426\n",
      "loss =  tensor(5486931., grad_fn=<SubBackward0>)\n",
      "step =  427\n",
      "loss =  tensor(5478159., grad_fn=<SubBackward0>)\n",
      "step =  428\n",
      "loss =  tensor(5501548., grad_fn=<SubBackward0>)\n",
      "step =  429\n",
      "loss =  tensor(5472226., grad_fn=<SubBackward0>)\n",
      "step =  430\n",
      "loss =  tensor(5493648., grad_fn=<SubBackward0>)\n",
      "step =  431\n",
      "loss =  tensor(5521488., grad_fn=<SubBackward0>)\n",
      "step =  432\n",
      "loss =  tensor(5472274.5000, grad_fn=<SubBackward0>)\n",
      "step =  433\n",
      "loss =  tensor(5488164., grad_fn=<SubBackward0>)\n",
      "step =  434\n",
      "loss =  tensor(5488641., grad_fn=<SubBackward0>)\n",
      "step =  435\n",
      "loss =  tensor(5509011., grad_fn=<SubBackward0>)\n",
      "step =  436\n",
      "loss =  tensor(5489298., grad_fn=<SubBackward0>)\n",
      "step =  437\n",
      "loss =  tensor(5491613., grad_fn=<SubBackward0>)\n",
      "step =  438\n",
      "loss =  tensor(5501002., grad_fn=<SubBackward0>)\n",
      "step =  439\n",
      "loss =  tensor(5486000., grad_fn=<SubBackward0>)\n",
      "step =  440\n",
      "loss =  tensor(5509226.5000, grad_fn=<SubBackward0>)\n",
      "step =  441\n",
      "loss =  tensor(5499953., grad_fn=<SubBackward0>)\n",
      "step =  442\n",
      "loss =  tensor(5495944., grad_fn=<SubBackward0>)\n",
      "step =  443\n",
      "loss =  tensor(5511091., grad_fn=<SubBackward0>)\n",
      "step =  444\n",
      "loss =  tensor(5505624., grad_fn=<SubBackward0>)\n",
      "step =  445\n",
      "loss =  tensor(5485264., grad_fn=<SubBackward0>)\n",
      "step =  446\n",
      "loss =  tensor(5494464., grad_fn=<SubBackward0>)\n",
      "step =  447\n",
      "loss =  tensor(5492299., grad_fn=<SubBackward0>)\n",
      "step =  448\n",
      "loss =  tensor(5499356., grad_fn=<SubBackward0>)\n",
      "step =  449\n",
      "loss =  tensor(5502672., grad_fn=<SubBackward0>)\n",
      "step =  450\n",
      "loss =  tensor(5483960., grad_fn=<SubBackward0>)\n",
      "step =  451\n",
      "loss =  tensor(5482972.5000, grad_fn=<SubBackward0>)\n",
      "step =  452\n",
      "loss =  tensor(5492016.5000, grad_fn=<SubBackward0>)\n",
      "step =  453\n",
      "loss =  tensor(5478680., grad_fn=<SubBackward0>)\n",
      "step =  454\n",
      "loss =  tensor(5504191., grad_fn=<SubBackward0>)\n",
      "step =  455\n",
      "loss =  tensor(5487346., grad_fn=<SubBackward0>)\n",
      "step =  456\n",
      "loss =  tensor(5514447.5000, grad_fn=<SubBackward0>)\n",
      "step =  457\n",
      "loss =  tensor(5484386., grad_fn=<SubBackward0>)\n",
      "step =  458\n",
      "loss =  tensor(5501174., grad_fn=<SubBackward0>)\n",
      "step =  459\n",
      "loss =  tensor(5487146., grad_fn=<SubBackward0>)\n",
      "step =  460\n",
      "loss =  tensor(5482626., grad_fn=<SubBackward0>)\n",
      "step =  461\n",
      "loss =  tensor(5480536.5000, grad_fn=<SubBackward0>)\n",
      "step =  462\n",
      "loss =  tensor(5495182.5000, grad_fn=<SubBackward0>)\n",
      "step =  463\n",
      "loss =  tensor(5496887., grad_fn=<SubBackward0>)\n",
      "step =  464\n",
      "loss =  tensor(5490943., grad_fn=<SubBackward0>)\n",
      "step =  465\n",
      "loss =  tensor(5465928., grad_fn=<SubBackward0>)\n",
      "step =  466\n",
      "loss =  tensor(5490448., grad_fn=<SubBackward0>)\n",
      "step =  467\n",
      "loss =  tensor(5508536., grad_fn=<SubBackward0>)\n",
      "step =  468\n",
      "loss =  tensor(5474884., grad_fn=<SubBackward0>)\n",
      "step =  469\n",
      "loss =  tensor(5513977., grad_fn=<SubBackward0>)\n",
      "step =  470\n",
      "loss =  tensor(5501069.5000, grad_fn=<SubBackward0>)\n",
      "step =  471\n",
      "loss =  tensor(5498671., grad_fn=<SubBackward0>)\n",
      "step =  472\n",
      "loss =  tensor(5492265., grad_fn=<SubBackward0>)\n",
      "step =  473\n",
      "loss =  tensor(5489792., grad_fn=<SubBackward0>)\n",
      "step =  474\n",
      "loss =  tensor(5512835., grad_fn=<SubBackward0>)\n",
      "step =  475\n",
      "loss =  tensor(5515526.5000, grad_fn=<SubBackward0>)\n",
      "step =  476\n",
      "loss =  tensor(5491930., grad_fn=<SubBackward0>)\n",
      "step =  477\n",
      "loss =  tensor(5512910., grad_fn=<SubBackward0>)\n",
      "step =  478\n",
      "loss =  tensor(5489780., grad_fn=<SubBackward0>)\n",
      "step =  479\n",
      "loss =  tensor(5466268.5000, grad_fn=<SubBackward0>)\n",
      "step =  480\n",
      "loss =  tensor(5497775., grad_fn=<SubBackward0>)\n",
      "step =  481\n",
      "loss =  tensor(5509988., grad_fn=<SubBackward0>)\n",
      "step =  482\n",
      "loss =  tensor(5488247., grad_fn=<SubBackward0>)\n",
      "step =  483\n",
      "loss =  tensor(5512302., grad_fn=<SubBackward0>)\n",
      "step =  484\n",
      "loss =  tensor(5495509., grad_fn=<SubBackward0>)\n",
      "step =  485\n",
      "loss =  tensor(5473092., grad_fn=<SubBackward0>)\n",
      "step =  486\n",
      "loss =  tensor(5520575., grad_fn=<SubBackward0>)\n",
      "step =  487\n",
      "loss =  tensor(5493912., grad_fn=<SubBackward0>)\n",
      "step =  488\n",
      "loss =  tensor(5496919., grad_fn=<SubBackward0>)\n",
      "step =  489\n",
      "loss =  tensor(5494415., grad_fn=<SubBackward0>)\n",
      "step =  490\n",
      "loss =  tensor(5487676., grad_fn=<SubBackward0>)\n",
      "step =  491\n",
      "loss =  tensor(5502405.5000, grad_fn=<SubBackward0>)\n",
      "step =  492\n",
      "loss =  tensor(5489253., grad_fn=<SubBackward0>)\n",
      "step =  493\n",
      "loss =  tensor(5484585., grad_fn=<SubBackward0>)\n",
      "step =  494\n",
      "loss =  tensor(5495716., grad_fn=<SubBackward0>)\n",
      "step =  495\n",
      "loss =  tensor(5486270., grad_fn=<SubBackward0>)\n",
      "step =  496\n",
      "loss =  tensor(5521113., grad_fn=<SubBackward0>)\n",
      "step =  497\n",
      "loss =  tensor(5495305., grad_fn=<SubBackward0>)\n",
      "step =  498\n",
      "loss =  tensor(5487486.5000, grad_fn=<SubBackward0>)\n",
      "step =  499\n",
      "loss =  tensor(5519447., grad_fn=<SubBackward0>)\n",
      "step =  500\n",
      "loss =  tensor(5513659., grad_fn=<SubBackward0>)\n",
      "step =  501\n",
      "loss =  tensor(5496253., grad_fn=<SubBackward0>)\n",
      "step =  502\n",
      "loss =  tensor(5507907.5000, grad_fn=<SubBackward0>)\n",
      "step =  503\n",
      "loss =  tensor(5485987., grad_fn=<SubBackward0>)\n",
      "step =  504\n",
      "loss =  tensor(5503285.5000, grad_fn=<SubBackward0>)\n",
      "step =  505\n",
      "loss =  tensor(5494362.5000, grad_fn=<SubBackward0>)\n",
      "step =  506\n",
      "loss =  tensor(5480876., grad_fn=<SubBackward0>)\n",
      "step =  507\n",
      "loss =  tensor(5499178.5000, grad_fn=<SubBackward0>)\n",
      "step =  508\n",
      "loss =  tensor(5499087., grad_fn=<SubBackward0>)\n",
      "step =  509\n",
      "loss =  tensor(5482106.5000, grad_fn=<SubBackward0>)\n",
      "step =  510\n",
      "loss =  tensor(5488549.5000, grad_fn=<SubBackward0>)\n",
      "step =  511\n",
      "loss =  tensor(5481028., grad_fn=<SubBackward0>)\n",
      "step =  512\n",
      "loss =  tensor(5494422.5000, grad_fn=<SubBackward0>)\n",
      "step =  513\n",
      "loss =  tensor(5523214., grad_fn=<SubBackward0>)\n",
      "step =  514\n",
      "loss =  tensor(5492002., grad_fn=<SubBackward0>)\n",
      "step =  515\n",
      "loss =  tensor(5495115., grad_fn=<SubBackward0>)\n",
      "step =  516\n",
      "loss =  tensor(5491547., grad_fn=<SubBackward0>)\n",
      "step =  517\n",
      "loss =  tensor(5504220., grad_fn=<SubBackward0>)\n",
      "step =  518\n",
      "loss =  tensor(5488822.5000, grad_fn=<SubBackward0>)\n",
      "step =  519\n",
      "loss =  tensor(5501516.5000, grad_fn=<SubBackward0>)\n",
      "step =  520\n",
      "loss =  tensor(5483896., grad_fn=<SubBackward0>)\n",
      "step =  521\n",
      "loss =  tensor(5491523.5000, grad_fn=<SubBackward0>)\n",
      "step =  522\n",
      "loss =  tensor(5498974., grad_fn=<SubBackward0>)\n",
      "step =  523\n",
      "loss =  tensor(5459647., grad_fn=<SubBackward0>)\n",
      "step =  524\n",
      "loss =  tensor(5504593.5000, grad_fn=<SubBackward0>)\n",
      "step =  525\n",
      "loss =  tensor(5480260., grad_fn=<SubBackward0>)\n",
      "step =  526\n",
      "loss =  tensor(5475783., grad_fn=<SubBackward0>)\n",
      "step =  527\n",
      "loss =  tensor(5498687., grad_fn=<SubBackward0>)\n",
      "step =  528\n",
      "loss =  tensor(5509662.5000, grad_fn=<SubBackward0>)\n",
      "step =  529\n",
      "loss =  tensor(5469447., grad_fn=<SubBackward0>)\n",
      "step =  530\n",
      "loss =  tensor(5513709., grad_fn=<SubBackward0>)\n",
      "step =  531\n",
      "loss =  tensor(5516426., grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  532\n",
      "loss =  tensor(5508096.5000, grad_fn=<SubBackward0>)\n",
      "step =  533\n",
      "loss =  tensor(5484493., grad_fn=<SubBackward0>)\n",
      "step =  534\n",
      "loss =  tensor(5497860., grad_fn=<SubBackward0>)\n",
      "step =  535\n",
      "loss =  tensor(5490672.5000, grad_fn=<SubBackward0>)\n",
      "step =  536\n",
      "loss =  tensor(5478140., grad_fn=<SubBackward0>)\n",
      "step =  537\n",
      "loss =  tensor(5510404., grad_fn=<SubBackward0>)\n",
      "step =  538\n",
      "loss =  tensor(5495801., grad_fn=<SubBackward0>)\n",
      "step =  539\n",
      "loss =  tensor(5473873., grad_fn=<SubBackward0>)\n",
      "step =  540\n",
      "loss =  tensor(5514202., grad_fn=<SubBackward0>)\n",
      "step =  541\n",
      "loss =  tensor(5519607., grad_fn=<SubBackward0>)\n",
      "step =  542\n",
      "loss =  tensor(5496276.5000, grad_fn=<SubBackward0>)\n",
      "step =  543\n",
      "loss =  tensor(5489102., grad_fn=<SubBackward0>)\n",
      "step =  544\n",
      "loss =  tensor(5491633.5000, grad_fn=<SubBackward0>)\n",
      "step =  545\n",
      "loss =  tensor(5486913.5000, grad_fn=<SubBackward0>)\n",
      "step =  546\n",
      "loss =  tensor(5487492., grad_fn=<SubBackward0>)\n",
      "step =  547\n",
      "loss =  tensor(5499970., grad_fn=<SubBackward0>)\n",
      "step =  548\n",
      "loss =  tensor(5506079., grad_fn=<SubBackward0>)\n",
      "step =  549\n",
      "loss =  tensor(5486260.5000, grad_fn=<SubBackward0>)\n",
      "step =  550\n",
      "loss =  tensor(5493544., grad_fn=<SubBackward0>)\n",
      "step =  551\n",
      "loss =  tensor(5514226., grad_fn=<SubBackward0>)\n",
      "step =  552\n",
      "loss =  tensor(5505156., grad_fn=<SubBackward0>)\n",
      "step =  553\n",
      "loss =  tensor(5463737., grad_fn=<SubBackward0>)\n",
      "step =  554\n",
      "loss =  tensor(5474774., grad_fn=<SubBackward0>)\n",
      "step =  555\n",
      "loss =  tensor(5498647., grad_fn=<SubBackward0>)\n",
      "step =  556\n",
      "loss =  tensor(5495929., grad_fn=<SubBackward0>)\n",
      "step =  557\n",
      "loss =  tensor(5480401., grad_fn=<SubBackward0>)\n",
      "step =  558\n",
      "loss =  tensor(5497794., grad_fn=<SubBackward0>)\n",
      "step =  559\n",
      "loss =  tensor(5502479.5000, grad_fn=<SubBackward0>)\n",
      "step =  560\n",
      "loss =  tensor(5509245., grad_fn=<SubBackward0>)\n",
      "step =  561\n",
      "loss =  tensor(5506463., grad_fn=<SubBackward0>)\n",
      "step =  562\n",
      "loss =  tensor(5485394., grad_fn=<SubBackward0>)\n",
      "step =  563\n",
      "loss =  tensor(5504499.5000, grad_fn=<SubBackward0>)\n",
      "step =  564\n",
      "loss =  tensor(5487673., grad_fn=<SubBackward0>)\n",
      "step =  565\n",
      "loss =  tensor(5507161., grad_fn=<SubBackward0>)\n",
      "step =  566\n",
      "loss =  tensor(5487584.5000, grad_fn=<SubBackward0>)\n",
      "step =  567\n",
      "loss =  tensor(5501234.5000, grad_fn=<SubBackward0>)\n",
      "step =  568\n",
      "loss =  tensor(5485081.5000, grad_fn=<SubBackward0>)\n",
      "step =  569\n",
      "loss =  tensor(5503509., grad_fn=<SubBackward0>)\n",
      "step =  570\n",
      "loss =  tensor(5482647., grad_fn=<SubBackward0>)\n",
      "step =  571\n",
      "loss =  tensor(5506872., grad_fn=<SubBackward0>)\n",
      "step =  572\n",
      "loss =  tensor(5491503., grad_fn=<SubBackward0>)\n",
      "step =  573\n",
      "loss =  tensor(5463619.5000, grad_fn=<SubBackward0>)\n",
      "step =  574\n",
      "loss =  tensor(5485777., grad_fn=<SubBackward0>)\n",
      "step =  575\n",
      "loss =  tensor(5500729., grad_fn=<SubBackward0>)\n",
      "step =  576\n",
      "loss =  tensor(5506971.5000, grad_fn=<SubBackward0>)\n",
      "step =  577\n",
      "loss =  tensor(5494140., grad_fn=<SubBackward0>)\n",
      "step =  578\n",
      "loss =  tensor(5493557., grad_fn=<SubBackward0>)\n",
      "step =  579\n",
      "loss =  tensor(5485059., grad_fn=<SubBackward0>)\n",
      "step =  580\n",
      "loss =  tensor(5506440.5000, grad_fn=<SubBackward0>)\n",
      "step =  581\n",
      "loss =  tensor(5489800., grad_fn=<SubBackward0>)\n",
      "step =  582\n",
      "loss =  tensor(5510980.5000, grad_fn=<SubBackward0>)\n",
      "step =  583\n",
      "loss =  tensor(5496941., grad_fn=<SubBackward0>)\n",
      "step =  584\n",
      "loss =  tensor(5489393., grad_fn=<SubBackward0>)\n",
      "step =  585\n",
      "loss =  tensor(5516829., grad_fn=<SubBackward0>)\n",
      "step =  586\n",
      "loss =  tensor(5522025., grad_fn=<SubBackward0>)\n",
      "step =  587\n",
      "loss =  tensor(5471818., grad_fn=<SubBackward0>)\n",
      "step =  588\n",
      "loss =  tensor(5495920.5000, grad_fn=<SubBackward0>)\n",
      "step =  589\n",
      "loss =  tensor(5487520., grad_fn=<SubBackward0>)\n",
      "step =  590\n",
      "loss =  tensor(5511241., grad_fn=<SubBackward0>)\n",
      "step =  591\n",
      "loss =  tensor(5526139., grad_fn=<SubBackward0>)\n",
      "step =  592\n",
      "loss =  tensor(5518584., grad_fn=<SubBackward0>)\n",
      "step =  593\n",
      "loss =  tensor(5479991., grad_fn=<SubBackward0>)\n",
      "step =  594\n",
      "loss =  tensor(5499422.5000, grad_fn=<SubBackward0>)\n",
      "step =  595\n",
      "loss =  tensor(5490484., grad_fn=<SubBackward0>)\n",
      "step =  596\n",
      "loss =  tensor(5497271., grad_fn=<SubBackward0>)\n",
      "step =  597\n",
      "loss =  tensor(5480562., grad_fn=<SubBackward0>)\n",
      "step =  598\n",
      "loss =  tensor(5493964., grad_fn=<SubBackward0>)\n",
      "step =  599\n",
      "loss =  tensor(5485101.5000, grad_fn=<SubBackward0>)\n",
      "step =  600\n",
      "loss =  tensor(5491849., grad_fn=<SubBackward0>)\n",
      "step =  601\n",
      "loss =  tensor(5496111., grad_fn=<SubBackward0>)\n",
      "step =  602\n",
      "loss =  tensor(5487544., grad_fn=<SubBackward0>)\n",
      "step =  603\n",
      "loss =  tensor(5508218., grad_fn=<SubBackward0>)\n",
      "step =  604\n",
      "loss =  tensor(5489829.5000, grad_fn=<SubBackward0>)\n",
      "step =  605\n",
      "loss =  tensor(5507284.5000, grad_fn=<SubBackward0>)\n",
      "step =  606\n",
      "loss =  tensor(5485801., grad_fn=<SubBackward0>)\n",
      "step =  607\n",
      "loss =  tensor(5481198., grad_fn=<SubBackward0>)\n",
      "step =  608\n",
      "loss =  tensor(5484918., grad_fn=<SubBackward0>)\n",
      "step =  609\n",
      "loss =  tensor(5500948., grad_fn=<SubBackward0>)\n",
      "step =  610\n",
      "loss =  tensor(5497927., grad_fn=<SubBackward0>)\n",
      "step =  611\n",
      "loss =  tensor(5499299., grad_fn=<SubBackward0>)\n",
      "step =  612\n",
      "loss =  tensor(5516754.5000, grad_fn=<SubBackward0>)\n",
      "step =  613\n",
      "loss =  tensor(5490400.5000, grad_fn=<SubBackward0>)\n",
      "step =  614\n",
      "loss =  tensor(5487971.5000, grad_fn=<SubBackward0>)\n",
      "step =  615\n",
      "loss =  tensor(5486394., grad_fn=<SubBackward0>)\n",
      "step =  616\n",
      "loss =  tensor(5471461., grad_fn=<SubBackward0>)\n",
      "step =  617\n",
      "loss =  tensor(5508988., grad_fn=<SubBackward0>)\n",
      "step =  618\n",
      "loss =  tensor(5500342.5000, grad_fn=<SubBackward0>)\n",
      "step =  619\n",
      "loss =  tensor(5506978., grad_fn=<SubBackward0>)\n",
      "step =  620\n",
      "loss =  tensor(5493173., grad_fn=<SubBackward0>)\n",
      "step =  621\n",
      "loss =  tensor(5499279.5000, grad_fn=<SubBackward0>)\n",
      "step =  622\n",
      "loss =  tensor(5476721.5000, grad_fn=<SubBackward0>)\n",
      "step =  623\n",
      "loss =  tensor(5494937., grad_fn=<SubBackward0>)\n",
      "step =  624\n",
      "loss =  tensor(5494885., grad_fn=<SubBackward0>)\n",
      "step =  625\n",
      "loss =  tensor(5511756., grad_fn=<SubBackward0>)\n",
      "step =  626\n",
      "loss =  tensor(5502182., grad_fn=<SubBackward0>)\n",
      "step =  627\n",
      "loss =  tensor(5486918., grad_fn=<SubBackward0>)\n",
      "step =  628\n",
      "loss =  tensor(5495274., grad_fn=<SubBackward0>)\n",
      "step =  629\n",
      "loss =  tensor(5481097., grad_fn=<SubBackward0>)\n",
      "step =  630\n",
      "loss =  tensor(5499477., grad_fn=<SubBackward0>)\n",
      "step =  631\n",
      "loss =  tensor(5501747.5000, grad_fn=<SubBackward0>)\n",
      "step =  632\n",
      "loss =  tensor(5471535., grad_fn=<SubBackward0>)\n",
      "step =  633\n",
      "loss =  tensor(5496864.5000, grad_fn=<SubBackward0>)\n",
      "step =  634\n",
      "loss =  tensor(5501222., grad_fn=<SubBackward0>)\n",
      "step =  635\n",
      "loss =  tensor(5503836., grad_fn=<SubBackward0>)\n",
      "step =  636\n",
      "loss =  tensor(5495608., grad_fn=<SubBackward0>)\n",
      "step =  637\n",
      "loss =  tensor(5502004., grad_fn=<SubBackward0>)\n",
      "step =  638\n",
      "loss =  tensor(5500547., grad_fn=<SubBackward0>)\n",
      "step =  639\n",
      "loss =  tensor(5501736., grad_fn=<SubBackward0>)\n",
      "step =  640\n",
      "loss =  tensor(5507435., grad_fn=<SubBackward0>)\n",
      "step =  641\n",
      "loss =  tensor(5478469., grad_fn=<SubBackward0>)\n",
      "step =  642\n",
      "loss =  tensor(5483763.5000, grad_fn=<SubBackward0>)\n",
      "step =  643\n",
      "loss =  tensor(5505205., grad_fn=<SubBackward0>)\n",
      "step =  644\n",
      "loss =  tensor(5486903.5000, grad_fn=<SubBackward0>)\n",
      "step =  645\n",
      "loss =  tensor(5490481., grad_fn=<SubBackward0>)\n",
      "step =  646\n",
      "loss =  tensor(5497195.5000, grad_fn=<SubBackward0>)\n",
      "step =  647\n",
      "loss =  tensor(5516793., grad_fn=<SubBackward0>)\n",
      "step =  648\n",
      "loss =  tensor(5495994.5000, grad_fn=<SubBackward0>)\n",
      "step =  649\n",
      "loss =  tensor(5500975.5000, grad_fn=<SubBackward0>)\n",
      "step =  650\n",
      "loss =  tensor(5491445., grad_fn=<SubBackward0>)\n",
      "step =  651\n",
      "loss =  tensor(5477246., grad_fn=<SubBackward0>)\n",
      "step =  652\n",
      "loss =  tensor(5472845.5000, grad_fn=<SubBackward0>)\n",
      "step =  653\n",
      "loss =  tensor(5481475., grad_fn=<SubBackward0>)\n",
      "step =  654\n",
      "loss =  tensor(5479058., grad_fn=<SubBackward0>)\n",
      "step =  655\n",
      "loss =  tensor(5474832., grad_fn=<SubBackward0>)\n",
      "step =  656\n",
      "loss =  tensor(5482902.5000, grad_fn=<SubBackward0>)\n",
      "step =  657\n",
      "loss =  tensor(5500546.5000, grad_fn=<SubBackward0>)\n",
      "step =  658\n",
      "loss =  tensor(5503956.5000, grad_fn=<SubBackward0>)\n",
      "step =  659\n",
      "loss =  tensor(5502013., grad_fn=<SubBackward0>)\n",
      "step =  660\n",
      "loss =  tensor(5490380.5000, grad_fn=<SubBackward0>)\n",
      "step =  661\n",
      "loss =  tensor(5471009., grad_fn=<SubBackward0>)\n",
      "step =  662\n",
      "loss =  tensor(5486664., grad_fn=<SubBackward0>)\n",
      "step =  663\n",
      "loss =  tensor(5511973., grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  664\n",
      "loss =  tensor(5493020., grad_fn=<SubBackward0>)\n",
      "step =  665\n",
      "loss =  tensor(5498776., grad_fn=<SubBackward0>)\n",
      "step =  666\n",
      "loss =  tensor(5499543., grad_fn=<SubBackward0>)\n",
      "step =  667\n",
      "loss =  tensor(5495804., grad_fn=<SubBackward0>)\n",
      "step =  668\n",
      "loss =  tensor(5477348.5000, grad_fn=<SubBackward0>)\n",
      "step =  669\n",
      "loss =  tensor(5495745.5000, grad_fn=<SubBackward0>)\n",
      "step =  670\n",
      "loss =  tensor(5502734.5000, grad_fn=<SubBackward0>)\n",
      "step =  671\n",
      "loss =  tensor(5495009., grad_fn=<SubBackward0>)\n",
      "step =  672\n",
      "loss =  tensor(5518584., grad_fn=<SubBackward0>)\n",
      "step =  673\n",
      "loss =  tensor(5501463., grad_fn=<SubBackward0>)\n",
      "step =  674\n",
      "loss =  tensor(5512751., grad_fn=<SubBackward0>)\n",
      "step =  675\n",
      "loss =  tensor(5511507., grad_fn=<SubBackward0>)\n",
      "step =  676\n",
      "loss =  tensor(5476037., grad_fn=<SubBackward0>)\n",
      "step =  677\n",
      "loss =  tensor(5485537., grad_fn=<SubBackward0>)\n",
      "step =  678\n",
      "loss =  tensor(5494485., grad_fn=<SubBackward0>)\n",
      "step =  679\n",
      "loss =  tensor(5487185., grad_fn=<SubBackward0>)\n",
      "step =  680\n",
      "loss =  tensor(5511675.5000, grad_fn=<SubBackward0>)\n",
      "step =  681\n",
      "loss =  tensor(5503871., grad_fn=<SubBackward0>)\n",
      "step =  682\n",
      "loss =  tensor(5483654., grad_fn=<SubBackward0>)\n",
      "step =  683\n",
      "loss =  tensor(5522370.5000, grad_fn=<SubBackward0>)\n",
      "step =  684\n",
      "loss =  tensor(5493034., grad_fn=<SubBackward0>)\n",
      "step =  685\n",
      "loss =  tensor(5493502., grad_fn=<SubBackward0>)\n",
      "step =  686\n",
      "loss =  tensor(5487877., grad_fn=<SubBackward0>)\n",
      "step =  687\n",
      "loss =  tensor(5474104., grad_fn=<SubBackward0>)\n",
      "step =  688\n",
      "loss =  tensor(5495244.5000, grad_fn=<SubBackward0>)\n",
      "step =  689\n",
      "loss =  tensor(5490041., grad_fn=<SubBackward0>)\n",
      "step =  690\n",
      "loss =  tensor(5516014.5000, grad_fn=<SubBackward0>)\n",
      "step =  691\n",
      "loss =  tensor(5478204., grad_fn=<SubBackward0>)\n",
      "step =  692\n",
      "loss =  tensor(5491606., grad_fn=<SubBackward0>)\n",
      "step =  693\n",
      "loss =  tensor(5471407., grad_fn=<SubBackward0>)\n",
      "step =  694\n",
      "loss =  tensor(5488954., grad_fn=<SubBackward0>)\n",
      "step =  695\n",
      "loss =  tensor(5506299., grad_fn=<SubBackward0>)\n",
      "step =  696\n",
      "loss =  tensor(5492952., grad_fn=<SubBackward0>)\n",
      "step =  697\n",
      "loss =  tensor(5479119.5000, grad_fn=<SubBackward0>)\n",
      "step =  698\n",
      "loss =  tensor(5492714.5000, grad_fn=<SubBackward0>)\n",
      "step =  699\n",
      "loss =  tensor(5497788.5000, grad_fn=<SubBackward0>)\n",
      "step =  700\n",
      "loss =  tensor(5481859., grad_fn=<SubBackward0>)\n",
      "step =  701\n",
      "loss =  tensor(5498288., grad_fn=<SubBackward0>)\n",
      "step =  702\n",
      "loss =  tensor(5489526., grad_fn=<SubBackward0>)\n",
      "step =  703\n",
      "loss =  tensor(5492456., grad_fn=<SubBackward0>)\n",
      "step =  704\n",
      "loss =  tensor(5485948.5000, grad_fn=<SubBackward0>)\n",
      "step =  705\n",
      "loss =  tensor(5488930., grad_fn=<SubBackward0>)\n",
      "step =  706\n",
      "loss =  tensor(5504425.5000, grad_fn=<SubBackward0>)\n",
      "step =  707\n",
      "loss =  tensor(5501475., grad_fn=<SubBackward0>)\n",
      "step =  708\n",
      "loss =  tensor(5483535., grad_fn=<SubBackward0>)\n",
      "step =  709\n",
      "loss =  tensor(5486435., grad_fn=<SubBackward0>)\n",
      "step =  710\n",
      "loss =  tensor(5491904., grad_fn=<SubBackward0>)\n",
      "step =  711\n",
      "loss =  tensor(5506445.5000, grad_fn=<SubBackward0>)\n",
      "step =  712\n",
      "loss =  tensor(5498804., grad_fn=<SubBackward0>)\n",
      "step =  713\n",
      "loss =  tensor(5475573., grad_fn=<SubBackward0>)\n",
      "step =  714\n",
      "loss =  tensor(5501805.5000, grad_fn=<SubBackward0>)\n",
      "step =  715\n",
      "loss =  tensor(5468741.5000, grad_fn=<SubBackward0>)\n",
      "step =  716\n",
      "loss =  tensor(5481737.5000, grad_fn=<SubBackward0>)\n",
      "step =  717\n",
      "loss =  tensor(5481549.5000, grad_fn=<SubBackward0>)\n",
      "step =  718\n",
      "loss =  tensor(5466505.5000, grad_fn=<SubBackward0>)\n",
      "step =  719\n",
      "loss =  tensor(5509556., grad_fn=<SubBackward0>)\n",
      "step =  720\n",
      "loss =  tensor(5475971.5000, grad_fn=<SubBackward0>)\n",
      "step =  721\n",
      "loss =  tensor(5511171., grad_fn=<SubBackward0>)\n",
      "step =  722\n",
      "loss =  tensor(5500280.5000, grad_fn=<SubBackward0>)\n",
      "step =  723\n",
      "loss =  tensor(5485337., grad_fn=<SubBackward0>)\n",
      "step =  724\n",
      "loss =  tensor(5494466.5000, grad_fn=<SubBackward0>)\n",
      "step =  725\n",
      "loss =  tensor(5481081., grad_fn=<SubBackward0>)\n",
      "step =  726\n",
      "loss =  tensor(5482131., grad_fn=<SubBackward0>)\n",
      "step =  727\n",
      "loss =  tensor(5515358., grad_fn=<SubBackward0>)\n",
      "step =  728\n",
      "loss =  tensor(5487803., grad_fn=<SubBackward0>)\n",
      "step =  729\n",
      "loss =  tensor(5471946.5000, grad_fn=<SubBackward0>)\n",
      "step =  730\n",
      "loss =  tensor(5495704.5000, grad_fn=<SubBackward0>)\n",
      "step =  731\n",
      "loss =  tensor(5495642., grad_fn=<SubBackward0>)\n",
      "step =  732\n",
      "loss =  tensor(5495722.5000, grad_fn=<SubBackward0>)\n",
      "step =  733\n",
      "loss =  tensor(5497512., grad_fn=<SubBackward0>)\n",
      "step =  734\n",
      "loss =  tensor(5491419., grad_fn=<SubBackward0>)\n",
      "step =  735\n",
      "loss =  tensor(5503112., grad_fn=<SubBackward0>)\n",
      "step =  736\n",
      "loss =  tensor(5490710., grad_fn=<SubBackward0>)\n",
      "step =  737\n",
      "loss =  tensor(5510753., grad_fn=<SubBackward0>)\n",
      "step =  738\n",
      "loss =  tensor(5512754., grad_fn=<SubBackward0>)\n",
      "step =  739\n",
      "loss =  tensor(5486267.5000, grad_fn=<SubBackward0>)\n",
      "step =  740\n",
      "loss =  tensor(5486168.5000, grad_fn=<SubBackward0>)\n",
      "step =  741\n",
      "loss =  tensor(5467452.5000, grad_fn=<SubBackward0>)\n",
      "step =  742\n",
      "loss =  tensor(5496986., grad_fn=<SubBackward0>)\n",
      "step =  743\n",
      "loss =  tensor(5509865., grad_fn=<SubBackward0>)\n",
      "step =  744\n",
      "loss =  tensor(5488239., grad_fn=<SubBackward0>)\n",
      "step =  745\n",
      "loss =  tensor(5485515., grad_fn=<SubBackward0>)\n",
      "step =  746\n",
      "loss =  tensor(5489489., grad_fn=<SubBackward0>)\n",
      "step =  747\n",
      "loss =  tensor(5496706.5000, grad_fn=<SubBackward0>)\n",
      "step =  748\n",
      "loss =  tensor(5471548.5000, grad_fn=<SubBackward0>)\n",
      "step =  749\n",
      "loss =  tensor(5503910., grad_fn=<SubBackward0>)\n",
      "step =  750\n",
      "loss =  tensor(5488582., grad_fn=<SubBackward0>)\n",
      "step =  751\n",
      "loss =  tensor(5501678., grad_fn=<SubBackward0>)\n",
      "step =  752\n",
      "loss =  tensor(5484135., grad_fn=<SubBackward0>)\n",
      "step =  753\n",
      "loss =  tensor(5496864., grad_fn=<SubBackward0>)\n",
      "step =  754\n",
      "loss =  tensor(5507776., grad_fn=<SubBackward0>)\n",
      "step =  755\n",
      "loss =  tensor(5471126.5000, grad_fn=<SubBackward0>)\n",
      "step =  756\n",
      "loss =  tensor(5474693., grad_fn=<SubBackward0>)\n",
      "step =  757\n",
      "loss =  tensor(5501065., grad_fn=<SubBackward0>)\n",
      "step =  758\n",
      "loss =  tensor(5491423., grad_fn=<SubBackward0>)\n",
      "step =  759\n",
      "loss =  tensor(5506165., grad_fn=<SubBackward0>)\n",
      "step =  760\n",
      "loss =  tensor(5479645., grad_fn=<SubBackward0>)\n",
      "step =  761\n",
      "loss =  tensor(5476544., grad_fn=<SubBackward0>)\n",
      "step =  762\n",
      "loss =  tensor(5494552., grad_fn=<SubBackward0>)\n",
      "step =  763\n",
      "loss =  tensor(5498500.5000, grad_fn=<SubBackward0>)\n",
      "step =  764\n",
      "loss =  tensor(5491541., grad_fn=<SubBackward0>)\n",
      "step =  765\n",
      "loss =  tensor(5523627., grad_fn=<SubBackward0>)\n",
      "step =  766\n",
      "loss =  tensor(5483739., grad_fn=<SubBackward0>)\n",
      "step =  767\n",
      "loss =  tensor(5489810., grad_fn=<SubBackward0>)\n",
      "step =  768\n",
      "loss =  tensor(5483453., grad_fn=<SubBackward0>)\n",
      "step =  769\n",
      "loss =  tensor(5497883., grad_fn=<SubBackward0>)\n",
      "step =  770\n",
      "loss =  tensor(5488720., grad_fn=<SubBackward0>)\n",
      "step =  771\n",
      "loss =  tensor(5486928., grad_fn=<SubBackward0>)\n",
      "step =  772\n",
      "loss =  tensor(5515529.5000, grad_fn=<SubBackward0>)\n",
      "step =  773\n",
      "loss =  tensor(5491145., grad_fn=<SubBackward0>)\n",
      "step =  774\n",
      "loss =  tensor(5471963., grad_fn=<SubBackward0>)\n",
      "step =  775\n",
      "loss =  tensor(5471998., grad_fn=<SubBackward0>)\n",
      "step =  776\n",
      "loss =  tensor(5490023.5000, grad_fn=<SubBackward0>)\n",
      "step =  777\n",
      "loss =  tensor(5475216., grad_fn=<SubBackward0>)\n",
      "step =  778\n",
      "loss =  tensor(5484885., grad_fn=<SubBackward0>)\n",
      "step =  779\n",
      "loss =  tensor(5497307.5000, grad_fn=<SubBackward0>)\n",
      "step =  780\n",
      "loss =  tensor(5500381., grad_fn=<SubBackward0>)\n",
      "step =  781\n",
      "loss =  tensor(5487006., grad_fn=<SubBackward0>)\n",
      "step =  782\n",
      "loss =  tensor(5469148., grad_fn=<SubBackward0>)\n",
      "step =  783\n",
      "loss =  tensor(5495740., grad_fn=<SubBackward0>)\n",
      "step =  784\n",
      "loss =  tensor(5482970., grad_fn=<SubBackward0>)\n",
      "step =  785\n",
      "loss =  tensor(5489262., grad_fn=<SubBackward0>)\n",
      "step =  786\n",
      "loss =  tensor(5484760.5000, grad_fn=<SubBackward0>)\n",
      "step =  787\n",
      "loss =  tensor(5483813., grad_fn=<SubBackward0>)\n",
      "step =  788\n",
      "loss =  tensor(5492233., grad_fn=<SubBackward0>)\n",
      "step =  789\n",
      "loss =  tensor(5495716., grad_fn=<SubBackward0>)\n",
      "step =  790\n",
      "loss =  tensor(5489710., grad_fn=<SubBackward0>)\n",
      "step =  791\n",
      "loss =  tensor(5484696., grad_fn=<SubBackward0>)\n",
      "step =  792\n",
      "loss =  tensor(5499945.5000, grad_fn=<SubBackward0>)\n",
      "step =  793\n",
      "loss =  tensor(5489748.5000, grad_fn=<SubBackward0>)\n",
      "step =  794\n",
      "loss =  tensor(5479763., grad_fn=<SubBackward0>)\n",
      "step =  795\n",
      "loss =  tensor(5467777.5000, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  796\n",
      "loss =  tensor(5494637., grad_fn=<SubBackward0>)\n",
      "step =  797\n",
      "loss =  tensor(5476044., grad_fn=<SubBackward0>)\n",
      "step =  798\n",
      "loss =  tensor(5473361., grad_fn=<SubBackward0>)\n",
      "step =  799\n",
      "loss =  tensor(5479745., grad_fn=<SubBackward0>)\n",
      "step =  800\n",
      "loss =  tensor(5491194.5000, grad_fn=<SubBackward0>)\n",
      "step =  801\n",
      "loss =  tensor(5472421., grad_fn=<SubBackward0>)\n",
      "step =  802\n",
      "loss =  tensor(5517694.5000, grad_fn=<SubBackward0>)\n",
      "step =  803\n",
      "loss =  tensor(5499537., grad_fn=<SubBackward0>)\n",
      "step =  804\n",
      "loss =  tensor(5490162., grad_fn=<SubBackward0>)\n",
      "step =  805\n",
      "loss =  tensor(5494218., grad_fn=<SubBackward0>)\n",
      "step =  806\n",
      "loss =  tensor(5472099., grad_fn=<SubBackward0>)\n",
      "step =  807\n",
      "loss =  tensor(5453737.5000, grad_fn=<SubBackward0>)\n",
      "step =  808\n",
      "loss =  tensor(5490777.5000, grad_fn=<SubBackward0>)\n",
      "step =  809\n",
      "loss =  tensor(5449042.5000, grad_fn=<SubBackward0>)\n",
      "step =  810\n",
      "loss =  tensor(5489872., grad_fn=<SubBackward0>)\n",
      "step =  811\n",
      "loss =  tensor(5479272., grad_fn=<SubBackward0>)\n",
      "step =  812\n",
      "loss =  tensor(5491136.5000, grad_fn=<SubBackward0>)\n",
      "step =  813\n",
      "loss =  tensor(5498688., grad_fn=<SubBackward0>)\n",
      "step =  814\n",
      "loss =  tensor(5475031., grad_fn=<SubBackward0>)\n",
      "step =  815\n",
      "loss =  tensor(5474991.5000, grad_fn=<SubBackward0>)\n",
      "step =  816\n",
      "loss =  tensor(5498834.5000, grad_fn=<SubBackward0>)\n",
      "step =  817\n",
      "loss =  tensor(5533742.5000, grad_fn=<SubBackward0>)\n",
      "step =  818\n",
      "loss =  tensor(5482385., grad_fn=<SubBackward0>)\n",
      "step =  819\n",
      "loss =  tensor(5464221.5000, grad_fn=<SubBackward0>)\n",
      "step =  820\n",
      "loss =  tensor(5506549., grad_fn=<SubBackward0>)\n",
      "step =  821\n",
      "loss =  tensor(5498344., grad_fn=<SubBackward0>)\n",
      "step =  822\n",
      "loss =  tensor(5475070., grad_fn=<SubBackward0>)\n",
      "step =  823\n",
      "loss =  tensor(5505340.5000, grad_fn=<SubBackward0>)\n",
      "step =  824\n",
      "loss =  tensor(5503736.5000, grad_fn=<SubBackward0>)\n",
      "step =  825\n",
      "loss =  tensor(5486499.5000, grad_fn=<SubBackward0>)\n",
      "step =  826\n",
      "loss =  tensor(5486748., grad_fn=<SubBackward0>)\n",
      "step =  827\n",
      "loss =  tensor(5471360., grad_fn=<SubBackward0>)\n",
      "step =  828\n",
      "loss =  tensor(5494575.5000, grad_fn=<SubBackward0>)\n",
      "step =  829\n",
      "loss =  tensor(5497232.5000, grad_fn=<SubBackward0>)\n",
      "step =  830\n",
      "loss =  tensor(5494565., grad_fn=<SubBackward0>)\n",
      "step =  831\n",
      "loss =  tensor(5486666., grad_fn=<SubBackward0>)\n",
      "step =  832\n",
      "loss =  tensor(5480642., grad_fn=<SubBackward0>)\n",
      "step =  833\n",
      "loss =  tensor(5497324.5000, grad_fn=<SubBackward0>)\n",
      "step =  834\n",
      "loss =  tensor(5465231., grad_fn=<SubBackward0>)\n",
      "step =  835\n",
      "loss =  tensor(5478154., grad_fn=<SubBackward0>)\n",
      "step =  836\n",
      "loss =  tensor(5489370., grad_fn=<SubBackward0>)\n",
      "step =  837\n",
      "loss =  tensor(5461708.5000, grad_fn=<SubBackward0>)\n",
      "step =  838\n",
      "loss =  tensor(5501547., grad_fn=<SubBackward0>)\n",
      "step =  839\n",
      "loss =  tensor(5482973., grad_fn=<SubBackward0>)\n",
      "step =  840\n",
      "loss =  tensor(5484103.5000, grad_fn=<SubBackward0>)\n",
      "step =  841\n",
      "loss =  tensor(5467411., grad_fn=<SubBackward0>)\n",
      "step =  842\n",
      "loss =  tensor(5510151., grad_fn=<SubBackward0>)\n",
      "step =  843\n",
      "loss =  tensor(5505502., grad_fn=<SubBackward0>)\n",
      "step =  844\n",
      "loss =  tensor(5502577., grad_fn=<SubBackward0>)\n",
      "step =  845\n",
      "loss =  tensor(5502210., grad_fn=<SubBackward0>)\n",
      "step =  846\n",
      "loss =  tensor(5496199.5000, grad_fn=<SubBackward0>)\n",
      "step =  847\n",
      "loss =  tensor(5489688., grad_fn=<SubBackward0>)\n",
      "step =  848\n",
      "loss =  tensor(5509333., grad_fn=<SubBackward0>)\n",
      "step =  849\n",
      "loss =  tensor(5493030., grad_fn=<SubBackward0>)\n",
      "step =  850\n",
      "loss =  tensor(5496038., grad_fn=<SubBackward0>)\n",
      "step =  851\n",
      "loss =  tensor(5487242.5000, grad_fn=<SubBackward0>)\n",
      "step =  852\n",
      "loss =  tensor(5508524.5000, grad_fn=<SubBackward0>)\n",
      "step =  853\n",
      "loss =  tensor(5476770., grad_fn=<SubBackward0>)\n",
      "step =  854\n",
      "loss =  tensor(5481170., grad_fn=<SubBackward0>)\n",
      "step =  855\n",
      "loss =  tensor(5499227., grad_fn=<SubBackward0>)\n",
      "step =  856\n",
      "loss =  tensor(5493764., grad_fn=<SubBackward0>)\n",
      "step =  857\n",
      "loss =  tensor(5480417.5000, grad_fn=<SubBackward0>)\n",
      "step =  858\n",
      "loss =  tensor(5489279., grad_fn=<SubBackward0>)\n",
      "step =  859\n",
      "loss =  tensor(5483172.5000, grad_fn=<SubBackward0>)\n",
      "step =  860\n",
      "loss =  tensor(5469311., grad_fn=<SubBackward0>)\n",
      "step =  861\n",
      "loss =  tensor(5469342.5000, grad_fn=<SubBackward0>)\n",
      "step =  862\n",
      "loss =  tensor(5467874., grad_fn=<SubBackward0>)\n",
      "step =  863\n",
      "loss =  tensor(5450035., grad_fn=<SubBackward0>)\n",
      "step =  864\n",
      "loss =  tensor(5475592.5000, grad_fn=<SubBackward0>)\n",
      "step =  865\n",
      "loss =  tensor(5487328., grad_fn=<SubBackward0>)\n",
      "step =  866\n",
      "loss =  tensor(5467705.5000, grad_fn=<SubBackward0>)\n",
      "step =  867\n",
      "loss =  tensor(5515106., grad_fn=<SubBackward0>)\n",
      "step =  868\n",
      "loss =  tensor(5501921., grad_fn=<SubBackward0>)\n",
      "step =  869\n",
      "loss =  tensor(5451131., grad_fn=<SubBackward0>)\n",
      "step =  870\n",
      "loss =  tensor(5512943., grad_fn=<SubBackward0>)\n",
      "step =  871\n",
      "loss =  tensor(5498004., grad_fn=<SubBackward0>)\n",
      "step =  872\n",
      "loss =  tensor(5518236., grad_fn=<SubBackward0>)\n",
      "step =  873\n",
      "loss =  tensor(5490690., grad_fn=<SubBackward0>)\n",
      "step =  874\n",
      "loss =  tensor(5481205., grad_fn=<SubBackward0>)\n",
      "step =  875\n",
      "loss =  tensor(5497728., grad_fn=<SubBackward0>)\n",
      "step =  876\n",
      "loss =  tensor(5497861., grad_fn=<SubBackward0>)\n",
      "step =  877\n",
      "loss =  tensor(5495680., grad_fn=<SubBackward0>)\n",
      "step =  878\n",
      "loss =  tensor(5492380.5000, grad_fn=<SubBackward0>)\n",
      "step =  879\n",
      "loss =  tensor(5481464., grad_fn=<SubBackward0>)\n",
      "step =  880\n",
      "loss =  tensor(5504098., grad_fn=<SubBackward0>)\n",
      "step =  881\n",
      "loss =  tensor(5478131., grad_fn=<SubBackward0>)\n",
      "step =  882\n",
      "loss =  tensor(5496725., grad_fn=<SubBackward0>)\n",
      "step =  883\n",
      "loss =  tensor(5498199., grad_fn=<SubBackward0>)\n",
      "step =  884\n",
      "loss =  tensor(5479453., grad_fn=<SubBackward0>)\n",
      "step =  885\n",
      "loss =  tensor(5501421., grad_fn=<SubBackward0>)\n",
      "step =  886\n",
      "loss =  tensor(5496083., grad_fn=<SubBackward0>)\n",
      "step =  887\n",
      "loss =  tensor(5489795., grad_fn=<SubBackward0>)\n",
      "step =  888\n",
      "loss =  tensor(5499944., grad_fn=<SubBackward0>)\n",
      "step =  889\n",
      "loss =  tensor(5501113., grad_fn=<SubBackward0>)\n",
      "step =  890\n",
      "loss =  tensor(5496737., grad_fn=<SubBackward0>)\n",
      "step =  891\n",
      "loss =  tensor(5484155.5000, grad_fn=<SubBackward0>)\n",
      "step =  892\n",
      "loss =  tensor(5479401., grad_fn=<SubBackward0>)\n",
      "step =  893\n",
      "loss =  tensor(5486141., grad_fn=<SubBackward0>)\n",
      "step =  894\n",
      "loss =  tensor(5509908., grad_fn=<SubBackward0>)\n",
      "step =  895\n",
      "loss =  tensor(5488594.5000, grad_fn=<SubBackward0>)\n",
      "step =  896\n",
      "loss =  tensor(5482280.5000, grad_fn=<SubBackward0>)\n",
      "step =  897\n",
      "loss =  tensor(5484859., grad_fn=<SubBackward0>)\n",
      "step =  898\n",
      "loss =  tensor(5494529., grad_fn=<SubBackward0>)\n",
      "step =  899\n",
      "loss =  tensor(5497695., grad_fn=<SubBackward0>)\n",
      "step =  900\n",
      "loss =  tensor(5495642., grad_fn=<SubBackward0>)\n",
      "step =  901\n",
      "loss =  tensor(5469035.5000, grad_fn=<SubBackward0>)\n",
      "step =  902\n",
      "loss =  tensor(5472250., grad_fn=<SubBackward0>)\n",
      "step =  903\n",
      "loss =  tensor(5481035.5000, grad_fn=<SubBackward0>)\n",
      "step =  904\n",
      "loss =  tensor(5525473., grad_fn=<SubBackward0>)\n",
      "step =  905\n",
      "loss =  tensor(5490907., grad_fn=<SubBackward0>)\n",
      "step =  906\n",
      "loss =  tensor(5492209., grad_fn=<SubBackward0>)\n",
      "step =  907\n",
      "loss =  tensor(5480150., grad_fn=<SubBackward0>)\n",
      "step =  908\n",
      "loss =  tensor(5480564., grad_fn=<SubBackward0>)\n",
      "step =  909\n",
      "loss =  tensor(5491687., grad_fn=<SubBackward0>)\n",
      "step =  910\n",
      "loss =  tensor(5497219., grad_fn=<SubBackward0>)\n",
      "step =  911\n",
      "loss =  tensor(5483989., grad_fn=<SubBackward0>)\n",
      "step =  912\n",
      "loss =  tensor(5461403., grad_fn=<SubBackward0>)\n",
      "step =  913\n",
      "loss =  tensor(5469625., grad_fn=<SubBackward0>)\n",
      "step =  914\n",
      "loss =  tensor(5505370., grad_fn=<SubBackward0>)\n",
      "step =  915\n",
      "loss =  tensor(5472238., grad_fn=<SubBackward0>)\n",
      "step =  916\n",
      "loss =  tensor(5479742.5000, grad_fn=<SubBackward0>)\n",
      "step =  917\n",
      "loss =  tensor(5489831., grad_fn=<SubBackward0>)\n",
      "step =  918\n",
      "loss =  tensor(5498497., grad_fn=<SubBackward0>)\n",
      "step =  919\n",
      "loss =  tensor(5479351., grad_fn=<SubBackward0>)\n",
      "step =  920\n",
      "loss =  tensor(5497112., grad_fn=<SubBackward0>)\n",
      "step =  921\n",
      "loss =  tensor(5489307., grad_fn=<SubBackward0>)\n",
      "step =  922\n",
      "loss =  tensor(5511176.5000, grad_fn=<SubBackward0>)\n",
      "step =  923\n",
      "loss =  tensor(5480936.5000, grad_fn=<SubBackward0>)\n",
      "step =  924\n",
      "loss =  tensor(5479657., grad_fn=<SubBackward0>)\n",
      "step =  925\n",
      "loss =  tensor(5479435., grad_fn=<SubBackward0>)\n",
      "step =  926\n",
      "loss =  tensor(5477838., grad_fn=<SubBackward0>)\n",
      "step =  927\n",
      "loss =  tensor(5486852.5000, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  928\n",
      "loss =  tensor(5510422., grad_fn=<SubBackward0>)\n",
      "step =  929\n",
      "loss =  tensor(5508903., grad_fn=<SubBackward0>)\n",
      "step =  930\n",
      "loss =  tensor(5482166., grad_fn=<SubBackward0>)\n",
      "step =  931\n",
      "loss =  tensor(5505582., grad_fn=<SubBackward0>)\n",
      "step =  932\n",
      "loss =  tensor(5475724., grad_fn=<SubBackward0>)\n",
      "step =  933\n",
      "loss =  tensor(5489000., grad_fn=<SubBackward0>)\n",
      "step =  934\n",
      "loss =  tensor(5494504., grad_fn=<SubBackward0>)\n",
      "step =  935\n",
      "loss =  tensor(5468599., grad_fn=<SubBackward0>)\n",
      "step =  936\n",
      "loss =  tensor(5487369., grad_fn=<SubBackward0>)\n",
      "step =  937\n",
      "loss =  tensor(5516216., grad_fn=<SubBackward0>)\n",
      "step =  938\n",
      "loss =  tensor(5496295., grad_fn=<SubBackward0>)\n",
      "step =  939\n",
      "loss =  tensor(5491323., grad_fn=<SubBackward0>)\n",
      "step =  940\n",
      "loss =  tensor(5491138., grad_fn=<SubBackward0>)\n",
      "step =  941\n",
      "loss =  tensor(5483248., grad_fn=<SubBackward0>)\n",
      "step =  942\n",
      "loss =  tensor(5481952., grad_fn=<SubBackward0>)\n",
      "step =  943\n",
      "loss =  tensor(5463865., grad_fn=<SubBackward0>)\n",
      "step =  944\n",
      "loss =  tensor(5485752., grad_fn=<SubBackward0>)\n",
      "step =  945\n",
      "loss =  tensor(5490629.5000, grad_fn=<SubBackward0>)\n",
      "step =  946\n",
      "loss =  tensor(5505088., grad_fn=<SubBackward0>)\n",
      "step =  947\n",
      "loss =  tensor(5499636., grad_fn=<SubBackward0>)\n",
      "step =  948\n",
      "loss =  tensor(5505631., grad_fn=<SubBackward0>)\n",
      "step =  949\n",
      "loss =  tensor(5461156., grad_fn=<SubBackward0>)\n",
      "step =  950\n",
      "loss =  tensor(5503261.5000, grad_fn=<SubBackward0>)\n",
      "step =  951\n",
      "loss =  tensor(5482823., grad_fn=<SubBackward0>)\n",
      "step =  952\n",
      "loss =  tensor(5500308., grad_fn=<SubBackward0>)\n",
      "step =  953\n",
      "loss =  tensor(5482202., grad_fn=<SubBackward0>)\n",
      "step =  954\n",
      "loss =  tensor(5505366., grad_fn=<SubBackward0>)\n",
      "step =  955\n",
      "loss =  tensor(5485576., grad_fn=<SubBackward0>)\n",
      "step =  956\n",
      "loss =  tensor(5511646., grad_fn=<SubBackward0>)\n",
      "step =  957\n",
      "loss =  tensor(5501613., grad_fn=<SubBackward0>)\n",
      "step =  958\n",
      "loss =  tensor(5485971., grad_fn=<SubBackward0>)\n",
      "step =  959\n",
      "loss =  tensor(5503872., grad_fn=<SubBackward0>)\n",
      "step =  960\n",
      "loss =  tensor(5481957.5000, grad_fn=<SubBackward0>)\n",
      "step =  961\n",
      "loss =  tensor(5482716., grad_fn=<SubBackward0>)\n",
      "step =  962\n",
      "loss =  tensor(5505523., grad_fn=<SubBackward0>)\n",
      "step =  963\n",
      "loss =  tensor(5501664., grad_fn=<SubBackward0>)\n",
      "step =  964\n",
      "loss =  tensor(5501757., grad_fn=<SubBackward0>)\n",
      "step =  965\n",
      "loss =  tensor(5468975., grad_fn=<SubBackward0>)\n",
      "step =  966\n",
      "loss =  tensor(5504313., grad_fn=<SubBackward0>)\n",
      "step =  967\n",
      "loss =  tensor(5478367., grad_fn=<SubBackward0>)\n",
      "step =  968\n",
      "loss =  tensor(5468478., grad_fn=<SubBackward0>)\n",
      "step =  969\n",
      "loss =  tensor(5487341., grad_fn=<SubBackward0>)\n",
      "step =  970\n",
      "loss =  tensor(5476092., grad_fn=<SubBackward0>)\n",
      "step =  971\n",
      "loss =  tensor(5478426., grad_fn=<SubBackward0>)\n",
      "step =  972\n",
      "loss =  tensor(5490614., grad_fn=<SubBackward0>)\n",
      "step =  973\n",
      "loss =  tensor(5481689.5000, grad_fn=<SubBackward0>)\n",
      "step =  974\n",
      "loss =  tensor(5487345., grad_fn=<SubBackward0>)\n",
      "step =  975\n",
      "loss =  tensor(5480352., grad_fn=<SubBackward0>)\n",
      "step =  976\n",
      "loss =  tensor(5497887.5000, grad_fn=<SubBackward0>)\n",
      "step =  977\n",
      "loss =  tensor(5501836.5000, grad_fn=<SubBackward0>)\n",
      "step =  978\n",
      "loss =  tensor(5492404., grad_fn=<SubBackward0>)\n",
      "step =  979\n",
      "loss =  tensor(5495821.5000, grad_fn=<SubBackward0>)\n",
      "step =  980\n",
      "loss =  tensor(5498864., grad_fn=<SubBackward0>)\n",
      "step =  981\n",
      "loss =  tensor(5486053., grad_fn=<SubBackward0>)\n",
      "step =  982\n",
      "loss =  tensor(5500362., grad_fn=<SubBackward0>)\n",
      "step =  983\n",
      "loss =  tensor(5472359., grad_fn=<SubBackward0>)\n",
      "step =  984\n",
      "loss =  tensor(5467754., grad_fn=<SubBackward0>)\n",
      "step =  985\n",
      "loss =  tensor(5478218., grad_fn=<SubBackward0>)\n",
      "step =  986\n",
      "loss =  tensor(5482809.5000, grad_fn=<SubBackward0>)\n",
      "step =  987\n",
      "loss =  tensor(5516195.5000, grad_fn=<SubBackward0>)\n",
      "step =  988\n",
      "loss =  tensor(5488502., grad_fn=<SubBackward0>)\n",
      "step =  989\n",
      "loss =  tensor(5512541.5000, grad_fn=<SubBackward0>)\n",
      "step =  990\n",
      "loss =  tensor(5470074., grad_fn=<SubBackward0>)\n",
      "step =  991\n",
      "loss =  tensor(5474146., grad_fn=<SubBackward0>)\n",
      "step =  992\n",
      "loss =  tensor(5498824., grad_fn=<SubBackward0>)\n",
      "step =  993\n",
      "loss =  tensor(5483864., grad_fn=<SubBackward0>)\n",
      "step =  994\n",
      "loss =  tensor(5503785., grad_fn=<SubBackward0>)\n",
      "step =  995\n",
      "loss =  tensor(5493695., grad_fn=<SubBackward0>)\n",
      "step =  996\n",
      "loss =  tensor(5463593., grad_fn=<SubBackward0>)\n",
      "step =  997\n",
      "loss =  tensor(5489693., grad_fn=<SubBackward0>)\n",
      "step =  998\n",
      "loss =  tensor(5510980., grad_fn=<SubBackward0>)\n",
      "step =  999\n",
      "loss =  tensor(5473411., grad_fn=<SubBackward0>)\n",
      "step =  1000\n",
      "loss =  tensor(5473742.5000, grad_fn=<SubBackward0>)\n",
      "step =  1001\n",
      "loss =  tensor(5485973., grad_fn=<SubBackward0>)\n",
      "step =  1002\n",
      "loss =  tensor(5487290., grad_fn=<SubBackward0>)\n",
      "step =  1003\n",
      "loss =  tensor(5495195., grad_fn=<SubBackward0>)\n",
      "step =  1004\n",
      "loss =  tensor(5502886., grad_fn=<SubBackward0>)\n",
      "step =  1005\n",
      "loss =  tensor(5488309., grad_fn=<SubBackward0>)\n",
      "step =  1006\n",
      "loss =  tensor(5518822., grad_fn=<SubBackward0>)\n",
      "step =  1007\n",
      "loss =  tensor(5488347., grad_fn=<SubBackward0>)\n",
      "step =  1008\n",
      "loss =  tensor(5492499., grad_fn=<SubBackward0>)\n",
      "step =  1009\n",
      "loss =  tensor(5487167.5000, grad_fn=<SubBackward0>)\n",
      "step =  1010\n",
      "loss =  tensor(5497636.5000, grad_fn=<SubBackward0>)\n",
      "step =  1011\n",
      "loss =  tensor(5488558.5000, grad_fn=<SubBackward0>)\n",
      "step =  1012\n",
      "loss =  tensor(5485692., grad_fn=<SubBackward0>)\n",
      "step =  1013\n",
      "loss =  tensor(5483898., grad_fn=<SubBackward0>)\n",
      "step =  1014\n",
      "loss =  tensor(5469693., grad_fn=<SubBackward0>)\n",
      "step =  1015\n",
      "loss =  tensor(5503479., grad_fn=<SubBackward0>)\n",
      "step =  1016\n",
      "loss =  tensor(5488476., grad_fn=<SubBackward0>)\n",
      "step =  1017\n",
      "loss =  tensor(5494828., grad_fn=<SubBackward0>)\n",
      "step =  1018\n",
      "loss =  tensor(5500818., grad_fn=<SubBackward0>)\n",
      "step =  1019\n",
      "loss =  tensor(5489787.5000, grad_fn=<SubBackward0>)\n",
      "step =  1020\n",
      "loss =  tensor(5469752., grad_fn=<SubBackward0>)\n",
      "step =  1021\n",
      "loss =  tensor(5466823.5000, grad_fn=<SubBackward0>)\n",
      "step =  1022\n",
      "loss =  tensor(5520619.5000, grad_fn=<SubBackward0>)\n",
      "step =  1023\n",
      "loss =  tensor(5504493.5000, grad_fn=<SubBackward0>)\n",
      "step =  1024\n",
      "loss =  tensor(5498075., grad_fn=<SubBackward0>)\n",
      "step =  1025\n",
      "loss =  tensor(5525872., grad_fn=<SubBackward0>)\n",
      "step =  1026\n",
      "loss =  tensor(5469413.5000, grad_fn=<SubBackward0>)\n",
      "step =  1027\n",
      "loss =  tensor(5493733.5000, grad_fn=<SubBackward0>)\n",
      "step =  1028\n",
      "loss =  tensor(5466950., grad_fn=<SubBackward0>)\n",
      "step =  1029\n",
      "loss =  tensor(5494220., grad_fn=<SubBackward0>)\n",
      "step =  1030\n",
      "loss =  tensor(5478178.5000, grad_fn=<SubBackward0>)\n",
      "step =  1031\n",
      "loss =  tensor(5487416., grad_fn=<SubBackward0>)\n",
      "step =  1032\n",
      "loss =  tensor(5490623., grad_fn=<SubBackward0>)\n",
      "step =  1033\n",
      "loss =  tensor(5500569.5000, grad_fn=<SubBackward0>)\n",
      "step =  1034\n",
      "loss =  tensor(5495708., grad_fn=<SubBackward0>)\n",
      "step =  1035\n",
      "loss =  tensor(5482954.5000, grad_fn=<SubBackward0>)\n",
      "step =  1036\n",
      "loss =  tensor(5484723., grad_fn=<SubBackward0>)\n",
      "step =  1037\n",
      "loss =  tensor(5470317., grad_fn=<SubBackward0>)\n",
      "step =  1038\n",
      "loss =  tensor(5486267., grad_fn=<SubBackward0>)\n",
      "step =  1039\n",
      "loss =  tensor(5492883.5000, grad_fn=<SubBackward0>)\n",
      "step =  1040\n",
      "loss =  tensor(5490924., grad_fn=<SubBackward0>)\n",
      "step =  1041\n",
      "loss =  tensor(5466577., grad_fn=<SubBackward0>)\n",
      "step =  1042\n",
      "loss =  tensor(5488085.5000, grad_fn=<SubBackward0>)\n",
      "step =  1043\n",
      "loss =  tensor(5501004., grad_fn=<SubBackward0>)\n",
      "step =  1044\n",
      "loss =  tensor(5486331., grad_fn=<SubBackward0>)\n",
      "step =  1045\n",
      "loss =  tensor(5502804.5000, grad_fn=<SubBackward0>)\n",
      "step =  1046\n",
      "loss =  tensor(5497966., grad_fn=<SubBackward0>)\n",
      "step =  1047\n",
      "loss =  tensor(5489570., grad_fn=<SubBackward0>)\n",
      "step =  1048\n",
      "loss =  tensor(5488822., grad_fn=<SubBackward0>)\n",
      "step =  1049\n",
      "loss =  tensor(5483244., grad_fn=<SubBackward0>)\n",
      "step =  1050\n",
      "loss =  tensor(5499772., grad_fn=<SubBackward0>)\n",
      "step =  1051\n",
      "loss =  tensor(5465870.5000, grad_fn=<SubBackward0>)\n",
      "step =  1052\n",
      "loss =  tensor(5477777., grad_fn=<SubBackward0>)\n",
      "step =  1053\n",
      "loss =  tensor(5496034., grad_fn=<SubBackward0>)\n",
      "step =  1054\n",
      "loss =  tensor(5486200.5000, grad_fn=<SubBackward0>)\n",
      "step =  1055\n",
      "loss =  tensor(5479302.5000, grad_fn=<SubBackward0>)\n",
      "step =  1056\n",
      "loss =  tensor(5463401.5000, grad_fn=<SubBackward0>)\n",
      "step =  1057\n",
      "loss =  tensor(5488813., grad_fn=<SubBackward0>)\n",
      "step =  1058\n",
      "loss =  tensor(5506816.5000, grad_fn=<SubBackward0>)\n",
      "step =  1059\n",
      "loss =  tensor(5479896., grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  1060\n",
      "loss =  tensor(5477455.5000, grad_fn=<SubBackward0>)\n",
      "step =  1061\n",
      "loss =  tensor(5469600.5000, grad_fn=<SubBackward0>)\n",
      "step =  1062\n",
      "loss =  tensor(5470312., grad_fn=<SubBackward0>)\n",
      "step =  1063\n",
      "loss =  tensor(5499221., grad_fn=<SubBackward0>)\n",
      "step =  1064\n",
      "loss =  tensor(5505139.5000, grad_fn=<SubBackward0>)\n",
      "step =  1065\n",
      "loss =  tensor(5483782., grad_fn=<SubBackward0>)\n",
      "step =  1066\n",
      "loss =  tensor(5462729., grad_fn=<SubBackward0>)\n",
      "step =  1067\n",
      "loss =  tensor(5496153., grad_fn=<SubBackward0>)\n",
      "step =  1068\n",
      "loss =  tensor(5505724.5000, grad_fn=<SubBackward0>)\n",
      "step =  1069\n",
      "loss =  tensor(5501329., grad_fn=<SubBackward0>)\n",
      "step =  1070\n",
      "loss =  tensor(5506424., grad_fn=<SubBackward0>)\n",
      "step =  1071\n",
      "loss =  tensor(5495928., grad_fn=<SubBackward0>)\n",
      "step =  1072\n",
      "loss =  tensor(5484716., grad_fn=<SubBackward0>)\n",
      "step =  1073\n",
      "loss =  tensor(5479224., grad_fn=<SubBackward0>)\n",
      "step =  1074\n",
      "loss =  tensor(5502926., grad_fn=<SubBackward0>)\n",
      "step =  1075\n",
      "loss =  tensor(5484923., grad_fn=<SubBackward0>)\n",
      "step =  1076\n",
      "loss =  tensor(5500947.5000, grad_fn=<SubBackward0>)\n",
      "step =  1077\n",
      "loss =  tensor(5483372., grad_fn=<SubBackward0>)\n",
      "step =  1078\n",
      "loss =  tensor(5470756., grad_fn=<SubBackward0>)\n",
      "step =  1079\n",
      "loss =  tensor(5504002., grad_fn=<SubBackward0>)\n",
      "step =  1080\n",
      "loss =  tensor(5465615., grad_fn=<SubBackward0>)\n",
      "step =  1081\n",
      "loss =  tensor(5462571.5000, grad_fn=<SubBackward0>)\n",
      "step =  1082\n",
      "loss =  tensor(5480960., grad_fn=<SubBackward0>)\n",
      "step =  1083\n",
      "loss =  tensor(5502384., grad_fn=<SubBackward0>)\n",
      "step =  1084\n",
      "loss =  tensor(5495099., grad_fn=<SubBackward0>)\n",
      "step =  1085\n",
      "loss =  tensor(5497964., grad_fn=<SubBackward0>)\n",
      "step =  1086\n",
      "loss =  tensor(5486960., grad_fn=<SubBackward0>)\n",
      "step =  1087\n",
      "loss =  tensor(5468641.5000, grad_fn=<SubBackward0>)\n",
      "step =  1088\n",
      "loss =  tensor(5485715., grad_fn=<SubBackward0>)\n",
      "step =  1089\n",
      "loss =  tensor(5473343., grad_fn=<SubBackward0>)\n",
      "step =  1090\n",
      "loss =  tensor(5478040., grad_fn=<SubBackward0>)\n",
      "step =  1091\n",
      "loss =  tensor(5484182., grad_fn=<SubBackward0>)\n",
      "step =  1092\n",
      "loss =  tensor(5481763.5000, grad_fn=<SubBackward0>)\n",
      "step =  1093\n",
      "loss =  tensor(5508413., grad_fn=<SubBackward0>)\n",
      "step =  1094\n",
      "loss =  tensor(5512893., grad_fn=<SubBackward0>)\n",
      "step =  1095\n",
      "loss =  tensor(5495136., grad_fn=<SubBackward0>)\n",
      "step =  1096\n",
      "loss =  tensor(5485511., grad_fn=<SubBackward0>)\n",
      "step =  1097\n",
      "loss =  tensor(5459972.5000, grad_fn=<SubBackward0>)\n",
      "step =  1098\n",
      "loss =  tensor(5495951., grad_fn=<SubBackward0>)\n",
      "step =  1099\n",
      "loss =  tensor(5496133., grad_fn=<SubBackward0>)\n",
      "step =  1100\n",
      "loss =  tensor(5469170., grad_fn=<SubBackward0>)\n",
      "step =  1101\n",
      "loss =  tensor(5477557., grad_fn=<SubBackward0>)\n",
      "step =  1102\n",
      "loss =  tensor(5473684., grad_fn=<SubBackward0>)\n",
      "step =  1103\n",
      "loss =  tensor(5510039.5000, grad_fn=<SubBackward0>)\n",
      "step =  1104\n",
      "loss =  tensor(5496442., grad_fn=<SubBackward0>)\n",
      "step =  1105\n",
      "loss =  tensor(5466489., grad_fn=<SubBackward0>)\n",
      "step =  1106\n",
      "loss =  tensor(5482462., grad_fn=<SubBackward0>)\n",
      "step =  1107\n",
      "loss =  tensor(5488676., grad_fn=<SubBackward0>)\n",
      "step =  1108\n",
      "loss =  tensor(5479459., grad_fn=<SubBackward0>)\n",
      "step =  1109\n",
      "loss =  tensor(5491098., grad_fn=<SubBackward0>)\n",
      "step =  1110\n",
      "loss =  tensor(5482204., grad_fn=<SubBackward0>)\n",
      "step =  1111\n",
      "loss =  tensor(5498046., grad_fn=<SubBackward0>)\n",
      "step =  1112\n",
      "loss =  tensor(5473930., grad_fn=<SubBackward0>)\n",
      "step =  1113\n",
      "loss =  tensor(5473400., grad_fn=<SubBackward0>)\n",
      "step =  1114\n",
      "loss =  tensor(5479639., grad_fn=<SubBackward0>)\n",
      "step =  1115\n",
      "loss =  tensor(5489442., grad_fn=<SubBackward0>)\n",
      "step =  1116\n",
      "loss =  tensor(5482206.5000, grad_fn=<SubBackward0>)\n",
      "step =  1117\n",
      "loss =  tensor(5464128.5000, grad_fn=<SubBackward0>)\n",
      "step =  1118\n",
      "loss =  tensor(5499817., grad_fn=<SubBackward0>)\n",
      "step =  1119\n",
      "loss =  tensor(5477415.5000, grad_fn=<SubBackward0>)\n",
      "step =  1120\n",
      "loss =  tensor(5482454.5000, grad_fn=<SubBackward0>)\n",
      "step =  1121\n",
      "loss =  tensor(5471106., grad_fn=<SubBackward0>)\n",
      "step =  1122\n",
      "loss =  tensor(5493650., grad_fn=<SubBackward0>)\n",
      "step =  1123\n",
      "loss =  tensor(5466630.5000, grad_fn=<SubBackward0>)\n",
      "step =  1124\n",
      "loss =  tensor(5485106.5000, grad_fn=<SubBackward0>)\n",
      "step =  1125\n",
      "loss =  tensor(5462474., grad_fn=<SubBackward0>)\n",
      "step =  1126\n",
      "loss =  tensor(5479490., grad_fn=<SubBackward0>)\n",
      "step =  1127\n",
      "loss =  tensor(5505221., grad_fn=<SubBackward0>)\n",
      "step =  1128\n",
      "loss =  tensor(5497753.5000, grad_fn=<SubBackward0>)\n",
      "step =  1129\n",
      "loss =  tensor(5489965., grad_fn=<SubBackward0>)\n",
      "step =  1130\n",
      "loss =  tensor(5491533., grad_fn=<SubBackward0>)\n",
      "step =  1131\n",
      "loss =  tensor(5471926., grad_fn=<SubBackward0>)\n",
      "step =  1132\n",
      "loss =  tensor(5475352., grad_fn=<SubBackward0>)\n",
      "step =  1133\n",
      "loss =  tensor(5479318.5000, grad_fn=<SubBackward0>)\n",
      "step =  1134\n",
      "loss =  tensor(5474918., grad_fn=<SubBackward0>)\n",
      "step =  1135\n",
      "loss =  tensor(5501986., grad_fn=<SubBackward0>)\n",
      "step =  1136\n",
      "loss =  tensor(5473375.5000, grad_fn=<SubBackward0>)\n",
      "step =  1137\n",
      "loss =  tensor(5484732., grad_fn=<SubBackward0>)\n",
      "step =  1138\n",
      "loss =  tensor(5481937.5000, grad_fn=<SubBackward0>)\n",
      "step =  1139\n",
      "loss =  tensor(5496304., grad_fn=<SubBackward0>)\n",
      "step =  1140\n",
      "loss =  tensor(5487210., grad_fn=<SubBackward0>)\n",
      "step =  1141\n",
      "loss =  tensor(5487712.5000, grad_fn=<SubBackward0>)\n",
      "step =  1142\n",
      "loss =  tensor(5487071., grad_fn=<SubBackward0>)\n",
      "step =  1143\n",
      "loss =  tensor(5473311.5000, grad_fn=<SubBackward0>)\n",
      "step =  1144\n",
      "loss =  tensor(5484261., grad_fn=<SubBackward0>)\n",
      "step =  1145\n",
      "loss =  tensor(5489062.5000, grad_fn=<SubBackward0>)\n",
      "step =  1146\n",
      "loss =  tensor(5469677., grad_fn=<SubBackward0>)\n",
      "step =  1147\n",
      "loss =  tensor(5511716., grad_fn=<SubBackward0>)\n",
      "step =  1148\n",
      "loss =  tensor(5520390., grad_fn=<SubBackward0>)\n",
      "step =  1149\n",
      "loss =  tensor(5508194., grad_fn=<SubBackward0>)\n",
      "step =  1150\n",
      "loss =  tensor(5483074., grad_fn=<SubBackward0>)\n",
      "step =  1151\n",
      "loss =  tensor(5476820.5000, grad_fn=<SubBackward0>)\n",
      "step =  1152\n",
      "loss =  tensor(5483636.5000, grad_fn=<SubBackward0>)\n",
      "step =  1153\n",
      "loss =  tensor(5485162., grad_fn=<SubBackward0>)\n",
      "step =  1154\n",
      "loss =  tensor(5483602., grad_fn=<SubBackward0>)\n",
      "step =  1155\n",
      "loss =  tensor(5498915.5000, grad_fn=<SubBackward0>)\n",
      "step =  1156\n",
      "loss =  tensor(5488239.5000, grad_fn=<SubBackward0>)\n",
      "step =  1157\n",
      "loss =  tensor(5468011., grad_fn=<SubBackward0>)\n",
      "step =  1158\n",
      "loss =  tensor(5476883., grad_fn=<SubBackward0>)\n",
      "step =  1159\n",
      "loss =  tensor(5473609., grad_fn=<SubBackward0>)\n",
      "step =  1160\n",
      "loss =  tensor(5472377., grad_fn=<SubBackward0>)\n",
      "step =  1161\n",
      "loss =  tensor(5470887.5000, grad_fn=<SubBackward0>)\n",
      "step =  1162\n",
      "loss =  tensor(5487199., grad_fn=<SubBackward0>)\n",
      "step =  1163\n",
      "loss =  tensor(5487914., grad_fn=<SubBackward0>)\n",
      "step =  1164\n",
      "loss =  tensor(5476331., grad_fn=<SubBackward0>)\n",
      "step =  1165\n",
      "loss =  tensor(5503721., grad_fn=<SubBackward0>)\n",
      "step =  1166\n",
      "loss =  tensor(5485298.5000, grad_fn=<SubBackward0>)\n",
      "step =  1167\n",
      "loss =  tensor(5476588., grad_fn=<SubBackward0>)\n",
      "step =  1168\n",
      "loss =  tensor(5474040., grad_fn=<SubBackward0>)\n",
      "step =  1169\n",
      "loss =  tensor(5496967., grad_fn=<SubBackward0>)\n",
      "step =  1170\n",
      "loss =  tensor(5467954., grad_fn=<SubBackward0>)\n",
      "step =  1171\n",
      "loss =  tensor(5487513., grad_fn=<SubBackward0>)\n",
      "step =  1172\n",
      "loss =  tensor(5475021., grad_fn=<SubBackward0>)\n",
      "step =  1173\n",
      "loss =  tensor(5482456., grad_fn=<SubBackward0>)\n",
      "step =  1174\n",
      "loss =  tensor(5516316., grad_fn=<SubBackward0>)\n",
      "step =  1175\n",
      "loss =  tensor(5504406., grad_fn=<SubBackward0>)\n",
      "step =  1176\n",
      "loss =  tensor(5493064., grad_fn=<SubBackward0>)\n",
      "step =  1177\n",
      "loss =  tensor(5480864., grad_fn=<SubBackward0>)\n",
      "step =  1178\n",
      "loss =  tensor(5482524., grad_fn=<SubBackward0>)\n",
      "step =  1179\n",
      "loss =  tensor(5492150., grad_fn=<SubBackward0>)\n",
      "step =  1180\n",
      "loss =  tensor(5463754., grad_fn=<SubBackward0>)\n",
      "step =  1181\n",
      "loss =  tensor(5486224.5000, grad_fn=<SubBackward0>)\n",
      "step =  1182\n",
      "loss =  tensor(5478020., grad_fn=<SubBackward0>)\n",
      "step =  1183\n",
      "loss =  tensor(5491550., grad_fn=<SubBackward0>)\n",
      "step =  1184\n",
      "loss =  tensor(5486448., grad_fn=<SubBackward0>)\n",
      "step =  1185\n",
      "loss =  tensor(5505612., grad_fn=<SubBackward0>)\n",
      "step =  1186\n",
      "loss =  tensor(5457185., grad_fn=<SubBackward0>)\n",
      "step =  1187\n",
      "loss =  tensor(5484081., grad_fn=<SubBackward0>)\n",
      "step =  1188\n",
      "loss =  tensor(5483910., grad_fn=<SubBackward0>)\n",
      "step =  1189\n",
      "loss =  tensor(5488310.5000, grad_fn=<SubBackward0>)\n",
      "step =  1190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(5494752., grad_fn=<SubBackward0>)\n",
      "step =  1191\n",
      "loss =  tensor(5510395., grad_fn=<SubBackward0>)\n",
      "step =  1192\n",
      "loss =  tensor(5505689., grad_fn=<SubBackward0>)\n",
      "step =  1193\n",
      "loss =  tensor(5511578., grad_fn=<SubBackward0>)\n",
      "step =  1194\n",
      "loss =  tensor(5493366., grad_fn=<SubBackward0>)\n",
      "step =  1195\n",
      "loss =  tensor(5475647., grad_fn=<SubBackward0>)\n",
      "step =  1196\n",
      "loss =  tensor(5475492., grad_fn=<SubBackward0>)\n",
      "step =  1197\n",
      "loss =  tensor(5489803., grad_fn=<SubBackward0>)\n",
      "step =  1198\n",
      "loss =  tensor(5495294., grad_fn=<SubBackward0>)\n",
      "step =  1199\n",
      "loss =  tensor(5498892.5000, grad_fn=<SubBackward0>)\n",
      "step =  1200\n",
      "loss =  tensor(5509197.5000, grad_fn=<SubBackward0>)\n",
      "step =  1201\n",
      "loss =  tensor(5505033., grad_fn=<SubBackward0>)\n",
      "step =  1202\n",
      "loss =  tensor(5464852.5000, grad_fn=<SubBackward0>)\n",
      "step =  1203\n",
      "loss =  tensor(5484379.5000, grad_fn=<SubBackward0>)\n",
      "step =  1204\n",
      "loss =  tensor(5485392., grad_fn=<SubBackward0>)\n",
      "step =  1205\n",
      "loss =  tensor(5496441.5000, grad_fn=<SubBackward0>)\n",
      "step =  1206\n",
      "loss =  tensor(5463020., grad_fn=<SubBackward0>)\n",
      "step =  1207\n",
      "loss =  tensor(5492726.5000, grad_fn=<SubBackward0>)\n",
      "step =  1208\n",
      "loss =  tensor(5485506., grad_fn=<SubBackward0>)\n",
      "step =  1209\n",
      "loss =  tensor(5474634.5000, grad_fn=<SubBackward0>)\n",
      "step =  1210\n",
      "loss =  tensor(5486460., grad_fn=<SubBackward0>)\n",
      "step =  1211\n",
      "loss =  tensor(5492309., grad_fn=<SubBackward0>)\n",
      "step =  1212\n",
      "loss =  tensor(5479267., grad_fn=<SubBackward0>)\n",
      "step =  1213\n",
      "loss =  tensor(5480317., grad_fn=<SubBackward0>)\n",
      "step =  1214\n",
      "loss =  tensor(5501937., grad_fn=<SubBackward0>)\n",
      "step =  1215\n",
      "loss =  tensor(5465303., grad_fn=<SubBackward0>)\n",
      "step =  1216\n",
      "loss =  tensor(5499302., grad_fn=<SubBackward0>)\n",
      "step =  1217\n",
      "loss =  tensor(5490454., grad_fn=<SubBackward0>)\n",
      "step =  1218\n",
      "loss =  tensor(5521701., grad_fn=<SubBackward0>)\n",
      "step =  1219\n",
      "loss =  tensor(5479231., grad_fn=<SubBackward0>)\n",
      "step =  1220\n",
      "loss =  tensor(5481982., grad_fn=<SubBackward0>)\n",
      "step =  1221\n",
      "loss =  tensor(5470101., grad_fn=<SubBackward0>)\n",
      "step =  1222\n",
      "loss =  tensor(5494460., grad_fn=<SubBackward0>)\n",
      "step =  1223\n",
      "loss =  tensor(5477539., grad_fn=<SubBackward0>)\n",
      "step =  1224\n",
      "loss =  tensor(5484943., grad_fn=<SubBackward0>)\n",
      "step =  1225\n",
      "loss =  tensor(5459989., grad_fn=<SubBackward0>)\n",
      "step =  1226\n",
      "loss =  tensor(5466106.5000, grad_fn=<SubBackward0>)\n",
      "step =  1227\n",
      "loss =  tensor(5466080., grad_fn=<SubBackward0>)\n",
      "step =  1228\n",
      "loss =  tensor(5489893., grad_fn=<SubBackward0>)\n",
      "step =  1229\n",
      "loss =  tensor(5476012., grad_fn=<SubBackward0>)\n",
      "step =  1230\n",
      "loss =  tensor(5477577.5000, grad_fn=<SubBackward0>)\n",
      "step =  1231\n",
      "loss =  tensor(5481140.5000, grad_fn=<SubBackward0>)\n",
      "step =  1232\n",
      "loss =  tensor(5462352., grad_fn=<SubBackward0>)\n",
      "step =  1233\n",
      "loss =  tensor(5483703., grad_fn=<SubBackward0>)\n",
      "step =  1234\n",
      "loss =  tensor(5474411., grad_fn=<SubBackward0>)\n",
      "step =  1235\n",
      "loss =  tensor(5483468., grad_fn=<SubBackward0>)\n",
      "step =  1236\n",
      "loss =  tensor(5476913., grad_fn=<SubBackward0>)\n",
      "step =  1237\n",
      "loss =  tensor(5482596., grad_fn=<SubBackward0>)\n",
      "step =  1238\n",
      "loss =  tensor(5482082.5000, grad_fn=<SubBackward0>)\n",
      "step =  1239\n",
      "loss =  tensor(5487015., grad_fn=<SubBackward0>)\n",
      "step =  1240\n",
      "loss =  tensor(5481039., grad_fn=<SubBackward0>)\n",
      "step =  1241\n",
      "loss =  tensor(5488725., grad_fn=<SubBackward0>)\n",
      "step =  1242\n",
      "loss =  tensor(5494253.5000, grad_fn=<SubBackward0>)\n",
      "step =  1243\n",
      "loss =  tensor(5491804., grad_fn=<SubBackward0>)\n",
      "step =  1244\n",
      "loss =  tensor(5491970., grad_fn=<SubBackward0>)\n",
      "step =  1245\n",
      "loss =  tensor(5485969.5000, grad_fn=<SubBackward0>)\n",
      "step =  1246\n",
      "loss =  tensor(5492935., grad_fn=<SubBackward0>)\n",
      "step =  1247\n",
      "loss =  tensor(5494959.5000, grad_fn=<SubBackward0>)\n",
      "step =  1248\n",
      "loss =  tensor(5480743., grad_fn=<SubBackward0>)\n",
      "step =  1249\n",
      "loss =  tensor(5485989., grad_fn=<SubBackward0>)\n",
      "step =  1250\n",
      "loss =  tensor(5499442., grad_fn=<SubBackward0>)\n",
      "step =  1251\n",
      "loss =  tensor(5462882., grad_fn=<SubBackward0>)\n",
      "step =  1252\n",
      "loss =  tensor(5492565., grad_fn=<SubBackward0>)\n",
      "step =  1253\n",
      "loss =  tensor(5487655., grad_fn=<SubBackward0>)\n",
      "step =  1254\n",
      "loss =  tensor(5461546.5000, grad_fn=<SubBackward0>)\n",
      "step =  1255\n",
      "loss =  tensor(5498978., grad_fn=<SubBackward0>)\n",
      "step =  1256\n",
      "loss =  tensor(5501759.5000, grad_fn=<SubBackward0>)\n",
      "step =  1257\n",
      "loss =  tensor(5506572., grad_fn=<SubBackward0>)\n",
      "step =  1258\n",
      "loss =  tensor(5490132., grad_fn=<SubBackward0>)\n",
      "step =  1259\n",
      "loss =  tensor(5473037.5000, grad_fn=<SubBackward0>)\n",
      "step =  1260\n",
      "loss =  tensor(5488912., grad_fn=<SubBackward0>)\n",
      "step =  1261\n",
      "loss =  tensor(5488628., grad_fn=<SubBackward0>)\n",
      "step =  1262\n",
      "loss =  tensor(5492732., grad_fn=<SubBackward0>)\n",
      "step =  1263\n",
      "loss =  tensor(5495675., grad_fn=<SubBackward0>)\n",
      "step =  1264\n",
      "loss =  tensor(5465028., grad_fn=<SubBackward0>)\n",
      "step =  1265\n",
      "loss =  tensor(5491145., grad_fn=<SubBackward0>)\n",
      "step =  1266\n",
      "loss =  tensor(5490400.5000, grad_fn=<SubBackward0>)\n",
      "step =  1267\n",
      "loss =  tensor(5467365.5000, grad_fn=<SubBackward0>)\n",
      "step =  1268\n",
      "loss =  tensor(5495339., grad_fn=<SubBackward0>)\n",
      "step =  1269\n",
      "loss =  tensor(5477930.5000, grad_fn=<SubBackward0>)\n",
      "step =  1270\n",
      "loss =  tensor(5483200., grad_fn=<SubBackward0>)\n",
      "step =  1271\n",
      "loss =  tensor(5477321.5000, grad_fn=<SubBackward0>)\n",
      "step =  1272\n",
      "loss =  tensor(5496241.5000, grad_fn=<SubBackward0>)\n",
      "step =  1273\n",
      "loss =  tensor(5505585.5000, grad_fn=<SubBackward0>)\n",
      "step =  1274\n",
      "loss =  tensor(5481802., grad_fn=<SubBackward0>)\n",
      "step =  1275\n",
      "loss =  tensor(5506410., grad_fn=<SubBackward0>)\n",
      "step =  1276\n",
      "loss =  tensor(5485422., grad_fn=<SubBackward0>)\n",
      "step =  1277\n",
      "loss =  tensor(5496334., grad_fn=<SubBackward0>)\n",
      "step =  1278\n",
      "loss =  tensor(5488090., grad_fn=<SubBackward0>)\n",
      "step =  1279\n",
      "loss =  tensor(5483146., grad_fn=<SubBackward0>)\n",
      "step =  1280\n",
      "loss =  tensor(5486992., grad_fn=<SubBackward0>)\n",
      "step =  1281\n",
      "loss =  tensor(5475024.5000, grad_fn=<SubBackward0>)\n",
      "step =  1282\n",
      "loss =  tensor(5481494., grad_fn=<SubBackward0>)\n",
      "step =  1283\n",
      "loss =  tensor(5475390.5000, grad_fn=<SubBackward0>)\n",
      "step =  1284\n",
      "loss =  tensor(5504813., grad_fn=<SubBackward0>)\n",
      "step =  1285\n",
      "loss =  tensor(5491956.5000, grad_fn=<SubBackward0>)\n",
      "step =  1286\n",
      "loss =  tensor(5492883., grad_fn=<SubBackward0>)\n",
      "step =  1287\n",
      "loss =  tensor(5507587., grad_fn=<SubBackward0>)\n",
      "step =  1288\n",
      "loss =  tensor(5494992.5000, grad_fn=<SubBackward0>)\n",
      "step =  1289\n",
      "loss =  tensor(5474813.5000, grad_fn=<SubBackward0>)\n",
      "step =  1290\n",
      "loss =  tensor(5468926., grad_fn=<SubBackward0>)\n",
      "step =  1291\n",
      "loss =  tensor(5510987.5000, grad_fn=<SubBackward0>)\n",
      "step =  1292\n",
      "loss =  tensor(5470098., grad_fn=<SubBackward0>)\n",
      "step =  1293\n",
      "loss =  tensor(5483369.5000, grad_fn=<SubBackward0>)\n",
      "step =  1294\n",
      "loss =  tensor(5485365., grad_fn=<SubBackward0>)\n",
      "step =  1295\n",
      "loss =  tensor(5494149., grad_fn=<SubBackward0>)\n",
      "step =  1296\n",
      "loss =  tensor(5461532.5000, grad_fn=<SubBackward0>)\n",
      "step =  1297\n",
      "loss =  tensor(5500239., grad_fn=<SubBackward0>)\n",
      "step =  1298\n",
      "loss =  tensor(5503726.5000, grad_fn=<SubBackward0>)\n",
      "step =  1299\n",
      "loss =  tensor(5458401., grad_fn=<SubBackward0>)\n",
      "step =  1300\n",
      "loss =  tensor(5465571., grad_fn=<SubBackward0>)\n",
      "step =  1301\n",
      "loss =  tensor(5495002.5000, grad_fn=<SubBackward0>)\n",
      "step =  1302\n",
      "loss =  tensor(5492497., grad_fn=<SubBackward0>)\n",
      "step =  1303\n",
      "loss =  tensor(5489685., grad_fn=<SubBackward0>)\n",
      "step =  1304\n",
      "loss =  tensor(5473323.5000, grad_fn=<SubBackward0>)\n",
      "step =  1305\n",
      "loss =  tensor(5482597., grad_fn=<SubBackward0>)\n",
      "step =  1306\n",
      "loss =  tensor(5506692., grad_fn=<SubBackward0>)\n",
      "step =  1307\n",
      "loss =  tensor(5483119.5000, grad_fn=<SubBackward0>)\n",
      "step =  1308\n",
      "loss =  tensor(5481434.5000, grad_fn=<SubBackward0>)\n",
      "step =  1309\n",
      "loss =  tensor(5474784., grad_fn=<SubBackward0>)\n",
      "step =  1310\n",
      "loss =  tensor(5469845., grad_fn=<SubBackward0>)\n",
      "step =  1311\n",
      "loss =  tensor(5473242.5000, grad_fn=<SubBackward0>)\n",
      "step =  1312\n",
      "loss =  tensor(5493496., grad_fn=<SubBackward0>)\n",
      "step =  1313\n",
      "loss =  tensor(5458265., grad_fn=<SubBackward0>)\n",
      "step =  1314\n",
      "loss =  tensor(5478877., grad_fn=<SubBackward0>)\n",
      "step =  1315\n",
      "loss =  tensor(5482933.5000, grad_fn=<SubBackward0>)\n",
      "step =  1316\n",
      "loss =  tensor(5474361., grad_fn=<SubBackward0>)\n",
      "step =  1317\n",
      "loss =  tensor(5466582.5000, grad_fn=<SubBackward0>)\n",
      "step =  1318\n",
      "loss =  tensor(5478561., grad_fn=<SubBackward0>)\n",
      "step =  1319\n",
      "loss =  tensor(5472269.5000, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  1320\n",
      "loss =  tensor(5477627.5000, grad_fn=<SubBackward0>)\n",
      "step =  1321\n",
      "loss =  tensor(5483960.5000, grad_fn=<SubBackward0>)\n",
      "step =  1322\n",
      "loss =  tensor(5475755., grad_fn=<SubBackward0>)\n",
      "step =  1323\n",
      "loss =  tensor(5485568., grad_fn=<SubBackward0>)\n",
      "step =  1324\n",
      "loss =  tensor(5474394.5000, grad_fn=<SubBackward0>)\n",
      "step =  1325\n",
      "loss =  tensor(5466955., grad_fn=<SubBackward0>)\n",
      "step =  1326\n",
      "loss =  tensor(5471028., grad_fn=<SubBackward0>)\n",
      "step =  1327\n",
      "loss =  tensor(5499906., grad_fn=<SubBackward0>)\n",
      "step =  1328\n",
      "loss =  tensor(5499926.5000, grad_fn=<SubBackward0>)\n",
      "step =  1329\n",
      "loss =  tensor(5481602., grad_fn=<SubBackward0>)\n",
      "step =  1330\n",
      "loss =  tensor(5479911., grad_fn=<SubBackward0>)\n",
      "step =  1331\n",
      "loss =  tensor(5477338., grad_fn=<SubBackward0>)\n",
      "step =  1332\n",
      "loss =  tensor(5485264., grad_fn=<SubBackward0>)\n",
      "step =  1333\n",
      "loss =  tensor(5492544., grad_fn=<SubBackward0>)\n",
      "step =  1334\n",
      "loss =  tensor(5481956., grad_fn=<SubBackward0>)\n",
      "step =  1335\n",
      "loss =  tensor(5481684., grad_fn=<SubBackward0>)\n",
      "step =  1336\n",
      "loss =  tensor(5456579.5000, grad_fn=<SubBackward0>)\n",
      "step =  1337\n",
      "loss =  tensor(5479192., grad_fn=<SubBackward0>)\n",
      "step =  1338\n",
      "loss =  tensor(5473347., grad_fn=<SubBackward0>)\n",
      "step =  1339\n",
      "loss =  tensor(5480856., grad_fn=<SubBackward0>)\n",
      "step =  1340\n",
      "loss =  tensor(5500622., grad_fn=<SubBackward0>)\n",
      "step =  1341\n",
      "loss =  tensor(5480337., grad_fn=<SubBackward0>)\n",
      "step =  1342\n",
      "loss =  tensor(5487421., grad_fn=<SubBackward0>)\n",
      "step =  1343\n",
      "loss =  tensor(5494448.5000, grad_fn=<SubBackward0>)\n",
      "step =  1344\n",
      "loss =  tensor(5510981.5000, grad_fn=<SubBackward0>)\n",
      "step =  1345\n",
      "loss =  tensor(5511590., grad_fn=<SubBackward0>)\n",
      "step =  1346\n",
      "loss =  tensor(5450572., grad_fn=<SubBackward0>)\n",
      "step =  1347\n",
      "loss =  tensor(5498257., grad_fn=<SubBackward0>)\n",
      "step =  1348\n",
      "loss =  tensor(5483513., grad_fn=<SubBackward0>)\n",
      "step =  1349\n",
      "loss =  tensor(5485733.5000, grad_fn=<SubBackward0>)\n",
      "step =  1350\n",
      "loss =  tensor(5496613.5000, grad_fn=<SubBackward0>)\n",
      "step =  1351\n",
      "loss =  tensor(5499107., grad_fn=<SubBackward0>)\n",
      "step =  1352\n",
      "loss =  tensor(5481496., grad_fn=<SubBackward0>)\n",
      "step =  1353\n",
      "loss =  tensor(5456397., grad_fn=<SubBackward0>)\n",
      "step =  1354\n",
      "loss =  tensor(5485145., grad_fn=<SubBackward0>)\n",
      "step =  1355\n",
      "loss =  tensor(5495895.5000, grad_fn=<SubBackward0>)\n",
      "step =  1356\n",
      "loss =  tensor(5496594., grad_fn=<SubBackward0>)\n",
      "step =  1357\n",
      "loss =  tensor(5470355., grad_fn=<SubBackward0>)\n",
      "step =  1358\n",
      "loss =  tensor(5486618., grad_fn=<SubBackward0>)\n",
      "step =  1359\n",
      "loss =  tensor(5503400., grad_fn=<SubBackward0>)\n",
      "step =  1360\n",
      "loss =  tensor(5502894., grad_fn=<SubBackward0>)\n",
      "step =  1361\n",
      "loss =  tensor(5464516., grad_fn=<SubBackward0>)\n",
      "step =  1362\n",
      "loss =  tensor(5465581., grad_fn=<SubBackward0>)\n",
      "step =  1363\n",
      "loss =  tensor(5477910., grad_fn=<SubBackward0>)\n",
      "step =  1364\n",
      "loss =  tensor(5483000., grad_fn=<SubBackward0>)\n",
      "step =  1365\n",
      "loss =  tensor(5487693., grad_fn=<SubBackward0>)\n",
      "step =  1366\n",
      "loss =  tensor(5476147.5000, grad_fn=<SubBackward0>)\n",
      "step =  1367\n",
      "loss =  tensor(5499219.5000, grad_fn=<SubBackward0>)\n",
      "step =  1368\n",
      "loss =  tensor(5449508.5000, grad_fn=<SubBackward0>)\n",
      "step =  1369\n",
      "loss =  tensor(5478322., grad_fn=<SubBackward0>)\n",
      "step =  1370\n",
      "loss =  tensor(5485438., grad_fn=<SubBackward0>)\n",
      "step =  1371\n",
      "loss =  tensor(5488353., grad_fn=<SubBackward0>)\n",
      "step =  1372\n",
      "loss =  tensor(5488033., grad_fn=<SubBackward0>)\n",
      "step =  1373\n",
      "loss =  tensor(5484426., grad_fn=<SubBackward0>)\n",
      "step =  1374\n",
      "loss =  tensor(5473665.5000, grad_fn=<SubBackward0>)\n",
      "step =  1375\n",
      "loss =  tensor(5503656., grad_fn=<SubBackward0>)\n",
      "step =  1376\n",
      "loss =  tensor(5477413., grad_fn=<SubBackward0>)\n",
      "step =  1377\n",
      "loss =  tensor(5478440., grad_fn=<SubBackward0>)\n",
      "step =  1378\n",
      "loss =  tensor(5471657., grad_fn=<SubBackward0>)\n",
      "step =  1379\n",
      "loss =  tensor(5508453., grad_fn=<SubBackward0>)\n",
      "step =  1380\n",
      "loss =  tensor(5481583., grad_fn=<SubBackward0>)\n",
      "step =  1381\n",
      "loss =  tensor(5461365., grad_fn=<SubBackward0>)\n",
      "step =  1382\n",
      "loss =  tensor(5474024., grad_fn=<SubBackward0>)\n",
      "step =  1383\n",
      "loss =  tensor(5477525., grad_fn=<SubBackward0>)\n",
      "step =  1384\n",
      "loss =  tensor(5483672., grad_fn=<SubBackward0>)\n",
      "step =  1385\n",
      "loss =  tensor(5506216., grad_fn=<SubBackward0>)\n",
      "step =  1386\n",
      "loss =  tensor(5491155., grad_fn=<SubBackward0>)\n",
      "step =  1387\n",
      "loss =  tensor(5488168.5000, grad_fn=<SubBackward0>)\n",
      "step =  1388\n",
      "loss =  tensor(5475416.5000, grad_fn=<SubBackward0>)\n",
      "step =  1389\n",
      "loss =  tensor(5493976., grad_fn=<SubBackward0>)\n",
      "step =  1390\n",
      "loss =  tensor(5473353., grad_fn=<SubBackward0>)\n",
      "step =  1391\n",
      "loss =  tensor(5470208., grad_fn=<SubBackward0>)\n",
      "step =  1392\n",
      "loss =  tensor(5498526., grad_fn=<SubBackward0>)\n",
      "step =  1393\n",
      "loss =  tensor(5475370., grad_fn=<SubBackward0>)\n",
      "step =  1394\n",
      "loss =  tensor(5464922.5000, grad_fn=<SubBackward0>)\n",
      "step =  1395\n",
      "loss =  tensor(5483348., grad_fn=<SubBackward0>)\n",
      "step =  1396\n",
      "loss =  tensor(5473110., grad_fn=<SubBackward0>)\n",
      "step =  1397\n",
      "loss =  tensor(5487759.5000, grad_fn=<SubBackward0>)\n",
      "step =  1398\n",
      "loss =  tensor(5479041., grad_fn=<SubBackward0>)\n",
      "step =  1399\n",
      "loss =  tensor(5453431., grad_fn=<SubBackward0>)\n",
      "step =  1400\n",
      "loss =  tensor(5466221.5000, grad_fn=<SubBackward0>)\n",
      "step =  1401\n",
      "loss =  tensor(5466738., grad_fn=<SubBackward0>)\n",
      "step =  1402\n",
      "loss =  tensor(5467984.5000, grad_fn=<SubBackward0>)\n",
      "step =  1403\n",
      "loss =  tensor(5483961., grad_fn=<SubBackward0>)\n",
      "step =  1404\n",
      "loss =  tensor(5492835., grad_fn=<SubBackward0>)\n",
      "step =  1405\n",
      "loss =  tensor(5485127., grad_fn=<SubBackward0>)\n",
      "step =  1406\n",
      "loss =  tensor(5480436.5000, grad_fn=<SubBackward0>)\n",
      "step =  1407\n",
      "loss =  tensor(5501182., grad_fn=<SubBackward0>)\n",
      "step =  1408\n",
      "loss =  tensor(5484352., grad_fn=<SubBackward0>)\n",
      "step =  1409\n",
      "loss =  tensor(5471762., grad_fn=<SubBackward0>)\n",
      "step =  1410\n",
      "loss =  tensor(5463140.5000, grad_fn=<SubBackward0>)\n",
      "step =  1411\n",
      "loss =  tensor(5478827., grad_fn=<SubBackward0>)\n",
      "step =  1412\n",
      "loss =  tensor(5481154.5000, grad_fn=<SubBackward0>)\n",
      "step =  1413\n",
      "loss =  tensor(5491880., grad_fn=<SubBackward0>)\n",
      "step =  1414\n",
      "loss =  tensor(5482577.5000, grad_fn=<SubBackward0>)\n",
      "step =  1415\n",
      "loss =  tensor(5479128.5000, grad_fn=<SubBackward0>)\n",
      "step =  1416\n",
      "loss =  tensor(5503732., grad_fn=<SubBackward0>)\n",
      "step =  1417\n",
      "loss =  tensor(5490422.5000, grad_fn=<SubBackward0>)\n",
      "step =  1418\n",
      "loss =  tensor(5497102., grad_fn=<SubBackward0>)\n",
      "step =  1419\n",
      "loss =  tensor(5482152., grad_fn=<SubBackward0>)\n",
      "step =  1420\n",
      "loss =  tensor(5484398., grad_fn=<SubBackward0>)\n",
      "step =  1421\n",
      "loss =  tensor(5484635., grad_fn=<SubBackward0>)\n",
      "step =  1422\n",
      "loss =  tensor(5477784., grad_fn=<SubBackward0>)\n",
      "step =  1423\n",
      "loss =  tensor(5471139., grad_fn=<SubBackward0>)\n",
      "step =  1424\n",
      "loss =  tensor(5489123., grad_fn=<SubBackward0>)\n",
      "step =  1425\n",
      "loss =  tensor(5467809.5000, grad_fn=<SubBackward0>)\n",
      "step =  1426\n",
      "loss =  tensor(5511855., grad_fn=<SubBackward0>)\n",
      "step =  1427\n",
      "loss =  tensor(5477233., grad_fn=<SubBackward0>)\n",
      "step =  1428\n",
      "loss =  tensor(5485737., grad_fn=<SubBackward0>)\n",
      "step =  1429\n",
      "loss =  tensor(5479208.5000, grad_fn=<SubBackward0>)\n",
      "step =  1430\n",
      "loss =  tensor(5469412.5000, grad_fn=<SubBackward0>)\n",
      "step =  1431\n",
      "loss =  tensor(5496104., grad_fn=<SubBackward0>)\n",
      "step =  1432\n",
      "loss =  tensor(5497137., grad_fn=<SubBackward0>)\n",
      "step =  1433\n",
      "loss =  tensor(5479430., grad_fn=<SubBackward0>)\n",
      "step =  1434\n",
      "loss =  tensor(5453048., grad_fn=<SubBackward0>)\n",
      "step =  1435\n",
      "loss =  tensor(5483191., grad_fn=<SubBackward0>)\n",
      "step =  1436\n",
      "loss =  tensor(5485853., grad_fn=<SubBackward0>)\n",
      "step =  1437\n",
      "loss =  tensor(5509991.5000, grad_fn=<SubBackward0>)\n",
      "step =  1438\n",
      "loss =  tensor(5469450.5000, grad_fn=<SubBackward0>)\n",
      "step =  1439\n",
      "loss =  tensor(5486059., grad_fn=<SubBackward0>)\n",
      "step =  1440\n",
      "loss =  tensor(5474566., grad_fn=<SubBackward0>)\n",
      "step =  1441\n",
      "loss =  tensor(5468524., grad_fn=<SubBackward0>)\n",
      "step =  1442\n",
      "loss =  tensor(5483819.5000, grad_fn=<SubBackward0>)\n",
      "step =  1443\n",
      "loss =  tensor(5493118., grad_fn=<SubBackward0>)\n",
      "step =  1444\n",
      "loss =  tensor(5478153., grad_fn=<SubBackward0>)\n",
      "step =  1445\n",
      "loss =  tensor(5484117., grad_fn=<SubBackward0>)\n",
      "step =  1446\n",
      "loss =  tensor(5493360., grad_fn=<SubBackward0>)\n",
      "step =  1447\n",
      "loss =  tensor(5461390.5000, grad_fn=<SubBackward0>)\n",
      "step =  1448\n",
      "loss =  tensor(5489613., grad_fn=<SubBackward0>)\n",
      "step =  1449\n",
      "loss =  tensor(5468012.5000, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  1450\n",
      "loss =  tensor(5488883., grad_fn=<SubBackward0>)\n",
      "step =  1451\n",
      "loss =  tensor(5480774.5000, grad_fn=<SubBackward0>)\n",
      "step =  1452\n",
      "loss =  tensor(5465174., grad_fn=<SubBackward0>)\n",
      "step =  1453\n",
      "loss =  tensor(5487012.5000, grad_fn=<SubBackward0>)\n",
      "step =  1454\n",
      "loss =  tensor(5468548.5000, grad_fn=<SubBackward0>)\n",
      "step =  1455\n",
      "loss =  tensor(5490356., grad_fn=<SubBackward0>)\n",
      "step =  1456\n",
      "loss =  tensor(5472243.5000, grad_fn=<SubBackward0>)\n",
      "step =  1457\n",
      "loss =  tensor(5468991., grad_fn=<SubBackward0>)\n",
      "step =  1458\n",
      "loss =  tensor(5505733., grad_fn=<SubBackward0>)\n",
      "step =  1459\n",
      "loss =  tensor(5488969., grad_fn=<SubBackward0>)\n",
      "step =  1460\n",
      "loss =  tensor(5476175., grad_fn=<SubBackward0>)\n",
      "step =  1461\n",
      "loss =  tensor(5460438.5000, grad_fn=<SubBackward0>)\n",
      "step =  1462\n",
      "loss =  tensor(5486719., grad_fn=<SubBackward0>)\n",
      "step =  1463\n",
      "loss =  tensor(5486574.5000, grad_fn=<SubBackward0>)\n",
      "step =  1464\n",
      "loss =  tensor(5482745., grad_fn=<SubBackward0>)\n",
      "step =  1465\n",
      "loss =  tensor(5495201., grad_fn=<SubBackward0>)\n",
      "step =  1466\n",
      "loss =  tensor(5464664.5000, grad_fn=<SubBackward0>)\n",
      "step =  1467\n",
      "loss =  tensor(5481165., grad_fn=<SubBackward0>)\n",
      "step =  1468\n",
      "loss =  tensor(5484572., grad_fn=<SubBackward0>)\n",
      "step =  1469\n",
      "loss =  tensor(5503377., grad_fn=<SubBackward0>)\n",
      "step =  1470\n",
      "loss =  tensor(5476476., grad_fn=<SubBackward0>)\n",
      "step =  1471\n",
      "loss =  tensor(5463745., grad_fn=<SubBackward0>)\n",
      "step =  1472\n",
      "loss =  tensor(5484901., grad_fn=<SubBackward0>)\n",
      "step =  1473\n",
      "loss =  tensor(5491620., grad_fn=<SubBackward0>)\n",
      "step =  1474\n",
      "loss =  tensor(5484300., grad_fn=<SubBackward0>)\n",
      "step =  1475\n",
      "loss =  tensor(5484310., grad_fn=<SubBackward0>)\n",
      "step =  1476\n",
      "loss =  tensor(5495006., grad_fn=<SubBackward0>)\n",
      "step =  1477\n",
      "loss =  tensor(5487494., grad_fn=<SubBackward0>)\n",
      "step =  1478\n",
      "loss =  tensor(5512078., grad_fn=<SubBackward0>)\n",
      "step =  1479\n",
      "loss =  tensor(5454012.5000, grad_fn=<SubBackward0>)\n",
      "step =  1480\n",
      "loss =  tensor(5499060.5000, grad_fn=<SubBackward0>)\n",
      "step =  1481\n",
      "loss =  tensor(5461494., grad_fn=<SubBackward0>)\n",
      "step =  1482\n",
      "loss =  tensor(5493425.5000, grad_fn=<SubBackward0>)\n",
      "step =  1483\n",
      "loss =  tensor(5495059., grad_fn=<SubBackward0>)\n",
      "step =  1484\n",
      "loss =  tensor(5496958., grad_fn=<SubBackward0>)\n",
      "step =  1485\n",
      "loss =  tensor(5492738., grad_fn=<SubBackward0>)\n",
      "step =  1486\n",
      "loss =  tensor(5501543.5000, grad_fn=<SubBackward0>)\n",
      "step =  1487\n",
      "loss =  tensor(5484832.5000, grad_fn=<SubBackward0>)\n",
      "step =  1488\n",
      "loss =  tensor(5491022., grad_fn=<SubBackward0>)\n",
      "step =  1489\n",
      "loss =  tensor(5462199., grad_fn=<SubBackward0>)\n",
      "step =  1490\n",
      "loss =  tensor(5483369.5000, grad_fn=<SubBackward0>)\n",
      "step =  1491\n",
      "loss =  tensor(5462633., grad_fn=<SubBackward0>)\n",
      "step =  1492\n",
      "loss =  tensor(5467324., grad_fn=<SubBackward0>)\n",
      "step =  1493\n",
      "loss =  tensor(5464857., grad_fn=<SubBackward0>)\n",
      "step =  1494\n",
      "loss =  tensor(5499459.5000, grad_fn=<SubBackward0>)\n",
      "step =  1495\n",
      "loss =  tensor(5462377., grad_fn=<SubBackward0>)\n",
      "step =  1496\n",
      "loss =  tensor(5470004., grad_fn=<SubBackward0>)\n",
      "step =  1497\n",
      "loss =  tensor(5467891., grad_fn=<SubBackward0>)\n",
      "step =  1498\n",
      "loss =  tensor(5493968., grad_fn=<SubBackward0>)\n",
      "step =  1499\n",
      "loss =  tensor(5477668.5000, grad_fn=<SubBackward0>)\n",
      "step =  1500\n",
      "loss =  tensor(5469022.5000, grad_fn=<SubBackward0>)\n",
      "step =  1501\n",
      "loss =  tensor(5476212.5000, grad_fn=<SubBackward0>)\n",
      "step =  1502\n",
      "loss =  tensor(5507353., grad_fn=<SubBackward0>)\n",
      "step =  1503\n",
      "loss =  tensor(5493585., grad_fn=<SubBackward0>)\n",
      "step =  1504\n",
      "loss =  tensor(5455406., grad_fn=<SubBackward0>)\n",
      "step =  1505\n",
      "loss =  tensor(5485120., grad_fn=<SubBackward0>)\n",
      "step =  1506\n",
      "loss =  tensor(5484982., grad_fn=<SubBackward0>)\n",
      "step =  1507\n",
      "loss =  tensor(5475019.5000, grad_fn=<SubBackward0>)\n",
      "step =  1508\n",
      "loss =  tensor(5459211., grad_fn=<SubBackward0>)\n",
      "step =  1509\n",
      "loss =  tensor(5485413.5000, grad_fn=<SubBackward0>)\n",
      "step =  1510\n",
      "loss =  tensor(5497050., grad_fn=<SubBackward0>)\n",
      "step =  1511\n",
      "loss =  tensor(5498306., grad_fn=<SubBackward0>)\n",
      "step =  1512\n",
      "loss =  tensor(5462418., grad_fn=<SubBackward0>)\n",
      "step =  1513\n",
      "loss =  tensor(5495125., grad_fn=<SubBackward0>)\n",
      "step =  1514\n",
      "loss =  tensor(5475060., grad_fn=<SubBackward0>)\n",
      "step =  1515\n",
      "loss =  tensor(5475827., grad_fn=<SubBackward0>)\n",
      "step =  1516\n",
      "loss =  tensor(5471604.5000, grad_fn=<SubBackward0>)\n",
      "step =  1517\n",
      "loss =  tensor(5458643., grad_fn=<SubBackward0>)\n",
      "step =  1518\n",
      "loss =  tensor(5474533., grad_fn=<SubBackward0>)\n",
      "step =  1519\n",
      "loss =  tensor(5475133., grad_fn=<SubBackward0>)\n",
      "step =  1520\n",
      "loss =  tensor(5503157., grad_fn=<SubBackward0>)\n",
      "step =  1521\n",
      "loss =  tensor(5497735., grad_fn=<SubBackward0>)\n",
      "step =  1522\n",
      "loss =  tensor(5502906., grad_fn=<SubBackward0>)\n",
      "step =  1523\n",
      "loss =  tensor(5480887., grad_fn=<SubBackward0>)\n",
      "step =  1524\n",
      "loss =  tensor(5492911., grad_fn=<SubBackward0>)\n",
      "step =  1525\n",
      "loss =  tensor(5461038.5000, grad_fn=<SubBackward0>)\n",
      "step =  1526\n",
      "loss =  tensor(5481575., grad_fn=<SubBackward0>)\n",
      "step =  1527\n",
      "loss =  tensor(5450479., grad_fn=<SubBackward0>)\n",
      "step =  1528\n",
      "loss =  tensor(5482053.5000, grad_fn=<SubBackward0>)\n",
      "step =  1529\n",
      "loss =  tensor(5464178.5000, grad_fn=<SubBackward0>)\n",
      "step =  1530\n",
      "loss =  tensor(5492734., grad_fn=<SubBackward0>)\n",
      "step =  1531\n",
      "loss =  tensor(5482436., grad_fn=<SubBackward0>)\n",
      "step =  1532\n",
      "loss =  tensor(5472502.5000, grad_fn=<SubBackward0>)\n",
      "step =  1533\n",
      "loss =  tensor(5476681.5000, grad_fn=<SubBackward0>)\n",
      "step =  1534\n",
      "loss =  tensor(5480706., grad_fn=<SubBackward0>)\n",
      "step =  1535\n",
      "loss =  tensor(5475788., grad_fn=<SubBackward0>)\n",
      "step =  1536\n",
      "loss =  tensor(5462888., grad_fn=<SubBackward0>)\n",
      "step =  1537\n",
      "loss =  tensor(5462399., grad_fn=<SubBackward0>)\n",
      "step =  1538\n",
      "loss =  tensor(5489316.5000, grad_fn=<SubBackward0>)\n",
      "step =  1539\n",
      "loss =  tensor(5470556.5000, grad_fn=<SubBackward0>)\n",
      "step =  1540\n",
      "loss =  tensor(5469489., grad_fn=<SubBackward0>)\n",
      "step =  1541\n",
      "loss =  tensor(5464701., grad_fn=<SubBackward0>)\n",
      "step =  1542\n",
      "loss =  tensor(5462866.5000, grad_fn=<SubBackward0>)\n",
      "step =  1543\n",
      "loss =  tensor(5467334., grad_fn=<SubBackward0>)\n",
      "step =  1544\n",
      "loss =  tensor(5482147.5000, grad_fn=<SubBackward0>)\n",
      "step =  1545\n",
      "loss =  tensor(5510354.5000, grad_fn=<SubBackward0>)\n",
      "step =  1546\n",
      "loss =  tensor(5469760., grad_fn=<SubBackward0>)\n",
      "step =  1547\n",
      "loss =  tensor(5485327.5000, grad_fn=<SubBackward0>)\n",
      "step =  1548\n",
      "loss =  tensor(5493377., grad_fn=<SubBackward0>)\n",
      "step =  1549\n",
      "loss =  tensor(5477188., grad_fn=<SubBackward0>)\n",
      "step =  1550\n",
      "loss =  tensor(5464914., grad_fn=<SubBackward0>)\n",
      "step =  1551\n",
      "loss =  tensor(5452252.5000, grad_fn=<SubBackward0>)\n",
      "step =  1552\n",
      "loss =  tensor(5477607., grad_fn=<SubBackward0>)\n",
      "step =  1553\n",
      "loss =  tensor(5467404.5000, grad_fn=<SubBackward0>)\n",
      "step =  1554\n",
      "loss =  tensor(5469511., grad_fn=<SubBackward0>)\n",
      "step =  1555\n",
      "loss =  tensor(5486824., grad_fn=<SubBackward0>)\n",
      "step =  1556\n",
      "loss =  tensor(5492588., grad_fn=<SubBackward0>)\n",
      "step =  1557\n",
      "loss =  tensor(5484694., grad_fn=<SubBackward0>)\n",
      "step =  1558\n",
      "loss =  tensor(5490652., grad_fn=<SubBackward0>)\n",
      "step =  1559\n",
      "loss =  tensor(5498530., grad_fn=<SubBackward0>)\n",
      "step =  1560\n",
      "loss =  tensor(5457424., grad_fn=<SubBackward0>)\n",
      "step =  1561\n",
      "loss =  tensor(5479888., grad_fn=<SubBackward0>)\n",
      "step =  1562\n",
      "loss =  tensor(5492263.5000, grad_fn=<SubBackward0>)\n",
      "step =  1563\n",
      "loss =  tensor(5487774., grad_fn=<SubBackward0>)\n",
      "step =  1564\n",
      "loss =  tensor(5480964., grad_fn=<SubBackward0>)\n",
      "step =  1565\n",
      "loss =  tensor(5447588.5000, grad_fn=<SubBackward0>)\n",
      "step =  1566\n",
      "loss =  tensor(5449366., grad_fn=<SubBackward0>)\n",
      "step =  1567\n",
      "loss =  tensor(5486344., grad_fn=<SubBackward0>)\n",
      "step =  1568\n",
      "loss =  tensor(5489992.5000, grad_fn=<SubBackward0>)\n",
      "step =  1569\n",
      "loss =  tensor(5468898., grad_fn=<SubBackward0>)\n",
      "step =  1570\n",
      "loss =  tensor(5483781.5000, grad_fn=<SubBackward0>)\n",
      "step =  1571\n",
      "loss =  tensor(5473406., grad_fn=<SubBackward0>)\n",
      "step =  1572\n",
      "loss =  tensor(5499975., grad_fn=<SubBackward0>)\n",
      "step =  1573\n",
      "loss =  tensor(5490679.5000, grad_fn=<SubBackward0>)\n",
      "step =  1574\n",
      "loss =  tensor(5487282., grad_fn=<SubBackward0>)\n",
      "step =  1575\n",
      "loss =  tensor(5473506., grad_fn=<SubBackward0>)\n",
      "step =  1576\n",
      "loss =  tensor(5480621.5000, grad_fn=<SubBackward0>)\n",
      "step =  1577\n",
      "loss =  tensor(5470969., grad_fn=<SubBackward0>)\n",
      "step =  1578\n",
      "loss =  tensor(5503438., grad_fn=<SubBackward0>)\n",
      "step =  1579\n",
      "loss =  tensor(5470560., grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  1580\n",
      "loss =  tensor(5464710., grad_fn=<SubBackward0>)\n",
      "step =  1581\n",
      "loss =  tensor(5487651.5000, grad_fn=<SubBackward0>)\n",
      "step =  1582\n",
      "loss =  tensor(5473045.5000, grad_fn=<SubBackward0>)\n",
      "step =  1583\n",
      "loss =  tensor(5504726., grad_fn=<SubBackward0>)\n",
      "step =  1584\n",
      "loss =  tensor(5475622., grad_fn=<SubBackward0>)\n",
      "step =  1585\n",
      "loss =  tensor(5476967., grad_fn=<SubBackward0>)\n",
      "step =  1586\n",
      "loss =  tensor(5464166., grad_fn=<SubBackward0>)\n",
      "step =  1587\n",
      "loss =  tensor(5491172.5000, grad_fn=<SubBackward0>)\n",
      "step =  1588\n",
      "loss =  tensor(5488254., grad_fn=<SubBackward0>)\n",
      "step =  1589\n",
      "loss =  tensor(5471486., grad_fn=<SubBackward0>)\n",
      "step =  1590\n",
      "loss =  tensor(5466835., grad_fn=<SubBackward0>)\n",
      "step =  1591\n",
      "loss =  tensor(5489596.5000, grad_fn=<SubBackward0>)\n",
      "step =  1592\n",
      "loss =  tensor(5460420., grad_fn=<SubBackward0>)\n",
      "step =  1593\n",
      "loss =  tensor(5469276.5000, grad_fn=<SubBackward0>)\n",
      "step =  1594\n",
      "loss =  tensor(5465491.5000, grad_fn=<SubBackward0>)\n",
      "step =  1595\n",
      "loss =  tensor(5452208., grad_fn=<SubBackward0>)\n",
      "step =  1596\n",
      "loss =  tensor(5455271., grad_fn=<SubBackward0>)\n",
      "step =  1597\n",
      "loss =  tensor(5469649.5000, grad_fn=<SubBackward0>)\n",
      "step =  1598\n",
      "loss =  tensor(5459167., grad_fn=<SubBackward0>)\n",
      "step =  1599\n",
      "loss =  tensor(5489899., grad_fn=<SubBackward0>)\n",
      "step =  1600\n",
      "loss =  tensor(5492967., grad_fn=<SubBackward0>)\n",
      "step =  1601\n",
      "loss =  tensor(5470473., grad_fn=<SubBackward0>)\n",
      "step =  1602\n",
      "loss =  tensor(5494461., grad_fn=<SubBackward0>)\n",
      "step =  1603\n",
      "loss =  tensor(5495249., grad_fn=<SubBackward0>)\n",
      "step =  1604\n",
      "loss =  tensor(5466617., grad_fn=<SubBackward0>)\n",
      "step =  1605\n",
      "loss =  tensor(5485170.5000, grad_fn=<SubBackward0>)\n",
      "step =  1606\n",
      "loss =  tensor(5501310., grad_fn=<SubBackward0>)\n",
      "step =  1607\n",
      "loss =  tensor(5478032., grad_fn=<SubBackward0>)\n",
      "step =  1608\n",
      "loss =  tensor(5462870., grad_fn=<SubBackward0>)\n",
      "step =  1609\n",
      "loss =  tensor(5477983.5000, grad_fn=<SubBackward0>)\n",
      "step =  1610\n",
      "loss =  tensor(5465894., grad_fn=<SubBackward0>)\n",
      "step =  1611\n",
      "loss =  tensor(5450233.5000, grad_fn=<SubBackward0>)\n",
      "step =  1612\n",
      "loss =  tensor(5500912., grad_fn=<SubBackward0>)\n",
      "step =  1613\n",
      "loss =  tensor(5453124., grad_fn=<SubBackward0>)\n",
      "step =  1614\n",
      "loss =  tensor(5471785., grad_fn=<SubBackward0>)\n",
      "step =  1615\n",
      "loss =  tensor(5451867., grad_fn=<SubBackward0>)\n",
      "step =  1616\n",
      "loss =  tensor(5469595., grad_fn=<SubBackward0>)\n",
      "step =  1617\n",
      "loss =  tensor(5467773.5000, grad_fn=<SubBackward0>)\n",
      "step =  1618\n",
      "loss =  tensor(5478702., grad_fn=<SubBackward0>)\n",
      "step =  1619\n",
      "loss =  tensor(5496121., grad_fn=<SubBackward0>)\n",
      "step =  1620\n",
      "loss =  tensor(5481010.5000, grad_fn=<SubBackward0>)\n",
      "step =  1621\n",
      "loss =  tensor(5474259., grad_fn=<SubBackward0>)\n",
      "step =  1622\n",
      "loss =  tensor(5482581., grad_fn=<SubBackward0>)\n",
      "step =  1623\n",
      "loss =  tensor(5457715., grad_fn=<SubBackward0>)\n",
      "step =  1624\n",
      "loss =  tensor(5471964., grad_fn=<SubBackward0>)\n",
      "step =  1625\n",
      "loss =  tensor(5490696., grad_fn=<SubBackward0>)\n",
      "step =  1626\n",
      "loss =  tensor(5494046., grad_fn=<SubBackward0>)\n",
      "step =  1627\n",
      "loss =  tensor(5465171., grad_fn=<SubBackward0>)\n",
      "step =  1628\n",
      "loss =  tensor(5476478.5000, grad_fn=<SubBackward0>)\n",
      "step =  1629\n",
      "loss =  tensor(5478781., grad_fn=<SubBackward0>)\n",
      "step =  1630\n",
      "loss =  tensor(5473746., grad_fn=<SubBackward0>)\n",
      "step =  1631\n",
      "loss =  tensor(5488492., grad_fn=<SubBackward0>)\n",
      "step =  1632\n",
      "loss =  tensor(5492962.5000, grad_fn=<SubBackward0>)\n",
      "step =  1633\n",
      "loss =  tensor(5444536., grad_fn=<SubBackward0>)\n",
      "step =  1634\n",
      "loss =  tensor(5470452.5000, grad_fn=<SubBackward0>)\n",
      "step =  1635\n",
      "loss =  tensor(5458670., grad_fn=<SubBackward0>)\n",
      "step =  1636\n",
      "loss =  tensor(5469984., grad_fn=<SubBackward0>)\n",
      "step =  1637\n",
      "loss =  tensor(5442119., grad_fn=<SubBackward0>)\n",
      "step =  1638\n",
      "loss =  tensor(5498925.5000, grad_fn=<SubBackward0>)\n",
      "step =  1639\n",
      "loss =  tensor(5481033., grad_fn=<SubBackward0>)\n",
      "step =  1640\n",
      "loss =  tensor(5521639., grad_fn=<SubBackward0>)\n",
      "step =  1641\n",
      "loss =  tensor(5480370., grad_fn=<SubBackward0>)\n",
      "step =  1642\n",
      "loss =  tensor(5470018., grad_fn=<SubBackward0>)\n",
      "step =  1643\n",
      "loss =  tensor(5485092.5000, grad_fn=<SubBackward0>)\n",
      "step =  1644\n",
      "loss =  tensor(5499924., grad_fn=<SubBackward0>)\n",
      "step =  1645\n",
      "loss =  tensor(5468933.5000, grad_fn=<SubBackward0>)\n",
      "step =  1646\n",
      "loss =  tensor(5481143.5000, grad_fn=<SubBackward0>)\n",
      "step =  1647\n",
      "loss =  tensor(5489171., grad_fn=<SubBackward0>)\n",
      "step =  1648\n",
      "loss =  tensor(5456432., grad_fn=<SubBackward0>)\n",
      "step =  1649\n",
      "loss =  tensor(5487776.5000, grad_fn=<SubBackward0>)\n",
      "step =  1650\n",
      "loss =  tensor(5463597., grad_fn=<SubBackward0>)\n",
      "step =  1651\n",
      "loss =  tensor(5462398., grad_fn=<SubBackward0>)\n",
      "step =  1652\n",
      "loss =  tensor(5479391., grad_fn=<SubBackward0>)\n",
      "step =  1653\n",
      "loss =  tensor(5466322., grad_fn=<SubBackward0>)\n",
      "step =  1654\n",
      "loss =  tensor(5450624., grad_fn=<SubBackward0>)\n",
      "step =  1655\n",
      "loss =  tensor(5485626., grad_fn=<SubBackward0>)\n",
      "step =  1656\n",
      "loss =  tensor(5465098., grad_fn=<SubBackward0>)\n",
      "step =  1657\n",
      "loss =  tensor(5447372., grad_fn=<SubBackward0>)\n",
      "step =  1658\n",
      "loss =  tensor(5469599., grad_fn=<SubBackward0>)\n",
      "step =  1659\n",
      "loss =  tensor(5470962.5000, grad_fn=<SubBackward0>)\n",
      "step =  1660\n",
      "loss =  tensor(5493098., grad_fn=<SubBackward0>)\n",
      "step =  1661\n",
      "loss =  tensor(5483427., grad_fn=<SubBackward0>)\n",
      "step =  1662\n",
      "loss =  tensor(5476607., grad_fn=<SubBackward0>)\n",
      "step =  1663\n",
      "loss =  tensor(5493028., grad_fn=<SubBackward0>)\n",
      "step =  1664\n",
      "loss =  tensor(5484294., grad_fn=<SubBackward0>)\n",
      "step =  1665\n",
      "loss =  tensor(5454591., grad_fn=<SubBackward0>)\n",
      "step =  1666\n",
      "loss =  tensor(5489996., grad_fn=<SubBackward0>)\n",
      "step =  1667\n",
      "loss =  tensor(5472507., grad_fn=<SubBackward0>)\n",
      "step =  1668\n",
      "loss =  tensor(5463525., grad_fn=<SubBackward0>)\n",
      "step =  1669\n",
      "loss =  tensor(5490433., grad_fn=<SubBackward0>)\n",
      "step =  1670\n",
      "loss =  tensor(5477462., grad_fn=<SubBackward0>)\n",
      "step =  1671\n",
      "loss =  tensor(5478359., grad_fn=<SubBackward0>)\n",
      "step =  1672\n",
      "loss =  tensor(5470820.5000, grad_fn=<SubBackward0>)\n",
      "step =  1673\n",
      "loss =  tensor(5482322., grad_fn=<SubBackward0>)\n",
      "step =  1674\n",
      "loss =  tensor(5508166., grad_fn=<SubBackward0>)\n",
      "step =  1675\n",
      "loss =  tensor(5486130.5000, grad_fn=<SubBackward0>)\n",
      "step =  1676\n",
      "loss =  tensor(5469247., grad_fn=<SubBackward0>)\n",
      "step =  1677\n",
      "loss =  tensor(5461065., grad_fn=<SubBackward0>)\n",
      "step =  1678\n",
      "loss =  tensor(5458619.5000, grad_fn=<SubBackward0>)\n",
      "step =  1679\n",
      "loss =  tensor(5487128., grad_fn=<SubBackward0>)\n",
      "step =  1680\n",
      "loss =  tensor(5478244.5000, grad_fn=<SubBackward0>)\n",
      "step =  1681\n",
      "loss =  tensor(5481111., grad_fn=<SubBackward0>)\n",
      "step =  1682\n",
      "loss =  tensor(5504231., grad_fn=<SubBackward0>)\n",
      "step =  1683\n",
      "loss =  tensor(5461541., grad_fn=<SubBackward0>)\n",
      "step =  1684\n",
      "loss =  tensor(5496902., grad_fn=<SubBackward0>)\n",
      "step =  1685\n",
      "loss =  tensor(5490488.5000, grad_fn=<SubBackward0>)\n",
      "step =  1686\n",
      "loss =  tensor(5516519., grad_fn=<SubBackward0>)\n",
      "step =  1687\n",
      "loss =  tensor(5465176., grad_fn=<SubBackward0>)\n",
      "step =  1688\n",
      "loss =  tensor(5494135., grad_fn=<SubBackward0>)\n",
      "step =  1689\n",
      "loss =  tensor(5472744., grad_fn=<SubBackward0>)\n",
      "step =  1690\n",
      "loss =  tensor(5494591.5000, grad_fn=<SubBackward0>)\n",
      "step =  1691\n",
      "loss =  tensor(5488467., grad_fn=<SubBackward0>)\n",
      "step =  1692\n",
      "loss =  tensor(5475694., grad_fn=<SubBackward0>)\n",
      "step =  1693\n",
      "loss =  tensor(5477067.5000, grad_fn=<SubBackward0>)\n",
      "step =  1694\n",
      "loss =  tensor(5487971., grad_fn=<SubBackward0>)\n",
      "step =  1695\n",
      "loss =  tensor(5478775.5000, grad_fn=<SubBackward0>)\n",
      "step =  1696\n",
      "loss =  tensor(5480183.5000, grad_fn=<SubBackward0>)\n",
      "step =  1697\n",
      "loss =  tensor(5461237., grad_fn=<SubBackward0>)\n",
      "step =  1698\n",
      "loss =  tensor(5495197., grad_fn=<SubBackward0>)\n",
      "step =  1699\n",
      "loss =  tensor(5456314., grad_fn=<SubBackward0>)\n",
      "step =  1700\n",
      "loss =  tensor(5470492., grad_fn=<SubBackward0>)\n",
      "step =  1701\n",
      "loss =  tensor(5479796., grad_fn=<SubBackward0>)\n",
      "step =  1702\n",
      "loss =  tensor(5487774.5000, grad_fn=<SubBackward0>)\n",
      "step =  1703\n",
      "loss =  tensor(5475459., grad_fn=<SubBackward0>)\n",
      "step =  1704\n",
      "loss =  tensor(5476754., grad_fn=<SubBackward0>)\n",
      "step =  1705\n",
      "loss =  tensor(5479724., grad_fn=<SubBackward0>)\n",
      "step =  1706\n",
      "loss =  tensor(5483039.5000, grad_fn=<SubBackward0>)\n",
      "step =  1707\n",
      "loss =  tensor(5487557., grad_fn=<SubBackward0>)\n",
      "step =  1708\n",
      "loss =  tensor(5480406., grad_fn=<SubBackward0>)\n",
      "step =  1709\n",
      "loss =  tensor(5471256., grad_fn=<SubBackward0>)\n",
      "step =  1710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(5468048., grad_fn=<SubBackward0>)\n",
      "step =  1711\n",
      "loss =  tensor(5464315., grad_fn=<SubBackward0>)\n",
      "step =  1712\n",
      "loss =  tensor(5470807., grad_fn=<SubBackward0>)\n",
      "step =  1713\n",
      "loss =  tensor(5474448.5000, grad_fn=<SubBackward0>)\n",
      "step =  1714\n",
      "loss =  tensor(5482260.5000, grad_fn=<SubBackward0>)\n",
      "step =  1715\n",
      "loss =  tensor(5456609., grad_fn=<SubBackward0>)\n",
      "step =  1716\n",
      "loss =  tensor(5463645., grad_fn=<SubBackward0>)\n",
      "step =  1717\n",
      "loss =  tensor(5492184., grad_fn=<SubBackward0>)\n",
      "step =  1718\n",
      "loss =  tensor(5472189.5000, grad_fn=<SubBackward0>)\n",
      "step =  1719\n",
      "loss =  tensor(5467976.5000, grad_fn=<SubBackward0>)\n",
      "step =  1720\n",
      "loss =  tensor(5469462., grad_fn=<SubBackward0>)\n",
      "step =  1721\n",
      "loss =  tensor(5472299., grad_fn=<SubBackward0>)\n",
      "step =  1722\n",
      "loss =  tensor(5499162., grad_fn=<SubBackward0>)\n",
      "step =  1723\n",
      "loss =  tensor(5475487., grad_fn=<SubBackward0>)\n",
      "step =  1724\n",
      "loss =  tensor(5469556.5000, grad_fn=<SubBackward0>)\n",
      "step =  1725\n",
      "loss =  tensor(5470111., grad_fn=<SubBackward0>)\n",
      "step =  1726\n",
      "loss =  tensor(5461861., grad_fn=<SubBackward0>)\n",
      "step =  1727\n",
      "loss =  tensor(5480582., grad_fn=<SubBackward0>)\n",
      "step =  1728\n",
      "loss =  tensor(5485790., grad_fn=<SubBackward0>)\n",
      "step =  1729\n",
      "loss =  tensor(5463082.5000, grad_fn=<SubBackward0>)\n",
      "step =  1730\n",
      "loss =  tensor(5483048., grad_fn=<SubBackward0>)\n",
      "step =  1731\n",
      "loss =  tensor(5465832.5000, grad_fn=<SubBackward0>)\n",
      "step =  1732\n",
      "loss =  tensor(5490692., grad_fn=<SubBackward0>)\n",
      "step =  1733\n",
      "loss =  tensor(5477707., grad_fn=<SubBackward0>)\n",
      "step =  1734\n",
      "loss =  tensor(5476492., grad_fn=<SubBackward0>)\n",
      "step =  1735\n",
      "loss =  tensor(5485884.5000, grad_fn=<SubBackward0>)\n",
      "step =  1736\n",
      "loss =  tensor(5476562.5000, grad_fn=<SubBackward0>)\n",
      "step =  1737\n",
      "loss =  tensor(5508043.5000, grad_fn=<SubBackward0>)\n",
      "step =  1738\n",
      "loss =  tensor(5471920., grad_fn=<SubBackward0>)\n",
      "step =  1739\n",
      "loss =  tensor(5468746.5000, grad_fn=<SubBackward0>)\n",
      "step =  1740\n",
      "loss =  tensor(5454971., grad_fn=<SubBackward0>)\n",
      "step =  1741\n",
      "loss =  tensor(5489080., grad_fn=<SubBackward0>)\n",
      "step =  1742\n",
      "loss =  tensor(5476325., grad_fn=<SubBackward0>)\n",
      "step =  1743\n",
      "loss =  tensor(5484506., grad_fn=<SubBackward0>)\n",
      "step =  1744\n",
      "loss =  tensor(5483340., grad_fn=<SubBackward0>)\n",
      "step =  1745\n",
      "loss =  tensor(5466616., grad_fn=<SubBackward0>)\n",
      "step =  1746\n",
      "loss =  tensor(5455362., grad_fn=<SubBackward0>)\n",
      "step =  1747\n",
      "loss =  tensor(5484378.5000, grad_fn=<SubBackward0>)\n",
      "step =  1748\n",
      "loss =  tensor(5492514., grad_fn=<SubBackward0>)\n",
      "step =  1749\n",
      "loss =  tensor(5481161., grad_fn=<SubBackward0>)\n",
      "step =  1750\n",
      "loss =  tensor(5473794., grad_fn=<SubBackward0>)\n",
      "step =  1751\n",
      "loss =  tensor(5471188.5000, grad_fn=<SubBackward0>)\n",
      "step =  1752\n",
      "loss =  tensor(5486499., grad_fn=<SubBackward0>)\n",
      "step =  1753\n",
      "loss =  tensor(5499530., grad_fn=<SubBackward0>)\n",
      "step =  1754\n",
      "loss =  tensor(5453452., grad_fn=<SubBackward0>)\n",
      "step =  1755\n",
      "loss =  tensor(5484002., grad_fn=<SubBackward0>)\n",
      "step =  1756\n",
      "loss =  tensor(5486525.5000, grad_fn=<SubBackward0>)\n",
      "step =  1757\n",
      "loss =  tensor(5480342., grad_fn=<SubBackward0>)\n",
      "step =  1758\n",
      "loss =  tensor(5497221., grad_fn=<SubBackward0>)\n",
      "step =  1759\n",
      "loss =  tensor(5474648., grad_fn=<SubBackward0>)\n",
      "step =  1760\n",
      "loss =  tensor(5457671.5000, grad_fn=<SubBackward0>)\n",
      "step =  1761\n",
      "loss =  tensor(5497550., grad_fn=<SubBackward0>)\n",
      "step =  1762\n",
      "loss =  tensor(5486797., grad_fn=<SubBackward0>)\n",
      "step =  1763\n",
      "loss =  tensor(5481540.5000, grad_fn=<SubBackward0>)\n",
      "step =  1764\n",
      "loss =  tensor(5502330., grad_fn=<SubBackward0>)\n",
      "step =  1765\n",
      "loss =  tensor(5488923.5000, grad_fn=<SubBackward0>)\n",
      "step =  1766\n",
      "loss =  tensor(5484387., grad_fn=<SubBackward0>)\n",
      "step =  1767\n",
      "loss =  tensor(5459802., grad_fn=<SubBackward0>)\n",
      "step =  1768\n",
      "loss =  tensor(5489499.5000, grad_fn=<SubBackward0>)\n",
      "step =  1769\n",
      "loss =  tensor(5441868., grad_fn=<SubBackward0>)\n",
      "step =  1770\n",
      "loss =  tensor(5486386., grad_fn=<SubBackward0>)\n",
      "step =  1771\n",
      "loss =  tensor(5460020., grad_fn=<SubBackward0>)\n",
      "step =  1772\n",
      "loss =  tensor(5469136., grad_fn=<SubBackward0>)\n",
      "step =  1773\n",
      "loss =  tensor(5463762., grad_fn=<SubBackward0>)\n",
      "step =  1774\n",
      "loss =  tensor(5473460.5000, grad_fn=<SubBackward0>)\n",
      "step =  1775\n",
      "loss =  tensor(5454449., grad_fn=<SubBackward0>)\n",
      "step =  1776\n",
      "loss =  tensor(5511603., grad_fn=<SubBackward0>)\n",
      "step =  1777\n",
      "loss =  tensor(5475392., grad_fn=<SubBackward0>)\n",
      "step =  1778\n",
      "loss =  tensor(5481864., grad_fn=<SubBackward0>)\n",
      "step =  1779\n",
      "loss =  tensor(5480422.5000, grad_fn=<SubBackward0>)\n",
      "step =  1780\n",
      "loss =  tensor(5482561., grad_fn=<SubBackward0>)\n",
      "step =  1781\n",
      "loss =  tensor(5490551., grad_fn=<SubBackward0>)\n",
      "step =  1782\n",
      "loss =  tensor(5460734.5000, grad_fn=<SubBackward0>)\n",
      "step =  1783\n",
      "loss =  tensor(5488153.5000, grad_fn=<SubBackward0>)\n",
      "step =  1784\n",
      "loss =  tensor(5464659., grad_fn=<SubBackward0>)\n",
      "step =  1785\n",
      "loss =  tensor(5474137.5000, grad_fn=<SubBackward0>)\n",
      "step =  1786\n",
      "loss =  tensor(5455724.5000, grad_fn=<SubBackward0>)\n",
      "step =  1787\n",
      "loss =  tensor(5462717., grad_fn=<SubBackward0>)\n",
      "step =  1788\n",
      "loss =  tensor(5489959.5000, grad_fn=<SubBackward0>)\n",
      "step =  1789\n",
      "loss =  tensor(5468819., grad_fn=<SubBackward0>)\n",
      "step =  1790\n",
      "loss =  tensor(5462888., grad_fn=<SubBackward0>)\n",
      "step =  1791\n",
      "loss =  tensor(5450028., grad_fn=<SubBackward0>)\n",
      "step =  1792\n",
      "loss =  tensor(5490418., grad_fn=<SubBackward0>)\n",
      "step =  1793\n",
      "loss =  tensor(5438597., grad_fn=<SubBackward0>)\n",
      "step =  1794\n",
      "loss =  tensor(5471418.5000, grad_fn=<SubBackward0>)\n",
      "step =  1795\n",
      "loss =  tensor(5464551., grad_fn=<SubBackward0>)\n",
      "step =  1796\n",
      "loss =  tensor(5484356., grad_fn=<SubBackward0>)\n",
      "step =  1797\n",
      "loss =  tensor(5488385., grad_fn=<SubBackward0>)\n",
      "step =  1798\n",
      "loss =  tensor(5473703., grad_fn=<SubBackward0>)\n",
      "step =  1799\n",
      "loss =  tensor(5481478.5000, grad_fn=<SubBackward0>)\n",
      "step =  1800\n",
      "loss =  tensor(5477756., grad_fn=<SubBackward0>)\n",
      "step =  1801\n",
      "loss =  tensor(5485832.5000, grad_fn=<SubBackward0>)\n",
      "step =  1802\n",
      "loss =  tensor(5478473., grad_fn=<SubBackward0>)\n",
      "step =  1803\n",
      "loss =  tensor(5485467., grad_fn=<SubBackward0>)\n",
      "step =  1804\n",
      "loss =  tensor(5485625., grad_fn=<SubBackward0>)\n",
      "step =  1805\n",
      "loss =  tensor(5470950., grad_fn=<SubBackward0>)\n",
      "step =  1806\n",
      "loss =  tensor(5495637., grad_fn=<SubBackward0>)\n",
      "step =  1807\n",
      "loss =  tensor(5505686., grad_fn=<SubBackward0>)\n",
      "step =  1808\n",
      "loss =  tensor(5477472., grad_fn=<SubBackward0>)\n",
      "step =  1809\n",
      "loss =  tensor(5486509., grad_fn=<SubBackward0>)\n",
      "step =  1810\n",
      "loss =  tensor(5486335., grad_fn=<SubBackward0>)\n",
      "step =  1811\n",
      "loss =  tensor(5464345., grad_fn=<SubBackward0>)\n",
      "step =  1812\n",
      "loss =  tensor(5507230.5000, grad_fn=<SubBackward0>)\n",
      "step =  1813\n",
      "loss =  tensor(5468088., grad_fn=<SubBackward0>)\n",
      "step =  1814\n",
      "loss =  tensor(5469295., grad_fn=<SubBackward0>)\n",
      "step =  1815\n",
      "loss =  tensor(5470664.5000, grad_fn=<SubBackward0>)\n",
      "step =  1816\n",
      "loss =  tensor(5482180., grad_fn=<SubBackward0>)\n",
      "step =  1817\n",
      "loss =  tensor(5479457.5000, grad_fn=<SubBackward0>)\n",
      "step =  1818\n",
      "loss =  tensor(5464487., grad_fn=<SubBackward0>)\n",
      "step =  1819\n",
      "loss =  tensor(5484352.5000, grad_fn=<SubBackward0>)\n",
      "step =  1820\n",
      "loss =  tensor(5480202.5000, grad_fn=<SubBackward0>)\n",
      "step =  1821\n",
      "loss =  tensor(5495575., grad_fn=<SubBackward0>)\n",
      "step =  1822\n",
      "loss =  tensor(5495566., grad_fn=<SubBackward0>)\n",
      "step =  1823\n",
      "loss =  tensor(5477490.5000, grad_fn=<SubBackward0>)\n",
      "step =  1824\n",
      "loss =  tensor(5476096.5000, grad_fn=<SubBackward0>)\n",
      "step =  1825\n",
      "loss =  tensor(5472110., grad_fn=<SubBackward0>)\n",
      "step =  1826\n",
      "loss =  tensor(5471953., grad_fn=<SubBackward0>)\n",
      "step =  1827\n",
      "loss =  tensor(5472020., grad_fn=<SubBackward0>)\n",
      "step =  1828\n",
      "loss =  tensor(5465475., grad_fn=<SubBackward0>)\n",
      "step =  1829\n",
      "loss =  tensor(5487200.5000, grad_fn=<SubBackward0>)\n",
      "step =  1830\n",
      "loss =  tensor(5484151., grad_fn=<SubBackward0>)\n",
      "step =  1831\n",
      "loss =  tensor(5486913., grad_fn=<SubBackward0>)\n",
      "step =  1832\n",
      "loss =  tensor(5463039., grad_fn=<SubBackward0>)\n",
      "step =  1833\n",
      "loss =  tensor(5463890., grad_fn=<SubBackward0>)\n",
      "step =  1834\n",
      "loss =  tensor(5454757., grad_fn=<SubBackward0>)\n",
      "step =  1835\n",
      "loss =  tensor(5471540., grad_fn=<SubBackward0>)\n",
      "step =  1836\n",
      "loss =  tensor(5490618., grad_fn=<SubBackward0>)\n",
      "step =  1837\n",
      "loss =  tensor(5496729., grad_fn=<SubBackward0>)\n",
      "step =  1838\n",
      "loss =  tensor(5472876., grad_fn=<SubBackward0>)\n",
      "step =  1839\n",
      "loss =  tensor(5478684., grad_fn=<SubBackward0>)\n",
      "step =  1840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(5486779., grad_fn=<SubBackward0>)\n",
      "step =  1841\n",
      "loss =  tensor(5473619.5000, grad_fn=<SubBackward0>)\n",
      "step =  1842\n",
      "loss =  tensor(5478713., grad_fn=<SubBackward0>)\n",
      "step =  1843\n",
      "loss =  tensor(5462794., grad_fn=<SubBackward0>)\n",
      "step =  1844\n",
      "loss =  tensor(5487309., grad_fn=<SubBackward0>)\n",
      "step =  1845\n",
      "loss =  tensor(5464577., grad_fn=<SubBackward0>)\n",
      "step =  1846\n",
      "loss =  tensor(5473805., grad_fn=<SubBackward0>)\n",
      "step =  1847\n",
      "loss =  tensor(5474328., grad_fn=<SubBackward0>)\n",
      "step =  1848\n",
      "loss =  tensor(5502307.5000, grad_fn=<SubBackward0>)\n",
      "step =  1849\n",
      "loss =  tensor(5458349., grad_fn=<SubBackward0>)\n",
      "step =  1850\n",
      "loss =  tensor(5460260., grad_fn=<SubBackward0>)\n",
      "step =  1851\n",
      "loss =  tensor(5470009.5000, grad_fn=<SubBackward0>)\n",
      "step =  1852\n",
      "loss =  tensor(5478433., grad_fn=<SubBackward0>)\n",
      "step =  1853\n",
      "loss =  tensor(5470932., grad_fn=<SubBackward0>)\n",
      "step =  1854\n",
      "loss =  tensor(5516898., grad_fn=<SubBackward0>)\n",
      "step =  1855\n",
      "loss =  tensor(5462550., grad_fn=<SubBackward0>)\n",
      "step =  1856\n",
      "loss =  tensor(5486514.5000, grad_fn=<SubBackward0>)\n",
      "step =  1857\n",
      "loss =  tensor(5477266., grad_fn=<SubBackward0>)\n",
      "step =  1858\n",
      "loss =  tensor(5479265.5000, grad_fn=<SubBackward0>)\n",
      "step =  1859\n",
      "loss =  tensor(5458377., grad_fn=<SubBackward0>)\n",
      "step =  1860\n",
      "loss =  tensor(5481375.5000, grad_fn=<SubBackward0>)\n",
      "step =  1861\n",
      "loss =  tensor(5483486., grad_fn=<SubBackward0>)\n",
      "step =  1862\n",
      "loss =  tensor(5498789., grad_fn=<SubBackward0>)\n",
      "step =  1863\n",
      "loss =  tensor(5473954., grad_fn=<SubBackward0>)\n",
      "step =  1864\n",
      "loss =  tensor(5479022.5000, grad_fn=<SubBackward0>)\n",
      "step =  1865\n",
      "loss =  tensor(5469168.5000, grad_fn=<SubBackward0>)\n",
      "step =  1866\n",
      "loss =  tensor(5476798., grad_fn=<SubBackward0>)\n",
      "step =  1867\n",
      "loss =  tensor(5497447., grad_fn=<SubBackward0>)\n",
      "step =  1868\n",
      "loss =  tensor(5458174., grad_fn=<SubBackward0>)\n",
      "step =  1869\n",
      "loss =  tensor(5489281., grad_fn=<SubBackward0>)\n",
      "step =  1870\n",
      "loss =  tensor(5489271., grad_fn=<SubBackward0>)\n",
      "step =  1871\n",
      "loss =  tensor(5477047., grad_fn=<SubBackward0>)\n",
      "step =  1872\n",
      "loss =  tensor(5484986., grad_fn=<SubBackward0>)\n",
      "step =  1873\n",
      "loss =  tensor(5478686.5000, grad_fn=<SubBackward0>)\n",
      "step =  1874\n",
      "loss =  tensor(5456842., grad_fn=<SubBackward0>)\n",
      "step =  1875\n",
      "loss =  tensor(5445118., grad_fn=<SubBackward0>)\n",
      "step =  1876\n",
      "loss =  tensor(5486227., grad_fn=<SubBackward0>)\n",
      "step =  1877\n",
      "loss =  tensor(5474777.5000, grad_fn=<SubBackward0>)\n",
      "step =  1878\n",
      "loss =  tensor(5473227.5000, grad_fn=<SubBackward0>)\n",
      "step =  1879\n",
      "loss =  tensor(5456099., grad_fn=<SubBackward0>)\n",
      "step =  1880\n",
      "loss =  tensor(5464890., grad_fn=<SubBackward0>)\n",
      "step =  1881\n",
      "loss =  tensor(5499330., grad_fn=<SubBackward0>)\n",
      "step =  1882\n",
      "loss =  tensor(5476334., grad_fn=<SubBackward0>)\n",
      "step =  1883\n",
      "loss =  tensor(5453702., grad_fn=<SubBackward0>)\n",
      "step =  1884\n",
      "loss =  tensor(5463335.5000, grad_fn=<SubBackward0>)\n",
      "step =  1885\n",
      "loss =  tensor(5498661., grad_fn=<SubBackward0>)\n",
      "step =  1886\n",
      "loss =  tensor(5456193., grad_fn=<SubBackward0>)\n",
      "step =  1887\n",
      "loss =  tensor(5478988.5000, grad_fn=<SubBackward0>)\n",
      "step =  1888\n",
      "loss =  tensor(5455621., grad_fn=<SubBackward0>)\n",
      "step =  1889\n",
      "loss =  tensor(5454585.5000, grad_fn=<SubBackward0>)\n",
      "step =  1890\n",
      "loss =  tensor(5482856., grad_fn=<SubBackward0>)\n",
      "step =  1891\n",
      "loss =  tensor(5483188.5000, grad_fn=<SubBackward0>)\n",
      "step =  1892\n",
      "loss =  tensor(5495663., grad_fn=<SubBackward0>)\n",
      "step =  1893\n",
      "loss =  tensor(5491107., grad_fn=<SubBackward0>)\n",
      "step =  1894\n",
      "loss =  tensor(5493297., grad_fn=<SubBackward0>)\n",
      "step =  1895\n",
      "loss =  tensor(5467100., grad_fn=<SubBackward0>)\n",
      "step =  1896\n",
      "loss =  tensor(5464022., grad_fn=<SubBackward0>)\n",
      "step =  1897\n",
      "loss =  tensor(5503294., grad_fn=<SubBackward0>)\n",
      "step =  1898\n",
      "loss =  tensor(5477266., grad_fn=<SubBackward0>)\n",
      "step =  1899\n",
      "loss =  tensor(5497291.5000, grad_fn=<SubBackward0>)\n",
      "step =  1900\n",
      "loss =  tensor(5461126., grad_fn=<SubBackward0>)\n",
      "step =  1901\n",
      "loss =  tensor(5473432., grad_fn=<SubBackward0>)\n",
      "step =  1902\n",
      "loss =  tensor(5467167., grad_fn=<SubBackward0>)\n",
      "step =  1903\n",
      "loss =  tensor(5477276., grad_fn=<SubBackward0>)\n",
      "step =  1904\n",
      "loss =  tensor(5469251., grad_fn=<SubBackward0>)\n",
      "step =  1905\n",
      "loss =  tensor(5469521., grad_fn=<SubBackward0>)\n",
      "step =  1906\n",
      "loss =  tensor(5458293., grad_fn=<SubBackward0>)\n",
      "step =  1907\n",
      "loss =  tensor(5470204., grad_fn=<SubBackward0>)\n",
      "step =  1908\n",
      "loss =  tensor(5463839., grad_fn=<SubBackward0>)\n",
      "step =  1909\n",
      "loss =  tensor(5461730., grad_fn=<SubBackward0>)\n",
      "step =  1910\n",
      "loss =  tensor(5479137., grad_fn=<SubBackward0>)\n",
      "step =  1911\n",
      "loss =  tensor(5470148.5000, grad_fn=<SubBackward0>)\n",
      "step =  1912\n",
      "loss =  tensor(5479507., grad_fn=<SubBackward0>)\n",
      "step =  1913\n",
      "loss =  tensor(5466739., grad_fn=<SubBackward0>)\n",
      "step =  1914\n",
      "loss =  tensor(5477478., grad_fn=<SubBackward0>)\n",
      "step =  1915\n",
      "loss =  tensor(5471747.5000, grad_fn=<SubBackward0>)\n",
      "step =  1916\n",
      "loss =  tensor(5489473.5000, grad_fn=<SubBackward0>)\n",
      "step =  1917\n",
      "loss =  tensor(5480494., grad_fn=<SubBackward0>)\n",
      "step =  1918\n",
      "loss =  tensor(5468067., grad_fn=<SubBackward0>)\n",
      "step =  1919\n",
      "loss =  tensor(5474191., grad_fn=<SubBackward0>)\n",
      "step =  1920\n",
      "loss =  tensor(5472226.5000, grad_fn=<SubBackward0>)\n",
      "step =  1921\n",
      "loss =  tensor(5473406., grad_fn=<SubBackward0>)\n",
      "step =  1922\n",
      "loss =  tensor(5478900.5000, grad_fn=<SubBackward0>)\n",
      "step =  1923\n",
      "loss =  tensor(5468295., grad_fn=<SubBackward0>)\n",
      "step =  1924\n",
      "loss =  tensor(5483958.5000, grad_fn=<SubBackward0>)\n",
      "step =  1925\n",
      "loss =  tensor(5494640., grad_fn=<SubBackward0>)\n",
      "step =  1926\n",
      "loss =  tensor(5497754., grad_fn=<SubBackward0>)\n",
      "step =  1927\n",
      "loss =  tensor(5481092., grad_fn=<SubBackward0>)\n",
      "step =  1928\n",
      "loss =  tensor(5475230., grad_fn=<SubBackward0>)\n",
      "step =  1929\n",
      "loss =  tensor(5480349., grad_fn=<SubBackward0>)\n",
      "step =  1930\n",
      "loss =  tensor(5482592., grad_fn=<SubBackward0>)\n",
      "step =  1931\n",
      "loss =  tensor(5474027.5000, grad_fn=<SubBackward0>)\n",
      "step =  1932\n",
      "loss =  tensor(5470891., grad_fn=<SubBackward0>)\n",
      "step =  1933\n",
      "loss =  tensor(5472800., grad_fn=<SubBackward0>)\n",
      "step =  1934\n",
      "loss =  tensor(5445453., grad_fn=<SubBackward0>)\n",
      "step =  1935\n",
      "loss =  tensor(5456083.5000, grad_fn=<SubBackward0>)\n",
      "step =  1936\n",
      "loss =  tensor(5473452., grad_fn=<SubBackward0>)\n",
      "step =  1937\n",
      "loss =  tensor(5476053.5000, grad_fn=<SubBackward0>)\n",
      "step =  1938\n",
      "loss =  tensor(5456860.5000, grad_fn=<SubBackward0>)\n",
      "step =  1939\n",
      "loss =  tensor(5468749., grad_fn=<SubBackward0>)\n",
      "step =  1940\n",
      "loss =  tensor(5443836., grad_fn=<SubBackward0>)\n",
      "step =  1941\n",
      "loss =  tensor(5454546., grad_fn=<SubBackward0>)\n",
      "step =  1942\n",
      "loss =  tensor(5489320.5000, grad_fn=<SubBackward0>)\n",
      "step =  1943\n",
      "loss =  tensor(5463498., grad_fn=<SubBackward0>)\n",
      "step =  1944\n",
      "loss =  tensor(5482303., grad_fn=<SubBackward0>)\n",
      "step =  1945\n",
      "loss =  tensor(5504421.5000, grad_fn=<SubBackward0>)\n",
      "step =  1946\n",
      "loss =  tensor(5467194.5000, grad_fn=<SubBackward0>)\n",
      "step =  1947\n",
      "loss =  tensor(5466529., grad_fn=<SubBackward0>)\n",
      "step =  1948\n",
      "loss =  tensor(5486346., grad_fn=<SubBackward0>)\n",
      "step =  1949\n",
      "loss =  tensor(5470254., grad_fn=<SubBackward0>)\n",
      "step =  1950\n",
      "loss =  tensor(5470817., grad_fn=<SubBackward0>)\n",
      "step =  1951\n",
      "loss =  tensor(5448487., grad_fn=<SubBackward0>)\n",
      "step =  1952\n",
      "loss =  tensor(5460700., grad_fn=<SubBackward0>)\n",
      "step =  1953\n",
      "loss =  tensor(5483596., grad_fn=<SubBackward0>)\n",
      "step =  1954\n",
      "loss =  tensor(5478291., grad_fn=<SubBackward0>)\n",
      "step =  1955\n",
      "loss =  tensor(5489563.5000, grad_fn=<SubBackward0>)\n",
      "step =  1956\n",
      "loss =  tensor(5500495.5000, grad_fn=<SubBackward0>)\n",
      "step =  1957\n",
      "loss =  tensor(5463841., grad_fn=<SubBackward0>)\n",
      "step =  1958\n",
      "loss =  tensor(5467984.5000, grad_fn=<SubBackward0>)\n",
      "step =  1959\n",
      "loss =  tensor(5459765., grad_fn=<SubBackward0>)\n",
      "step =  1960\n",
      "loss =  tensor(5487518., grad_fn=<SubBackward0>)\n",
      "step =  1961\n",
      "loss =  tensor(5465131., grad_fn=<SubBackward0>)\n",
      "step =  1962\n",
      "loss =  tensor(5492688., grad_fn=<SubBackward0>)\n",
      "step =  1963\n",
      "loss =  tensor(5469738., grad_fn=<SubBackward0>)\n",
      "step =  1964\n",
      "loss =  tensor(5479483., grad_fn=<SubBackward0>)\n",
      "step =  1965\n",
      "loss =  tensor(5469075., grad_fn=<SubBackward0>)\n",
      "step =  1966\n",
      "loss =  tensor(5469743., grad_fn=<SubBackward0>)\n",
      "step =  1967\n",
      "loss =  tensor(5455676., grad_fn=<SubBackward0>)\n",
      "step =  1968\n",
      "loss =  tensor(5479116.5000, grad_fn=<SubBackward0>)\n",
      "step =  1969\n",
      "loss =  tensor(5463552., grad_fn=<SubBackward0>)\n",
      "step =  1970\n",
      "loss =  tensor(5489669., grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  1971\n",
      "loss =  tensor(5480658., grad_fn=<SubBackward0>)\n",
      "step =  1972\n",
      "loss =  tensor(5469067., grad_fn=<SubBackward0>)\n",
      "step =  1973\n",
      "loss =  tensor(5474743., grad_fn=<SubBackward0>)\n",
      "step =  1974\n",
      "loss =  tensor(5475393.5000, grad_fn=<SubBackward0>)\n",
      "step =  1975\n",
      "loss =  tensor(5467252.5000, grad_fn=<SubBackward0>)\n",
      "step =  1976\n",
      "loss =  tensor(5479812., grad_fn=<SubBackward0>)\n",
      "step =  1977\n",
      "loss =  tensor(5456071.5000, grad_fn=<SubBackward0>)\n",
      "step =  1978\n",
      "loss =  tensor(5477084., grad_fn=<SubBackward0>)\n",
      "step =  1979\n",
      "loss =  tensor(5458849., grad_fn=<SubBackward0>)\n",
      "step =  1980\n",
      "loss =  tensor(5477664.5000, grad_fn=<SubBackward0>)\n",
      "step =  1981\n",
      "loss =  tensor(5482575., grad_fn=<SubBackward0>)\n",
      "step =  1982\n",
      "loss =  tensor(5468063., grad_fn=<SubBackward0>)\n",
      "step =  1983\n",
      "loss =  tensor(5439619.5000, grad_fn=<SubBackward0>)\n",
      "step =  1984\n",
      "loss =  tensor(5479624., grad_fn=<SubBackward0>)\n",
      "step =  1985\n",
      "loss =  tensor(5489068., grad_fn=<SubBackward0>)\n",
      "step =  1986\n",
      "loss =  tensor(5473040.5000, grad_fn=<SubBackward0>)\n",
      "step =  1987\n",
      "loss =  tensor(5472597., grad_fn=<SubBackward0>)\n",
      "step =  1988\n",
      "loss =  tensor(5456846., grad_fn=<SubBackward0>)\n",
      "step =  1989\n",
      "loss =  tensor(5476270., grad_fn=<SubBackward0>)\n",
      "step =  1990\n",
      "loss =  tensor(5478601., grad_fn=<SubBackward0>)\n",
      "step =  1991\n",
      "loss =  tensor(5468219.5000, grad_fn=<SubBackward0>)\n",
      "step =  1992\n",
      "loss =  tensor(5473139., grad_fn=<SubBackward0>)\n",
      "step =  1993\n",
      "loss =  tensor(5466392.5000, grad_fn=<SubBackward0>)\n",
      "step =  1994\n",
      "loss =  tensor(5465152., grad_fn=<SubBackward0>)\n",
      "step =  1995\n",
      "loss =  tensor(5484046.5000, grad_fn=<SubBackward0>)\n",
      "step =  1996\n",
      "loss =  tensor(5486235.5000, grad_fn=<SubBackward0>)\n",
      "step =  1997\n",
      "loss =  tensor(5470218., grad_fn=<SubBackward0>)\n",
      "step =  1998\n",
      "loss =  tensor(5474824., grad_fn=<SubBackward0>)\n",
      "step =  1999\n",
      "loss =  tensor(5481428., grad_fn=<SubBackward0>)\n",
      "step =  2000\n",
      "loss =  tensor(5492115.5000, grad_fn=<SubBackward0>)\n",
      "step =  2001\n",
      "loss =  tensor(5468849., grad_fn=<SubBackward0>)\n",
      "step =  2002\n",
      "loss =  tensor(5468905., grad_fn=<SubBackward0>)\n",
      "step =  2003\n",
      "loss =  tensor(5485601., grad_fn=<SubBackward0>)\n",
      "step =  2004\n",
      "loss =  tensor(5484997., grad_fn=<SubBackward0>)\n",
      "step =  2005\n",
      "loss =  tensor(5482910.5000, grad_fn=<SubBackward0>)\n",
      "step =  2006\n",
      "loss =  tensor(5434627., grad_fn=<SubBackward0>)\n",
      "step =  2007\n",
      "loss =  tensor(5476165., grad_fn=<SubBackward0>)\n",
      "step =  2008\n",
      "loss =  tensor(5472244., grad_fn=<SubBackward0>)\n",
      "step =  2009\n",
      "loss =  tensor(5475111., grad_fn=<SubBackward0>)\n",
      "step =  2010\n",
      "loss =  tensor(5464804.5000, grad_fn=<SubBackward0>)\n",
      "step =  2011\n",
      "loss =  tensor(5478674., grad_fn=<SubBackward0>)\n",
      "step =  2012\n",
      "loss =  tensor(5477681., grad_fn=<SubBackward0>)\n",
      "step =  2013\n",
      "loss =  tensor(5475966., grad_fn=<SubBackward0>)\n",
      "step =  2014\n",
      "loss =  tensor(5486631., grad_fn=<SubBackward0>)\n",
      "step =  2015\n",
      "loss =  tensor(5480351., grad_fn=<SubBackward0>)\n",
      "step =  2016\n",
      "loss =  tensor(5465844., grad_fn=<SubBackward0>)\n",
      "step =  2017\n",
      "loss =  tensor(5493800., grad_fn=<SubBackward0>)\n",
      "step =  2018\n",
      "loss =  tensor(5458352.5000, grad_fn=<SubBackward0>)\n",
      "step =  2019\n",
      "loss =  tensor(5486129., grad_fn=<SubBackward0>)\n",
      "step =  2020\n",
      "loss =  tensor(5444003., grad_fn=<SubBackward0>)\n",
      "step =  2021\n",
      "loss =  tensor(5461664., grad_fn=<SubBackward0>)\n",
      "step =  2022\n",
      "loss =  tensor(5484817., grad_fn=<SubBackward0>)\n",
      "step =  2023\n",
      "loss =  tensor(5452941., grad_fn=<SubBackward0>)\n",
      "step =  2024\n",
      "loss =  tensor(5457573., grad_fn=<SubBackward0>)\n",
      "step =  2025\n",
      "loss =  tensor(5511747., grad_fn=<SubBackward0>)\n",
      "step =  2026\n",
      "loss =  tensor(5467691., grad_fn=<SubBackward0>)\n",
      "step =  2027\n",
      "loss =  tensor(5488269., grad_fn=<SubBackward0>)\n",
      "step =  2028\n",
      "loss =  tensor(5474378., grad_fn=<SubBackward0>)\n",
      "step =  2029\n",
      "loss =  tensor(5472610.5000, grad_fn=<SubBackward0>)\n",
      "step =  2030\n",
      "loss =  tensor(5466312., grad_fn=<SubBackward0>)\n",
      "step =  2031\n",
      "loss =  tensor(5472041., grad_fn=<SubBackward0>)\n",
      "step =  2032\n",
      "loss =  tensor(5489832., grad_fn=<SubBackward0>)\n",
      "step =  2033\n",
      "loss =  tensor(5466729., grad_fn=<SubBackward0>)\n",
      "step =  2034\n",
      "loss =  tensor(5478698., grad_fn=<SubBackward0>)\n",
      "step =  2035\n",
      "loss =  tensor(5452535., grad_fn=<SubBackward0>)\n",
      "step =  2036\n",
      "loss =  tensor(5454569., grad_fn=<SubBackward0>)\n",
      "step =  2037\n",
      "loss =  tensor(5486660., grad_fn=<SubBackward0>)\n",
      "step =  2038\n",
      "loss =  tensor(5488435., grad_fn=<SubBackward0>)\n",
      "step =  2039\n",
      "loss =  tensor(5463367., grad_fn=<SubBackward0>)\n",
      "step =  2040\n",
      "loss =  tensor(5482298.5000, grad_fn=<SubBackward0>)\n",
      "step =  2041\n",
      "loss =  tensor(5462585., grad_fn=<SubBackward0>)\n",
      "step =  2042\n",
      "loss =  tensor(5492457., grad_fn=<SubBackward0>)\n",
      "step =  2043\n",
      "loss =  tensor(5451678., grad_fn=<SubBackward0>)\n",
      "step =  2044\n",
      "loss =  tensor(5451453., grad_fn=<SubBackward0>)\n",
      "step =  2045\n",
      "loss =  tensor(5477139.5000, grad_fn=<SubBackward0>)\n",
      "step =  2046\n",
      "loss =  tensor(5490668.5000, grad_fn=<SubBackward0>)\n",
      "step =  2047\n",
      "loss =  tensor(5486149.5000, grad_fn=<SubBackward0>)\n",
      "step =  2048\n",
      "loss =  tensor(5480487., grad_fn=<SubBackward0>)\n",
      "step =  2049\n",
      "loss =  tensor(5454552., grad_fn=<SubBackward0>)\n",
      "step =  2050\n",
      "loss =  tensor(5478311., grad_fn=<SubBackward0>)\n",
      "step =  2051\n",
      "loss =  tensor(5472230., grad_fn=<SubBackward0>)\n",
      "step =  2052\n",
      "loss =  tensor(5457277., grad_fn=<SubBackward0>)\n",
      "step =  2053\n",
      "loss =  tensor(5465003.5000, grad_fn=<SubBackward0>)\n",
      "step =  2054\n",
      "loss =  tensor(5468414., grad_fn=<SubBackward0>)\n",
      "step =  2055\n",
      "loss =  tensor(5489751., grad_fn=<SubBackward0>)\n",
      "step =  2056\n",
      "loss =  tensor(5439477., grad_fn=<SubBackward0>)\n",
      "step =  2057\n",
      "loss =  tensor(5498301., grad_fn=<SubBackward0>)\n",
      "step =  2058\n",
      "loss =  tensor(5474532.5000, grad_fn=<SubBackward0>)\n",
      "step =  2059\n",
      "loss =  tensor(5459862.5000, grad_fn=<SubBackward0>)\n",
      "step =  2060\n",
      "loss =  tensor(5468531., grad_fn=<SubBackward0>)\n",
      "step =  2061\n",
      "loss =  tensor(5462100., grad_fn=<SubBackward0>)\n",
      "step =  2062\n",
      "loss =  tensor(5474825., grad_fn=<SubBackward0>)\n",
      "step =  2063\n",
      "loss =  tensor(5479442., grad_fn=<SubBackward0>)\n",
      "step =  2064\n",
      "loss =  tensor(5472880., grad_fn=<SubBackward0>)\n",
      "step =  2065\n",
      "loss =  tensor(5454699., grad_fn=<SubBackward0>)\n",
      "step =  2066\n",
      "loss =  tensor(5475937., grad_fn=<SubBackward0>)\n",
      "step =  2067\n",
      "loss =  tensor(5470823., grad_fn=<SubBackward0>)\n",
      "step =  2068\n",
      "loss =  tensor(5482232., grad_fn=<SubBackward0>)\n",
      "step =  2069\n",
      "loss =  tensor(5469002., grad_fn=<SubBackward0>)\n",
      "step =  2070\n",
      "loss =  tensor(5474508., grad_fn=<SubBackward0>)\n",
      "step =  2071\n",
      "loss =  tensor(5503890., grad_fn=<SubBackward0>)\n",
      "step =  2072\n",
      "loss =  tensor(5471659.5000, grad_fn=<SubBackward0>)\n",
      "step =  2073\n",
      "loss =  tensor(5469514., grad_fn=<SubBackward0>)\n",
      "step =  2074\n",
      "loss =  tensor(5454080., grad_fn=<SubBackward0>)\n",
      "step =  2075\n",
      "loss =  tensor(5485641., grad_fn=<SubBackward0>)\n",
      "step =  2076\n",
      "loss =  tensor(5462288.5000, grad_fn=<SubBackward0>)\n",
      "step =  2077\n",
      "loss =  tensor(5479061., grad_fn=<SubBackward0>)\n",
      "step =  2078\n",
      "loss =  tensor(5484005., grad_fn=<SubBackward0>)\n",
      "step =  2079\n",
      "loss =  tensor(5477109.5000, grad_fn=<SubBackward0>)\n",
      "step =  2080\n",
      "loss =  tensor(5480596.5000, grad_fn=<SubBackward0>)\n",
      "step =  2081\n",
      "loss =  tensor(5463526.5000, grad_fn=<SubBackward0>)\n",
      "step =  2082\n",
      "loss =  tensor(5487282., grad_fn=<SubBackward0>)\n",
      "step =  2083\n",
      "loss =  tensor(5473410., grad_fn=<SubBackward0>)\n",
      "step =  2084\n",
      "loss =  tensor(5467807., grad_fn=<SubBackward0>)\n",
      "step =  2085\n",
      "loss =  tensor(5473719., grad_fn=<SubBackward0>)\n",
      "step =  2086\n",
      "loss =  tensor(5476086.5000, grad_fn=<SubBackward0>)\n",
      "step =  2087\n",
      "loss =  tensor(5483570.5000, grad_fn=<SubBackward0>)\n",
      "step =  2088\n",
      "loss =  tensor(5457757., grad_fn=<SubBackward0>)\n",
      "step =  2089\n",
      "loss =  tensor(5462762., grad_fn=<SubBackward0>)\n",
      "step =  2090\n",
      "loss =  tensor(5480076., grad_fn=<SubBackward0>)\n",
      "step =  2091\n",
      "loss =  tensor(5490640., grad_fn=<SubBackward0>)\n",
      "step =  2092\n",
      "loss =  tensor(5469414.5000, grad_fn=<SubBackward0>)\n",
      "step =  2093\n",
      "loss =  tensor(5461552., grad_fn=<SubBackward0>)\n",
      "step =  2094\n",
      "loss =  tensor(5473946., grad_fn=<SubBackward0>)\n",
      "step =  2095\n",
      "loss =  tensor(5444949., grad_fn=<SubBackward0>)\n",
      "step =  2096\n",
      "loss =  tensor(5450533.5000, grad_fn=<SubBackward0>)\n",
      "step =  2097\n",
      "loss =  tensor(5486759., grad_fn=<SubBackward0>)\n",
      "step =  2098\n",
      "loss =  tensor(5489436.5000, grad_fn=<SubBackward0>)\n",
      "step =  2099\n",
      "loss =  tensor(5483976.5000, grad_fn=<SubBackward0>)\n",
      "step =  2100\n",
      "loss =  tensor(5483792., grad_fn=<SubBackward0>)\n",
      "step =  2101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(5510453., grad_fn=<SubBackward0>)\n",
      "step =  2102\n",
      "loss =  tensor(5490676.5000, grad_fn=<SubBackward0>)\n",
      "step =  2103\n",
      "loss =  tensor(5498523., grad_fn=<SubBackward0>)\n",
      "step =  2104\n",
      "loss =  tensor(5502348., grad_fn=<SubBackward0>)\n",
      "step =  2105\n",
      "loss =  tensor(5455421., grad_fn=<SubBackward0>)\n",
      "step =  2106\n",
      "loss =  tensor(5456056., grad_fn=<SubBackward0>)\n",
      "step =  2107\n",
      "loss =  tensor(5436509., grad_fn=<SubBackward0>)\n",
      "step =  2108\n",
      "loss =  tensor(5462923., grad_fn=<SubBackward0>)\n",
      "step =  2109\n",
      "loss =  tensor(5488172.5000, grad_fn=<SubBackward0>)\n",
      "step =  2110\n",
      "loss =  tensor(5460713., grad_fn=<SubBackward0>)\n",
      "step =  2111\n",
      "loss =  tensor(5436325., grad_fn=<SubBackward0>)\n",
      "step =  2112\n",
      "loss =  tensor(5473313., grad_fn=<SubBackward0>)\n",
      "step =  2113\n",
      "loss =  tensor(5470907.5000, grad_fn=<SubBackward0>)\n",
      "step =  2114\n",
      "loss =  tensor(5474349., grad_fn=<SubBackward0>)\n",
      "step =  2115\n",
      "loss =  tensor(5476775., grad_fn=<SubBackward0>)\n",
      "step =  2116\n",
      "loss =  tensor(5492726., grad_fn=<SubBackward0>)\n",
      "step =  2117\n",
      "loss =  tensor(5458000., grad_fn=<SubBackward0>)\n",
      "step =  2118\n",
      "loss =  tensor(5457840., grad_fn=<SubBackward0>)\n",
      "step =  2119\n",
      "loss =  tensor(5451139., grad_fn=<SubBackward0>)\n",
      "step =  2120\n",
      "loss =  tensor(5500271., grad_fn=<SubBackward0>)\n",
      "step =  2121\n",
      "loss =  tensor(5466202., grad_fn=<SubBackward0>)\n",
      "step =  2122\n",
      "loss =  tensor(5487375., grad_fn=<SubBackward0>)\n",
      "step =  2123\n",
      "loss =  tensor(5491255.5000, grad_fn=<SubBackward0>)\n",
      "step =  2124\n",
      "loss =  tensor(5474421., grad_fn=<SubBackward0>)\n",
      "step =  2125\n",
      "loss =  tensor(5469280., grad_fn=<SubBackward0>)\n",
      "step =  2126\n",
      "loss =  tensor(5474899., grad_fn=<SubBackward0>)\n",
      "step =  2127\n",
      "loss =  tensor(5450348.5000, grad_fn=<SubBackward0>)\n",
      "step =  2128\n",
      "loss =  tensor(5468084.5000, grad_fn=<SubBackward0>)\n",
      "step =  2129\n",
      "loss =  tensor(5474298., grad_fn=<SubBackward0>)\n",
      "step =  2130\n",
      "loss =  tensor(5476887., grad_fn=<SubBackward0>)\n",
      "step =  2131\n",
      "loss =  tensor(5480929.5000, grad_fn=<SubBackward0>)\n",
      "step =  2132\n",
      "loss =  tensor(5478007.5000, grad_fn=<SubBackward0>)\n",
      "step =  2133\n",
      "loss =  tensor(5480651., grad_fn=<SubBackward0>)\n",
      "step =  2134\n",
      "loss =  tensor(5455198.5000, grad_fn=<SubBackward0>)\n",
      "step =  2135\n",
      "loss =  tensor(5478018., grad_fn=<SubBackward0>)\n",
      "step =  2136\n",
      "loss =  tensor(5474144., grad_fn=<SubBackward0>)\n",
      "step =  2137\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-90996917000f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'step = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatchSamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSizeN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainingData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnSamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpfStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchSamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/cluster/python/projects/generative_DR_ROM/GenerativeSurrogate.py\u001b[0m in \u001b[0;36mpfStep\u001b[0;34m(self, batchSamples)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSizeN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSizeZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpfNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_pf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cluster/python/projects/generative_DR_ROM/GenerativeSurrogate.py\u001b[0m in \u001b[0;36mloss_pf\u001b[0;34m(self, predOut, batchSamples)\u001b[0m\n\u001b[1;32m     94\u001b[0m                           torch.mean(torch.log(predOut + eps), dim=2).flatten()) - \\\n\u001b[1;32m     95\u001b[0m                 torch.dot(1 - self.data.microstructImg[batchSamples, :].flatten(),\n\u001b[0;32m---> 96\u001b[0;31m                           torch.mean(torch.log(1 - predOut + eps), dim=2).flatten())\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpfStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "steps = int(5)\n",
    "for s in range(steps):\n",
    "    print('step = ', s)\n",
    "    batchSamples = torch.LongTensor(model.batchSizeN).random_(0, trainingData.nSamples)\n",
    "    model.pfStep(batchSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.writer.close()\n",
    "model.plotInputReconstruction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.gcf()\n",
    "f.suptitle('Untrained, N = 1184', fontsize=32, y=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# writer = SummaryWriter('runs/gendrrom')\n",
    "\n",
    "# z = torch.randn(model.batchSizeN, model.batchSizeZ, model.dim_z)\n",
    "# writer.add_graph(model.pfNet, (z, model.data.imgX))\n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = torch.randn(model.batchSizeN, model.batchSizeZ, model.dim_z)\n",
    "# pred = model.pfNet(z, model.data.imgX)\n",
    "# batchSamples = torch.LongTensor(model.batchSizeN).random_(0, trainingData.nSamples)\n",
    "# loss = model.loss_pf(pred, batchSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (generative_DR_ROM)",
   "language": "python",
   "name": "pycharm-712517ba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
