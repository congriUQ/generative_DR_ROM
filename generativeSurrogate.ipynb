{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from poisson_fem import PoissonFEM\n",
    "import ROM\n",
    "import GenerativeSurrogate as gs\n",
    "import Data as dta\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import scipy.sparse.linalg as lg\n",
    "import time\n",
    "import petsc4py\n",
    "import sys\n",
    "petsc4py.init(sys.argv)\n",
    "from petsc4py import PETSc\n",
    "import torch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Some fixed parameters\n",
    "lin_dim_rom = 4                      # Linear number of rom elements\n",
    "a = np.array([1, 2, 3])              # Boundary condition function coefficients\n",
    "dim_z = 100                            # Latent space dimension\n",
    "dtype = torch.float                  # Tensor data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Define mesh and boundary conditions\n",
    "mesh = PoissonFEM.RectangularMesh(np.ones(lin_dim_rom)/lin_dim_rom)\n",
    "# mesh.plot()\n",
    "\n",
    "def origin(x):\n",
    "    return np.abs(x[0]) < np.finfo(float).eps and np.abs(x[1]) < np.finfo(float).eps\n",
    "\n",
    "def essBoundaryFun(x):\n",
    "    return 0.0\n",
    "mesh.setEssentialBoundary(origin, essBoundaryFun)\n",
    "\n",
    "def domainBoundary(x):\n",
    "    # unit square\n",
    "    return np.abs(x[0]) < np.finfo(float).eps or np.abs(x[1]) < np.finfo(float).eps or \\\n",
    "            np.abs(x[0]) > 1.0 - np.finfo(float).eps or np.abs(x[1]) > 1.0 - np.finfo(float).eps\n",
    "mesh.setNaturalBoundary(domainBoundary)\n",
    "\n",
    "def flux(x):\n",
    "    q = np.array([a[0] + a[2]*x[1], a[1] + a[2]*x[0]])\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spepify right hand side and stiffness matrix\n",
    "#Define boundary flux field\n",
    "rhs = PoissonFEM.RightHandSide(mesh)\n",
    "rhs.setNaturalRHS(mesh, flux)\n",
    "funSpace = PoissonFEM.FunctionSpace(mesh)\n",
    "K = PoissonFEM.StiffnessMatrix(mesh, funSpace)\n",
    "rhs.setRhsStencil(mesh, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up solver\n",
    "ksp = PETSc.KSP().create()\n",
    "ksp.setType('preonly')\n",
    "precond = ksp.getPC()\n",
    "precond.setType('cholesky')\n",
    "ksp.setFromOptions() #???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define rom\n",
    "rom = ROM.ROM(mesh, K, rhs, ksp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = dta.StokesData(range(512))\n",
    "trainingData.readData(['IMG'])\n",
    "# trainingData.plotMicrostruct(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gs.GenerativeSurrogate(rom, trainingData, dim_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0\n",
      "loss =  tensor(5179394., grad_fn=<SubBackward0>)\n",
      "step =  1\n",
      "loss =  tensor(5141770.5000, grad_fn=<SubBackward0>)\n",
      "step =  2\n",
      "loss =  tensor(5105520., grad_fn=<SubBackward0>)\n",
      "step =  3\n",
      "loss =  tensor(5043710., grad_fn=<SubBackward0>)\n",
      "step =  4\n",
      "loss =  tensor(5039710., grad_fn=<SubBackward0>)\n",
      "step =  5\n",
      "loss =  tensor(4973045., grad_fn=<SubBackward0>)\n",
      "step =  6\n",
      "loss =  tensor(4962454.5000, grad_fn=<SubBackward0>)\n",
      "step =  7\n",
      "loss =  tensor(4916611.5000, grad_fn=<SubBackward0>)\n",
      "step =  8\n",
      "loss =  tensor(4883929., grad_fn=<SubBackward0>)\n",
      "step =  9\n",
      "loss =  tensor(4866855.5000, grad_fn=<SubBackward0>)\n",
      "step =  10\n",
      "loss =  tensor(4828365.5000, grad_fn=<SubBackward0>)\n",
      "step =  11\n",
      "loss =  tensor(4814273.5000, grad_fn=<SubBackward0>)\n",
      "step =  12\n",
      "loss =  tensor(4780096., grad_fn=<SubBackward0>)\n",
      "step =  13\n",
      "loss =  tensor(4746748.5000, grad_fn=<SubBackward0>)\n",
      "step =  14\n",
      "loss =  tensor(4745533., grad_fn=<SubBackward0>)\n",
      "step =  15\n",
      "loss =  tensor(4708643., grad_fn=<SubBackward0>)\n",
      "step =  16\n",
      "loss =  tensor(4694797., grad_fn=<SubBackward0>)\n",
      "step =  17\n",
      "loss =  tensor(4667371.5000, grad_fn=<SubBackward0>)\n",
      "step =  18\n",
      "loss =  tensor(4664759., grad_fn=<SubBackward0>)\n",
      "step =  19\n",
      "loss =  tensor(4689327., grad_fn=<SubBackward0>)\n",
      "step =  20\n",
      "loss =  tensor(4629856., grad_fn=<SubBackward0>)\n",
      "step =  21\n",
      "loss =  tensor(4648678., grad_fn=<SubBackward0>)\n",
      "step =  22\n",
      "loss =  tensor(4582754.5000, grad_fn=<SubBackward0>)\n",
      "step =  23\n",
      "loss =  tensor(4586274., grad_fn=<SubBackward0>)\n",
      "step =  24\n",
      "loss =  tensor(4550422., grad_fn=<SubBackward0>)\n",
      "step =  25\n",
      "loss =  tensor(4610221., grad_fn=<SubBackward0>)\n",
      "step =  26\n",
      "loss =  tensor(4581018.5000, grad_fn=<SubBackward0>)\n",
      "step =  27\n",
      "loss =  tensor(4596390.5000, grad_fn=<SubBackward0>)\n",
      "step =  28\n",
      "loss =  tensor(4594005.5000, grad_fn=<SubBackward0>)\n",
      "step =  29\n",
      "loss =  tensor(4539052., grad_fn=<SubBackward0>)\n",
      "step =  30\n",
      "loss =  tensor(4561749.5000, grad_fn=<SubBackward0>)\n",
      "step =  31\n",
      "loss =  tensor(4621708., grad_fn=<SubBackward0>)\n",
      "step =  32\n",
      "loss =  tensor(4548465.5000, grad_fn=<SubBackward0>)\n",
      "step =  33\n",
      "loss =  tensor(4561270., grad_fn=<SubBackward0>)\n",
      "step =  34\n",
      "loss =  tensor(4543609., grad_fn=<SubBackward0>)\n",
      "step =  35\n",
      "loss =  tensor(4555888.5000, grad_fn=<SubBackward0>)\n",
      "step =  36\n",
      "loss =  tensor(4525241.5000, grad_fn=<SubBackward0>)\n",
      "step =  37\n",
      "loss =  tensor(4570548.5000, grad_fn=<SubBackward0>)\n",
      "step =  38\n",
      "loss =  tensor(4465401., grad_fn=<SubBackward0>)\n",
      "step =  39\n",
      "loss =  tensor(4563132., grad_fn=<SubBackward0>)\n",
      "step =  40\n",
      "loss =  tensor(4520559., grad_fn=<SubBackward0>)\n",
      "step =  41\n",
      "loss =  tensor(4503168., grad_fn=<SubBackward0>)\n",
      "step =  42\n",
      "loss =  tensor(4565724., grad_fn=<SubBackward0>)\n",
      "step =  43\n",
      "loss =  tensor(4505674., grad_fn=<SubBackward0>)\n",
      "step =  44\n",
      "loss =  tensor(4550879., grad_fn=<SubBackward0>)\n",
      "step =  45\n",
      "loss =  tensor(4474759.5000, grad_fn=<SubBackward0>)\n",
      "step =  46\n",
      "loss =  tensor(4560864.5000, grad_fn=<SubBackward0>)\n",
      "step =  47\n",
      "loss =  tensor(4542948.5000, grad_fn=<SubBackward0>)\n",
      "step =  48\n",
      "loss =  tensor(4562603., grad_fn=<SubBackward0>)\n",
      "step =  49\n",
      "loss =  tensor(4553636.5000, grad_fn=<SubBackward0>)\n",
      "step =  50\n",
      "loss =  tensor(4550551.5000, grad_fn=<SubBackward0>)\n",
      "step =  51\n",
      "loss =  tensor(4539645., grad_fn=<SubBackward0>)\n",
      "step =  52\n",
      "loss =  tensor(4493018., grad_fn=<SubBackward0>)\n",
      "step =  53\n",
      "loss =  tensor(4538528., grad_fn=<SubBackward0>)\n",
      "step =  54\n",
      "loss =  tensor(4507345.5000, grad_fn=<SubBackward0>)\n",
      "step =  55\n",
      "loss =  tensor(4541431.5000, grad_fn=<SubBackward0>)\n",
      "step =  56\n",
      "loss =  tensor(4570006., grad_fn=<SubBackward0>)\n",
      "step =  57\n",
      "loss =  tensor(4529985.5000, grad_fn=<SubBackward0>)\n",
      "step =  58\n",
      "loss =  tensor(4537641., grad_fn=<SubBackward0>)\n",
      "step =  59\n",
      "loss =  tensor(4528726., grad_fn=<SubBackward0>)\n",
      "step =  60\n",
      "loss =  tensor(4509923.5000, grad_fn=<SubBackward0>)\n",
      "step =  61\n",
      "loss =  tensor(4526063., grad_fn=<SubBackward0>)\n",
      "step =  62\n",
      "loss =  tensor(4484733., grad_fn=<SubBackward0>)\n",
      "step =  63\n",
      "loss =  tensor(4522370., grad_fn=<SubBackward0>)\n",
      "step =  64\n",
      "loss =  tensor(4531319., grad_fn=<SubBackward0>)\n",
      "step =  65\n",
      "loss =  tensor(4532123., grad_fn=<SubBackward0>)\n",
      "step =  66\n",
      "loss =  tensor(4495053., grad_fn=<SubBackward0>)\n",
      "step =  67\n",
      "loss =  tensor(4522162., grad_fn=<SubBackward0>)\n",
      "step =  68\n",
      "loss =  tensor(4549088.5000, grad_fn=<SubBackward0>)\n",
      "step =  69\n",
      "loss =  tensor(4528322., grad_fn=<SubBackward0>)\n",
      "step =  70\n",
      "loss =  tensor(4506582., grad_fn=<SubBackward0>)\n",
      "step =  71\n",
      "loss =  tensor(4467547.5000, grad_fn=<SubBackward0>)\n",
      "step =  72\n",
      "loss =  tensor(4533873.5000, grad_fn=<SubBackward0>)\n",
      "step =  73\n",
      "loss =  tensor(4557187., grad_fn=<SubBackward0>)\n",
      "step =  74\n",
      "loss =  tensor(4556898., grad_fn=<SubBackward0>)\n",
      "step =  75\n",
      "loss =  tensor(4493665.5000, grad_fn=<SubBackward0>)\n",
      "step =  76\n",
      "loss =  tensor(4542109., grad_fn=<SubBackward0>)\n",
      "step =  77\n",
      "loss =  tensor(4514870., grad_fn=<SubBackward0>)\n",
      "step =  78\n",
      "loss =  tensor(4509518., grad_fn=<SubBackward0>)\n",
      "step =  79\n",
      "loss =  tensor(4544313., grad_fn=<SubBackward0>)\n",
      "step =  80\n",
      "loss =  tensor(4621178., grad_fn=<SubBackward0>)\n",
      "step =  81\n",
      "loss =  tensor(4513006., grad_fn=<SubBackward0>)\n",
      "step =  82\n",
      "loss =  tensor(4554921., grad_fn=<SubBackward0>)\n",
      "step =  83\n",
      "loss =  tensor(4572637., grad_fn=<SubBackward0>)\n",
      "step =  84\n",
      "loss =  tensor(4507142.5000, grad_fn=<SubBackward0>)\n",
      "step =  85\n",
      "loss =  tensor(4532430., grad_fn=<SubBackward0>)\n",
      "step =  86\n",
      "loss =  tensor(4546701., grad_fn=<SubBackward0>)\n",
      "step =  87\n",
      "loss =  tensor(4520901., grad_fn=<SubBackward0>)\n",
      "step =  88\n",
      "loss =  tensor(4522575., grad_fn=<SubBackward0>)\n",
      "step =  89\n",
      "loss =  tensor(4587087., grad_fn=<SubBackward0>)\n",
      "step =  90\n",
      "loss =  tensor(4530112.5000, grad_fn=<SubBackward0>)\n",
      "step =  91\n",
      "loss =  tensor(4505240., grad_fn=<SubBackward0>)\n",
      "step =  92\n",
      "loss =  tensor(4529043., grad_fn=<SubBackward0>)\n",
      "step =  93\n",
      "loss =  tensor(4544698., grad_fn=<SubBackward0>)\n",
      "step =  94\n",
      "loss =  tensor(4479909., grad_fn=<SubBackward0>)\n",
      "step =  95\n",
      "loss =  tensor(4546344., grad_fn=<SubBackward0>)\n",
      "step =  96\n",
      "loss =  tensor(4524168., grad_fn=<SubBackward0>)\n",
      "step =  97\n",
      "loss =  tensor(4522912.5000, grad_fn=<SubBackward0>)\n",
      "step =  98\n",
      "loss =  tensor(4507297., grad_fn=<SubBackward0>)\n",
      "step =  99\n",
      "loss =  tensor(4504155., grad_fn=<SubBackward0>)\n",
      "step =  100\n",
      "loss =  tensor(4529851., grad_fn=<SubBackward0>)\n",
      "step =  101\n",
      "loss =  tensor(4501458., grad_fn=<SubBackward0>)\n",
      "step =  102\n",
      "loss =  tensor(4516682.5000, grad_fn=<SubBackward0>)\n",
      "step =  103\n",
      "loss =  tensor(4568834., grad_fn=<SubBackward0>)\n",
      "step =  104\n",
      "loss =  tensor(4549815., grad_fn=<SubBackward0>)\n",
      "step =  105\n",
      "loss =  tensor(4539072., grad_fn=<SubBackward0>)\n",
      "step =  106\n",
      "loss =  tensor(4537798.5000, grad_fn=<SubBackward0>)\n",
      "step =  107\n",
      "loss =  tensor(4573910.5000, grad_fn=<SubBackward0>)\n",
      "step =  108\n",
      "loss =  tensor(4540836., grad_fn=<SubBackward0>)\n",
      "step =  109\n",
      "loss =  tensor(4554901.5000, grad_fn=<SubBackward0>)\n",
      "step =  110\n",
      "loss =  tensor(4490903., grad_fn=<SubBackward0>)\n",
      "step =  111\n",
      "loss =  tensor(4552220., grad_fn=<SubBackward0>)\n",
      "step =  112\n",
      "loss =  tensor(4503607., grad_fn=<SubBackward0>)\n",
      "step =  113\n",
      "loss =  tensor(4501261., grad_fn=<SubBackward0>)\n",
      "step =  114\n",
      "loss =  tensor(4554286., grad_fn=<SubBackward0>)\n",
      "step =  115\n",
      "loss =  tensor(4520265., grad_fn=<SubBackward0>)\n",
      "step =  116\n",
      "loss =  tensor(4505437., grad_fn=<SubBackward0>)\n",
      "step =  117\n",
      "loss =  tensor(4518004.5000, grad_fn=<SubBackward0>)\n",
      "step =  118\n",
      "loss =  tensor(4514407., grad_fn=<SubBackward0>)\n",
      "step =  119\n",
      "loss =  tensor(4557983., grad_fn=<SubBackward0>)\n",
      "step =  120\n",
      "loss =  tensor(4500022.5000, grad_fn=<SubBackward0>)\n",
      "step =  121\n",
      "loss =  tensor(4523291.5000, grad_fn=<SubBackward0>)\n",
      "step =  122\n",
      "loss =  tensor(4494779.5000, grad_fn=<SubBackward0>)\n",
      "step =  123\n",
      "loss =  tensor(4487721., grad_fn=<SubBackward0>)\n",
      "step =  124\n",
      "loss =  tensor(4523922., grad_fn=<SubBackward0>)\n",
      "step =  125\n",
      "loss =  tensor(4551381., grad_fn=<SubBackward0>)\n",
      "step =  126\n",
      "loss =  tensor(4554856., grad_fn=<SubBackward0>)\n",
      "step =  127\n",
      "loss =  tensor(4545354.5000, grad_fn=<SubBackward0>)\n",
      "step =  128\n",
      "loss =  tensor(4558577., grad_fn=<SubBackward0>)\n",
      "step =  129\n",
      "loss =  tensor(4566781., grad_fn=<SubBackward0>)\n",
      "step =  130\n",
      "loss =  tensor(4606053.5000, grad_fn=<SubBackward0>)\n",
      "step =  131\n",
      "loss =  tensor(4547598.5000, grad_fn=<SubBackward0>)\n",
      "step =  132\n",
      "loss =  tensor(4506731.5000, grad_fn=<SubBackward0>)\n",
      "step =  133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(4481261.5000, grad_fn=<SubBackward0>)\n",
      "step =  134\n",
      "loss =  tensor(4571911.5000, grad_fn=<SubBackward0>)\n",
      "step =  135\n",
      "loss =  tensor(4525618.5000, grad_fn=<SubBackward0>)\n",
      "step =  136\n",
      "loss =  tensor(4528813., grad_fn=<SubBackward0>)\n",
      "step =  137\n",
      "loss =  tensor(4492880., grad_fn=<SubBackward0>)\n",
      "step =  138\n",
      "loss =  tensor(4503380., grad_fn=<SubBackward0>)\n",
      "step =  139\n",
      "loss =  tensor(4596701., grad_fn=<SubBackward0>)\n",
      "step =  140\n",
      "loss =  tensor(4520092., grad_fn=<SubBackward0>)\n",
      "step =  141\n",
      "loss =  tensor(4529584., grad_fn=<SubBackward0>)\n",
      "step =  142\n",
      "loss =  tensor(4512538., grad_fn=<SubBackward0>)\n",
      "step =  143\n",
      "loss =  tensor(4541815.5000, grad_fn=<SubBackward0>)\n",
      "step =  144\n",
      "loss =  tensor(4498305.5000, grad_fn=<SubBackward0>)\n",
      "step =  145\n",
      "loss =  tensor(4504824., grad_fn=<SubBackward0>)\n",
      "step =  146\n",
      "loss =  tensor(4520464., grad_fn=<SubBackward0>)\n",
      "step =  147\n",
      "loss =  tensor(4550431.5000, grad_fn=<SubBackward0>)\n",
      "step =  148\n",
      "loss =  tensor(4519565., grad_fn=<SubBackward0>)\n",
      "step =  149\n",
      "loss =  tensor(4503134., grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "steps = int(150)\n",
    "for s in range(steps):\n",
    "    print('step = ', s)\n",
    "    batchSamples = torch.LongTensor(model.batchSizeN).random_(0, trainingData.nSamples)\n",
    "    model.pfStep(batchSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plotInputReconstruction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.7, 'Untrained, N = 2048')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = plt.gcf()\n",
    "f.suptitle('Untrained, N = 2048', fontsize=32, y=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1453634.9960056504"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.imgResolution**2*32*np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Data.StokesData at 0x7fbe19949350>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33554432"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.microstructImg.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros(int(1e4), int(1e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 100000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.unsqueeze(2)\n",
    "X = X.expand(int(1e4), int(1e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 100000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (generative_DR_ROM)",
   "language": "python",
   "name": "pycharm-712517ba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
